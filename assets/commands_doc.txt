COMMAND: ls

DESCRIPTION: ls - list directory contents

USAGE: ls [OPTION]... [FILE]...

EXECUTION EXAMPLE:
COMMAND INPUT:
ls -la

COMMAND OUTPUT:
total 56
drwxr-xr-x 6 vega vega 4096 Mar  3 23:02 .
drwxr-xr-x 3 root root 4096 Mar  3 22:44 ..
-rw-r--r-- 1 vega vega  220 Mar 29  2024 .bash_logout
-rw-r--r-- 1 vega vega 3526 Mar 29  2024 .bashrc
drwx------ 3 vega vega 4096 Mar  3 22:50 .config
-rw------- 1 vega vega   20 Mar  3 22:48 .lesshst
drwxr-xr-x 3 vega vega 4096 Mar  3 22:48 .local
-rw-r--r-- 1 vega vega  807 Mar 29  2024 .profile
drwx------ 2 vega vega 4096 Mar  3 22:44 .ssh
-rw-r--r-- 1 vega vega 9346 Mar  3 22:58 commands.py
-rw-r--r-- 1 vega vega    0 Mar  3 23:02 commands_doc.txt
-rw-r--r-- 1 vega vega 1440 Mar  3 22:57 commands_exec.txt
-rw-r--r-- 1 vega vega    0 Mar  3 22:58 new_file.txt
drwxr-xr-x 2 vega vega 4096 Mar  3 22:50 test_dir

===

COMMAND: cd

DESCRIPTION: The 'cd' command is a Unix/Linux utility.

USAGE: cd [OPTIONS] [ARGUMENTS]

EXECUTION EXAMPLE:
COMMAND INPUT:
cd ~

COMMAND OUTPUT:
# Note: 'cd' is a shell builtin command that typically doesn't produce output when successful.

===

COMMAND: pwd

DESCRIPTION: pwd - print name of current/working directory

USAGE: pwd [OPTION]...

EXECUTION EXAMPLE:
COMMAND INPUT:
pwd

COMMAND OUTPUT:
/home/vega

===

COMMAND: cat

DESCRIPTION: cat - concatenate files and print on the standard output

USAGE: cat [OPTION]... [FILE]...

EXECUTION EXAMPLE:
COMMAND INPUT:
cat /etc/hostname

COMMAND OUTPUT:
cybo1

===

COMMAND: echo

DESCRIPTION: echo - display a line of text

USAGE: echo [SHORT-OPTION]... [STRING]...
       echo LONG-OPTION

EXECUTION EXAMPLE:
COMMAND INPUT:
echo "Hello World"

COMMAND OUTPUT:
"Hello World"

===

COMMAND: mkdir

DESCRIPTION: mkdir - make directories

USAGE: mkdir [OPTION]... DIRECTORY...

EXECUTION EXAMPLE:
COMMAND INPUT:
mkdir test_dir

COMMAND OUTPUT:
mkdir: cannot create directory ‘test_dir’: File exists

===

COMMAND: touch

DESCRIPTION: touch - change file timestamps

USAGE: touch [OPTION]... FILE...

EXECUTION EXAMPLE:
COMMAND INPUT:
touch new_file.txt

COMMAND OUTPUT:
(No output)

===

COMMAND: whoami

DESCRIPTION: whoami - print effective user name

USAGE: whoami [OPTION]...

EXECUTION EXAMPLE:
COMMAND INPUT:
whoami

COMMAND OUTPUT:
vega

===

COMMAND: uname

DESCRIPTION: uname - print system information

USAGE: uname [OPTION]...

EXECUTION EXAMPLE:
COMMAND INPUT:
uname -a

COMMAND OUTPUT:
Linux cybo1 6.1.0-31-cloud-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.128-1 (2025-02-07) x86_64 GNU/Linux

===

COMMAND: ps

DESCRIPTION: ps - report a snapshot of the current processes.

USAGE: ps [options]

EXECUTION EXAMPLE:
COMMAND INPUT:
ps aux | head -5

COMMAND OUTPUT:
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root           1  0.2  0.3 168996 13608 ?        Ss   22:29   0:04 /sbin/init
root           2  0.0  0.0      0     0 ?        S    22:29   0:00 [kthreadd]
root           3  0.0  0.0      0     0 ?        I<   22:29   0:00 [rcu_gp]
root           4  0.0  0.0      0     0 ?        I<   22:29   0:00 [rcu_par_gp]

===

COMMAND: date

DESCRIPTION: date - print or set the system date and time

USAGE: date [OPTION]... [+FORMAT]
       date [-u|--utc|--universal] [MMDDhhmm[[CC]YY][.ss]]

EXECUTION EXAMPLE:
COMMAND INPUT:
date

COMMAND OUTPUT:
Mon Mar  3 23:02:30 UTC 2025

===

COMMAND: history

DESCRIPTION: history - GNU History Library

USAGE: history [OPTIONS] [ARGUMENTS]

EXECUTION EXAMPLE:
COMMAND INPUT:
history | tail -5

COMMAND OUTPUT:
/bin/sh: 1: history: not found

===

COMMAND: hostname

DESCRIPTION: hostname - show or set the system's host name
       domainname - show or set the system's NIS/YP domain name
       ypdomainname - show or set the system's NIS/YP domain name
       nisdomainname - show or set the system's NIS/YP domain name
       dnsdomainname - show the system's DNS domain name

USAGE: hostname [-a|--alias] [-d|--domain] [-f|--fqdn|--long] [-A|--all-fqdns]
       [-i|--ip-address] [-I|--all-ip-addresses] [-s|--short] [-y|--yp|--nis]
       hostname [-b|--boot] [-F|--file filename] [hostname]
       hostname [-h|--help] [-V|--version]

       domainname [nisdomain] [-F file]
       ypdomainname [nisdomain] [-F file]
       nisdomainname [nisdomain] [-F file]

       dnsdomainname

OPTIONS:
-a, --alias
              Display  the  alias  name  of the host (if used). This option is
              deprecated and should not be used anymore.

       -A, --all-fqdns
              Displays all FQDNs of the machine. This  option  enumerates  all
              configured  network  addresses  on all configured network inter-
              faces, and translates them to DNS domain names.  Addresses  that
              cannot be translated (i.e. because they do not have an appropri-
              ate reverse IP entry) are skipped. Note that different addresses
              may  resolve  to the same name, therefore the output may contain
              duplicate entries. Do not make any assumptions about  the  order
              of the output.

       -b, --boot
              Always  set  a hostname; this allows the file specified by -F to
              be non-existent or empty, in which case the default hostname lo-
              calhost will be used if none is yet set.

       -d, --domain
              Display  the  name of the DNS domain.  Don't use the command do-
              mainname to get the DNS domain name because it will show the NIS
              domain  name  and not the DNS domain name. Use dnsdomainname in-
              stead. See the warnings in section THE FQDN above, and avoid us-
              ing this option.

       -f, --fqdn, --long
              Display  the FQDN (Fully Qualified Domain Name). A FQDN consists
              of a short host name and the DNS domain name. Unless you are us-
              ing bind or NIS for host lookups you can change the FQDN and the
              DNS domain name (which is part of the FQDN)  in  the  /etc/hosts
              file.  See  the warnings in section THE FQDN above und use host-
              name --all-fqdns instead wherever possible.

       -F, --file filename
              Read the host name from  the  specified  file.  Comments  (lines
              starting with a `#') are ignored.

       -i, --ip-address
              Display the network address(es) of the host name. Note that this
              works only if the host name can be resolved.  Avoid  using  this
              option; use hostname --all-ip-addresses instead.

       -I, --all-ip-addresses
              Display  all  network addresses of the host. This option enumer-
              ates all configured addresses on  all  network  interfaces.  The
              loopback  interface  and  IPv6 link-local addresses are omitted.
              Contrary to option -i, this option does not depend on name reso-
              lution.  Do not make any assumptions about the order of the out-
              put.

       -s, --short
              Display the short host name. This is the host name  cut  at  the
              first dot.

       -V, --version
              Print  version  information on standard output and exit success-
              fully.

       -y, --yp, --nis
              Display the NIS domain name. If a parameter is given (or  --file
              name ) then root can also set a new NIS domain.

       -h, --help
              Print a usage message and exit.

EXECUTION EXAMPLE:
COMMAND INPUT:
hostname

COMMAND OUTPUT:
cybo1

===

COMMAND: groups

DESCRIPTION: groups - print the groups a user is in

USAGE: groups [OPTION]... [USERNAME]...

EXECUTION EXAMPLE:
COMMAND INPUT:
groups

COMMAND OUTPUT:
vega adm dip video plugdev google-sudoers

===

COMMAND: uptime

DESCRIPTION: uptime - Tell how long the system has been running.

USAGE: uptime [options]

OPTIONS:
-p, --pretty
              show uptime in pretty format

       -h, --help
              display this help text

       -s, --since
              system up since, in yyyy-mm-dd HH:MM:SS format

       -V, --version
              display version information and exit

EXECUTION EXAMPLE:
COMMAND INPUT:
uptime

COMMAND OUTPUT:
23:02:30 up 33 min,  1 user,  load average: 0.52, 0.29, 0.20

===

COMMAND: file

DESCRIPTION: file -- determine file type

USAGE: file [-bcdEhiklLNnprsSvzZ0] [--apple] [--exclude-quiet] [--extension]
          [--mime-encoding] [--mime-type] [-e testname] [-F separator]
          [-f namefile] [-m magicfiles] [-P name=value] file ...
     file -C [-m magicfiles]
     file [--help]

OPTIONS:
--apple
             Causes the file command to output the file type and creator code
             as used by older MacOS versions.  The code consists of eight let-
             ters, the first describing the file type, the latter the creator.
             This option works properly only for file formats that have the
             apple-style output defined.

     -b, --brief
             Do not prepend filenames to output lines (brief mode).

     -C, --compile
             Write a magic.mgc output file that contains a pre-parsed version
             of the magic file or directory.

     -c, --checking-printout
             Cause a checking printout of the parsed form of the magic file.
             This is usually used in conjunction with the -m option to debug a
             new magic file before installing it.

     -d      Prints internal debugging information to stderr.

     -E      On filesystem errors (file not found etc), instead of handling
             the error as regular output as POSIX mandates and keep going, is-
             sue an error message and exit.

     -e, --exclude testname
             Exclude the test named in testname from the list of tests made to
             determine the file type.  Valid test names are:

             apptype   EMX application type (only on EMX).

             ascii     Various types of text files (this test will try to
                       guess the text encoding, irrespective of the setting of
                       the 'encoding' option).

             encoding  Different text encodings for soft magic tests.

             tokens    Ignored for backwards compatibility.

             cdf       Prints details of Compound Document Files.

             compress  Checks for, and looks inside, compressed files.

             csv       Checks Comma Separated Value files.

             elf       Prints ELF file details, provided soft magic tests are
                       enabled and the elf magic is found.

             json      Examines JSON (RFC-7159) files by parsing them for com-
                       pliance.

             soft      Consults magic files.

             tar       Examines tar files by verifying the checksum of the 512
                       byte tar header.  Excluding this test can provide more
                       detailed content description by using the soft magic
                       method.

             text      A synonym for 'ascii'.

     --exclude-quiet
             Like --exclude but ignore tests that file does not know about.
             This is intended for compatibility with older versions of file.

     --extension
             Print a slash-separated list of valid extensions for the file
             type found.

     -F, --separator separator
             Use the specified string as the separator between the filename
             and the file result returned.  Defaults to ':'.

     -f, --files-from namefile
             Read the names of the files to be examined from namefile (one per
             line) before the argument list.  Either namefile or at least one
             filename argument must be present; to test the standard input,
             use '-' as a filename argument.  Please note that namefile is un-
             wrapped and the enclosed filenames are processed when this option
             is encountered and before any further options processing is done.
             This allows one to process multiple lists of files with different
             command line arguments on the same file invocation.  Thus if you
             want to set the delimiter, you need to do it before you specify
             the list of files, like: "-F @ -f namefile", instead of: "-f
             namefile -F @".

     -h, --no-dereference
             This option causes symlinks not to be followed (on systems that
             support symbolic links).  This is the default if the environment
             variable POSIXLY_CORRECT is not defined.

     -i, --mime
             Causes the file command to output mime type strings rather than
             the more traditional human readable ones.  Thus it may say
             'text/plain; charset=us-ascii' rather than "ASCII text".

     --mime-type, --mime-encoding
             Like -i, but print only the specified element(s).

     -k, --keep-going
             Don't stop at the first match, keep going.  Subsequent matches
             will be have the string '\012- ' prepended.  (If you want a new-
             line, see the -r option.)  The magic pattern with the highest
             strength (see the -l option) comes first.

     -l, --list
             Shows a list of patterns and their strength sorted descending by
             magic(5) strength which is used for the matching (see also the -k
             option).

     -L, --dereference
             This option causes symlinks to be followed, as the like-named op-
             tion in ls(1) (on systems that support symbolic links).  This is
             the default if the environment variable POSIXLY_CORRECT is de-
             fined.

     -m, --magic-file magicfiles
             Specify an alternate list of files and directories containing
             magic.  This can be a single item, or a colon-separated list.  If
             a compiled magic file is found alongside a file or directory, it
             will be used instead.

     -N, --no-pad
             Don't pad filenames so that they align in the output.

     -n, --no-buffer
             Force stdout to be flushed after checking each file.  This is
             only useful if checking a list of files.  It is intended to be
             used by programs that want filetype output from a pipe.

     -p, --preserve-date
             On systems that support utime(3) or utimes(2), attempt to pre-
             serve the access time of files analyzed, to pretend that file
             never read them.

     -P, --parameter name=value
             Set various parameter limits.

                   Name         Default    Explanation
                   bytes        1048576    max number of bytes to read from
                                                                          file
                   elf_notes    256        max ELF notes processed
                   elf_phnum    2048       max ELF program sections processed
                   elf_shnum    32768      max ELF sections processed
                   encoding     65536      max number of bytes to scan for
                                                                          encoding
                                                                          evaluation
                   indir        50         recursion limit for indirect magic
                   name         50         use count limit for name/use magic
                   regex        8192       length limit for regex searches

     -r, --raw
             Don't translate unprintable characters to \ooo.  Normally file
             translates unprintable characters to their octal representation.

     -s, --special-files
             Normally, file only attempts to read and determine the type of
             argument files which stat(2) reports are ordinary files.  This
             prevents problems, because reading special files may have pecu-
             liar consequences.  Specifying the -s option causes file to also
             read argument files which are block or character special files.
             This is useful for determining the filesystem types of the data
             in raw disk partitions, which are block special files.  This op-
             tion also causes file to disregard the file size as reported by
             stat(2) since on some systems it reports a zero size for raw disk
             partitions.

     -S, --no-sandbox
             On systems where libseccomp
             (https://github.com/seccomp/libseccomp) is available, the -S op-
             tion disables sandboxing which is enabled by default.  This op-
             tion is needed for file to execute external decompressing pro-
             grams, i.e. when the -z option is specified and the built-in de-
             compressors are not available.  On systems where sandboxing is
             not available, this option has no effect.

             Note: This Debian version of file was built without seccomp sup-
             port, so this option has no effect.

     -v, --version
             Print the version of the program and exit.

     -z, --uncompress
             Try to look inside compressed files.

     -Z, --uncompress-noreport
             Try to look inside compressed files, but report information about
             the contents only not the compression.

     -0, --print0
             Output a null character '\0' after the end of the filename.  Nice
             to cut(1) the output.  This does not affect the separator, which
             is still printed.

             If this option is repeated more than once, then file prints just
             the filename followed by a NUL followed by the description (or
             ERROR: text) followed by a second NUL for each entry.

     --help  Print a help message and exit.

EXECUTION EXAMPLE:
COMMAND INPUT:
file /bin/bash

COMMAND OUTPUT:
/bin/bash: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=f6101dbf7496e744703ecab8c33c2cc348805f7f, for GNU/Linux 3.2.0, stripped

===

COMMAND: wc

DESCRIPTION: wc - print newline, word, and byte counts for each file

USAGE: wc [OPTION]... [FILE]...
       wc [OPTION]... --files0-from=F

EXECUTION EXAMPLE:
COMMAND INPUT:
wc -l /etc/passwd

COMMAND OUTPUT:
28 /etc/passwd

===

COMMAND: head

DESCRIPTION: head - output the first part of files

USAGE: head [OPTION]... [FILE]...

EXECUTION EXAMPLE:
COMMAND INPUT:
head -3 /etc/passwd

COMMAND OUTPUT:
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin

===

COMMAND: tail

DESCRIPTION: tail - output the last part of files

USAGE: tail [OPTION]... [FILE]...

EXECUTION EXAMPLE:
COMMAND INPUT:
tail -3 /etc/passwd

COMMAND OUTPUT:
sshd:x:104:65534::/run/sshd:/usr/sbin/nologin
polkitd:x:995:995:polkit:/nonexistent:/usr/sbin/nologin
vega:x:1000:1001::/home/vega:/bin/bash

===

COMMAND: du

DESCRIPTION: du - estimate file space usage

USAGE: du [OPTION]... [FILE]...
       du [OPTION]... --files0-from=F

EXECUTION EXAMPLE:
COMMAND INPUT:
du -sh /home

COMMAND OUTPUT:
92K	/home

===

COMMAND: df

DESCRIPTION: df - report file system space usage

USAGE: df [OPTION]... [FILE]...

OPTIONS:
Show  information  about the file system on which each FILE resides, or
       all file systems by default.

       Mandatory arguments to long options are  mandatory  for  short  options
       too.

       -a, --all
              include pseudo, duplicate, inaccessible file systems

       -B, --block-size=SIZE
              scale  sizes  by  SIZE  before printing them; e.g., '-BM' prints
              sizes in units of 1,048,576 bytes; see SIZE format below

       -h, --human-readable
              print sizes in powers of 1024 (e.g., 1023M)

       -H, --si
              print sizes in powers of 1000 (e.g., 1.1G)

       -i, --inodes
              list inode information instead of block usage

       -k     like --block-size=1K

       -l, --local
              limit listing to local file systems

       --no-sync
              do not invoke sync before getting usage info (default)

       --output[=FIELD_LIST]
              use the output format defined by FIELD_LIST, or print all fields
              if FIELD_LIST is omitted.

       -P, --portability
              use the POSIX output format

       --sync invoke sync before getting usage info

       --total
              elide  all entries insignificant to available space, and produce
              a grand total

       -t, --type=TYPE
              limit listing to file systems of type TYPE

       -T, --print-type
              print file system type

       -x, --exclude-type=TYPE
              limit listing to file systems not of type TYPE

       -v     (ignored)

       --help display this help and exit

       --version
              output version information and exit

       Display  values  are  in  units  of  the  first  available  SIZE   from
       --block-size,  and the DF_BLOCK_SIZE, BLOCK_SIZE and BLOCKSIZE environ-
       ment variables.  Otherwise, units default to  1024  bytes  (or  512  if
       POSIXLY_CORRECT is set).

       The  SIZE  argument  is  an  integer and optional unit (example: 10K is
       10*1024).  Units are K,M,G,T,P,E,Z,Y  (powers  of  1024)  or  KB,MB,...
       (powers  of 1000).  Binary prefixes can be used, too: KiB=K, MiB=M, and
       so on.

       FIELD_LIST is a comma-separated list of columns to be included.   Valid
       field  names are: 'source', 'fstype', 'itotal', 'iused', 'iavail', 'ip-
       cent', 'size', 'used', 'avail', 'pcent', 'file' and 'target' (see  info
       page).

EXECUTION EXAMPLE:
COMMAND INPUT:
df -h

COMMAND OUTPUT:
Filesystem      Size  Used Avail Use% Mounted on
udev            2.0G     0  2.0G   0% /dev
tmpfs           393M  532K  392M   1% /run
/dev/sda1       9.7G  3.5G  5.8G  38% /
tmpfs           2.0G     0  2.0G   0% /dev/shm
tmpfs           5.0M     0  5.0M   0% /run/lock
/dev/sda15      124M   12M  113M  10% /boot/efi
tmpfs           393M     0  393M   0% /run/user/1000

===

COMMAND: stat

DESCRIPTION: stat - display file or file system status

USAGE: stat [OPTION]... FILE...

EXECUTION EXAMPLE:
COMMAND INPUT:
stat /etc/passwd

COMMAND OUTPUT:
File: /etc/passwd
  Size: 1399      	Blocks: 8          IO Block: 4096   regular file
Device: 8,1	Inode: 1418        Links: 1
Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)
Access: 2025-03-03 22:44:07.369747237 +0000
Modify: 2025-03-03 22:44:07.345746069 +0000
Change: 2025-03-03 22:44:07.345746069 +0000
 Birth: 2025-03-03 22:44:07.345746069 +0000

===

COMMAND: ip

DESCRIPTION: ip - show / manipulate routing, network devices, interfaces and tunnels

USAGE: ip [ OPTIONS ] OBJECT { COMMAND | help }

       ip [ -force ] -batch filename

       OBJECT := { link | address | addrlabel | route | rule | neigh | ntable
               | tunnel | tuntap | maddress | mroute | mrule | monitor | xfrm
               | netns | l2tp | tcp_metrics | token | macsec | vrf | mptcp |
               ioam | stats }

       OPTIONS := { -V[ersion] | -h[uman-readable] | -s[tatistics] |
               -d[etails] | -r[esolve] | -iec | -f[amily] { inet | inet6 |
               link } | -4 | -6 | -B | -0 | -l[oops] { maximum-addr-flush-at-
               tempts } | -o[neline] | -rc[vbuf] [size] | -t[imestamp] |
               -ts[hort] | -n[etns] name | -N[umeric] | -a[ll] | -c[olor] |
               -br[ief] | -j[son] | -p[retty] }

OPTIONS:
-V, -Version
              Print the version of the ip utility and exit.

       -h, -human, -human-readable
              output statistics with human readable values followed by suffix.

       -b, -batch <FILENAME>
              Read commands from provided file or standard input and invoke
              them.  First failure will cause termination of ip.

       -force Don't terminate ip on errors in batch mode.  If there were any
              errors during execution of the commands, the application return
              code will be non zero.

       -s, -stats, -statistics
              Output more information. If the option appears twice or more,
              the amount of information increases.  As a rule, the information
              is statistics or some time values.

       -d, -details
              Output more detailed information.

       -l, -loops <COUNT>
              Specify maximum number of loops the 'ip address flush' logic
              will attempt before giving up. The default is 10.  Zero (0)
              means loop until all addresses are removed.

       -f, -family <FAMILY>
              Specifies the protocol family to use. The protocol family iden-
              tifier can be one of inet, inet6, bridge, mpls or link.  If this
              option is not present, the protocol family is guessed from other
              arguments. If the rest of the command line does not give enough
              information to guess the family, ip falls back to the default
              one, usually inet or any.  link is a special family identifier
              meaning that no networking protocol is involved.

       -4     shortcut for -family inet.

       -6     shortcut for -family inet6.

       -B     shortcut for -family bridge.

       -M     shortcut for -family mpls.

       -0     shortcut for -family link.

       -o, -oneline
              output each record on a single line, replacing line feeds with
              the '\' character. This is convenient when you want to count
              records with wc(1) or to grep(1) the output.

       -r, -resolve
              use the system's name resolver to print DNS names instead of
              host addresses.

       -n, -netns <NETNS>
              switches ip to the specified network namespace NETNS.  Actually
              it just simplifies executing of:

              ip netns exec NETNS ip [ OPTIONS ] OBJECT { COMMAND | help }

              to

              ip -n[etns] NETNS [ OPTIONS ] OBJECT { COMMAND | help }

       -N, -Numeric
              Print the number of protocol, scope, dsfield, etc directly in-
              stead of converting it to human readable name.

       -a, -all
              executes specified command over all objects, it depends if com-
              mand supports this option.

       -c[color][={always|auto|never}
              Configure color output. If parameter is omitted or always, color
              output is enabled regardless of stdout state. If parameter is
              auto, stdout is checked to be a terminal before enabling color
              output. If parameter is never, color output is disabled. If
              specified multiple times, the last one takes precedence. This
              flag is ignored if -json is also given.

              Used color palette can be influenced by COLORFGBG environment
              variable (see ENVIRONMENT).

       -t, -timestamp
              display current time when using monitor option.

       -ts, -tshort
              Like -timestamp, but use shorter format.

       -rc, -rcvbuf<SIZE>
              Set the netlink socket receive buffer size, defaults to 1MB.

       -iec   print human readable rates in IEC units (e.g. 1Ki = 1024).

       -br, -brief
              Print only basic information in a tabular format for better
              readability. This option is currently only supported by ip addr
              show , ip link show & ip neigh show commands.

       -j, -json
              Output results in JavaScript Object Notation (JSON).

       -p, -pretty
              The default JSON format is compact and more efficient to parse
              but hard for most users to read.  This flag adds indentation for
              readability.

       -echo  Request the kernel to send the applied configuration back.

EXECUTION EXAMPLE:
COMMAND INPUT:
ip addr

COMMAND OUTPUT:
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host noprefixroute 
       valid_lft forever preferred_lft forever
2: ens4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1460 qdisc mq state UP group default qlen 1000
    link/ether 42:01:0a:80:00:02 brd ff:ff:ff:ff:ff:ff
    altname enp0s4
    inet 10.128.0.2/32 metric 100 scope global dynamic ens4
       valid_lft 3422sec preferred_lft 3422sec
    inet6 fe80::4001:aff:fe80:2/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:c0:c0:b3:f9 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever

===

COMMAND: netstat

DESCRIPTION: netstat  - Print network connections, routing tables, interface statis-
       tics, masquerade connections, and multicast memberships

USAGE: netstat [address_family_options] [--tcp|-t]  [--udp|-u]  [--udplite|-U]
       [--sctp|-S]   [--raw|-w]  [--l2cap|-2]  [--rfcomm|-f]  [--listening|-l]
       [--all|-a] [--numeric|-n]  [--numeric-hosts]  [--numeric-ports]  [--nu-
       meric-users]  [--symbolic|-N]  [--extend|-e[--extend|-e]] [--timers|-o]
       [--program|-p] [--verbose|-v] [--continuous|-c] [--wide|-W]

       netstat   {--route|-r}   [address_family_options]    [--extend|-e[--ex-
       tend|-e]]   [--verbose|-v]   [--numeric|-n]   [--numeric-hosts]  [--nu-
       meric-ports] [--numeric-users] [--continuous|-c]

       netstat {--interfaces|-i} [--all|-a] [--extend|-e[--extend|-e]] [--ver-
       bose|-v]  [--program|-p]  [--numeric|-n]  [--numeric-hosts] [--numeric-
       ports] [--numeric-users] [--continuous|-c]

       netstat   {--groups|-g}   [--numeric|-n]    [--numeric-hosts]    [--nu-
       meric-ports] [--numeric-users] [--continuous|-c]

       netstat    {--masquerade|-M}    [--extend|-e]   [--numeric|-n]   [--nu-
       meric-hosts] [--numeric-ports] [--numeric-users] [--continuous|-c]

       netstat   {--statistics|-s}   [--tcp|-t]   [--udp|-u]    [--udplite|-U]
       [--sctp|-S] [--raw|-w]

       netstat {--version|-V}

       netstat {--help|-h}

       address_family_options:

       [-4|--inet]                    [-6|--inet6]                   [--proto-
       col={inet,inet6,unix,ipx,ax25,netrom,ddp,bluetooth, ... } ] [--unix|-x]
       [--inet|--ip|--tcpip]  [--ax25]  [--x25] [--rose] [--ash] [--bluetooth]
       [--ipx] [--netrom] [--ddp|--appletalk] [--econet|--ec]

OPTIONS:
--verbose, -v
       Tell  the user what is going on by being verbose. Especially print some
       useful information about unconfigured address families.

   --wide, -W
       Do not truncate IP addresses by using output as wide as needed. This is
       optional for now to not break existing scripts.

   --numeric, -n
       Show  numerical addresses instead of trying to determine symbolic host,
       port or user names.

   --numeric-hosts
       shows numerical host addresses but does not affect  the  resolution  of
       port or user names.

   --numeric-ports
       shows numerical port numbers but does not affect the resolution of host
       or user names.

   --numeric-users
       shows numerical user IDs but does not affect the resolution of host  or
       port names.

   --protocol=family, -A
       Specifies  the  address families (perhaps better described as low level
       protocols) for which connections are to be shown.  family  is  a  comma
       (',') separated list of address family keywords like inet, inet6, unix,
       ipx, ax25, netrom, econet, ddp, and bluetooth.  This has the  same  ef-
       fect  as  using  the  --inet|-4,  --inet6|-6, --unix|-x, --ipx, --ax25,
       --netrom, --ddp, and --bluetooth options.

       The address family inet (Iv4) includes raw, udp, udplite and tcp proto-
       col sockets.

       The  address  family bluetooth (Iv4) includes l2cap and rfcomm protocol
       sockets.

   -c, --continuous
       This will cause netstat to print the selected information every  second
       continuously.

   -e, --extend
       Display  additional information.  Use this option twice for maximum de-
       tail.

   -o, --timers
       Include information related to networking timers.

   -p, --program
       Show the PID and name of the program to which each socket  belongs.   A
       hyphen is shown if the socket belongs to the kernel (e.g. a kernel ser-
       vice, or the process has exited but the socket hasn't finished  closing
       yet).

   -l, --listening
       Show only listening sockets.  (These are omitted by default.)

   -a, --all
       Show  both  listening and non-listening sockets.  With the --interfaces
       option, show interfaces that are not up

   -F
       Print routing information from the FIB.  (This is the default.)

   -C
       Print routing information from the route cache.

EXECUTION EXAMPLE:
COMMAND INPUT:
netstat -tulpn

COMMAND OUTPUT:
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 127.0.0.1:34777         0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.53:53           0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:5355            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.54:53           0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:20202           0.0.0.0:*               LISTEN      -                   
tcp6       0      0 :::22                   :::*                    LISTEN      -                   
tcp6       0      0 ::1:25                  :::*                    LISTEN      -                   
tcp6       0      0 :::5355                 :::*                    LISTEN      -                   
tcp6       0      0 :::20201                :::*                    LISTEN      -                   
udp        0      0 0.0.0.0:5355            0.0.0.0:*                           -                   
udp        0      0 127.0.0.54:53           0.0.0.0:*                           -                   
udp        0      0 127.0.0.53:53           0.0.0.0:*                           -                   
udp        0      0 10.128.0.2:68           0.0.0.0:*                           -                   
udp6       0      0 :::5355                 :::*                                -

===

COMMAND: chmod

DESCRIPTION: chmod - change file mode bits

USAGE: chmod [OPTION]... MODE[,MODE]... FILE...
       chmod [OPTION]... OCTAL-MODE FILE...
       chmod [OPTION]... --reference=RFILE FILE...

OPTIONS:
Change  the  mode  of  each FILE to MODE.  With --reference, change the
       mode of each FILE to that of RFILE.

       -c, --changes
              like verbose but report only when a change is made

       -f, --silent, --quiet
              suppress most error messages

       -v, --verbose
              output a diagnostic for every file processed

       --no-preserve-root
              do not treat '/' specially (the default)

       --preserve-root
              fail to operate recursively on '/'

       --reference=RFILE
              use RFILE's mode instead of MODE values

       -R, --recursive
              change files and directories recursively

       --help display this help and exit

       --version
              output version information and exit

       Each          MODE          is          of           the           form
       '[ugoa]*([-+=]([rwxXst]*|[ugo]))+|[-+=][0-7]+'.

EXECUTION EXAMPLE:
COMMAND INPUT:
chmod 755 test_dir

COMMAND OUTPUT:
# Note: Command 'chmod 755 test_dir' not executed for safety reasons. Use with caution.

===

COMMAND: chown

DESCRIPTION: chown - change file owner and group

USAGE: chown [OPTION]... [OWNER][:[GROUP]] FILE...
       chown [OPTION]... --reference=RFILE FILE...

OPTIONS:
Change the owner and/or group of each FILE to OWNER and/or GROUP.  With
       --reference, change the owner and group of each FILE to those of RFILE.

       -c, --changes
              like verbose but report only when a change is made

       -f, --silent, --quiet
              suppress most error messages

       -v, --verbose
              output a diagnostic for every file processed

       --dereference
              affect the referent of each symbolic link (this is the default),
              rather than the symbolic link itself

       -h, --no-dereference
              affect  symbolic  links  instead  of any referenced file (useful
              only on systems that can change the ownership of a symlink)

       --from=CURRENT_OWNER:CURRENT_GROUP
              change the owner and/or group of each file only if  its  current
              owner  and/or  group  match those specified here.  Either may be
              omitted, in which case a match is not required for  the  omitted
              attribute

       --no-preserve-root
              do not treat '/' specially (the default)

       --preserve-root
              fail to operate recursively on '/'

       --reference=RFILE
              use  RFILE's  owner and group rather than specifying OWNER:GROUP
              values

       -R, --recursive
              operate on files and directories recursively

       The following options modify how a hierarchy is traversed when  the  -R
       option  is also specified.  If more than one is specified, only the fi-
       nal one takes effect.

       -H     if a command line argument is a symbolic link  to  a  directory,
              traverse it

       -L     traverse every symbolic link to a directory encountered

       -P     do not traverse any symbolic links (default)

       --help display this help and exit

       --version
              output version information and exit

       Owner  is  unchanged  if  missing.   Group is unchanged if missing, but
       changed to login group if implied by a ':' following a symbolic  OWNER.
       OWNER and GROUP may be numeric as well as symbolic.

EXECUTION EXAMPLE:
COMMAND INPUT:
chown $(whoami) new_file.txt

COMMAND OUTPUT:
# Note: Command 'chown $(whoami) new_file.txt' not executed for safety reasons. Use with caution.

===

COMMAND: grep

DESCRIPTION: grep, egrep, fgrep, rgrep - print lines that match patterns

USAGE: grep [OPTION...] PATTERNS [FILE...]
       grep [OPTION...] -e PATTERNS ... [FILE...]
       grep [OPTION...] -f PATTERN_FILE ... [FILE...]

OPTIONS:
Generic Program Information
       --help Output a usage message and exit.

       -V, --version
              Output the version number of grep and exit.

   Pattern Syntax
       -E, --extended-regexp
              Interpret  PATTERNS  as  extended regular expressions (EREs, see
              below).

       -F, --fixed-strings
              Interpret PATTERNS as fixed strings, not regular expressions.

       -G, --basic-regexp
              Interpret PATTERNS  as  basic  regular  expressions  (BREs,  see
              below).  This is the default.

       -P, --perl-regexp
              Interpret   PATTERNS   as  Perl-compatible  regular  expressions
              (PCREs).  This option is experimental when combined with the  -z
              (--null-data)  option,  and  grep  -P  may warn of unimplemented
              features.

   Matching Control
       -e PATTERNS, --regexp=PATTERNS
              Use PATTERNS as the patterns.  If this option is  used  multiple
              times or is combined with the -f (--file) option, search for all
              patterns given.  This option can be used to  protect  a  pattern
              beginning with "-".

       -f FILE, --file=FILE
              Obtain patterns from FILE, one per line.  If this option is used
              multiple times or is combined with  the  -e  (--regexp)  option,
              search  for  all  patterns  given.  The empty file contains zero
              patterns, and therefore matches nothing.

       -i, --ignore-case
              Ignore case distinctions in patterns and  input  data,  so  that
              characters that differ only in case match each other.

       --no-ignore-case
              Do  not  ignore  case  distinctions  in patterns and input data.
              This is the default.  This option is useful for passing to shell
              scripts  that  already use -i, to cancel its effects because the
              two options override each other.

       -v, --invert-match
              Invert the sense of matching, to select non-matching lines.

       -w, --word-regexp
              Select only those  lines  containing  matches  that  form  whole
              words.   The  test is that the matching substring must either be
              at the  beginning  of  the  line,  or  preceded  by  a  non-word
              constituent  character.  Similarly, it must be either at the end
              of the line or followed by  a  non-word  constituent  character.
              Word-constituent   characters   are  letters,  digits,  and  the
              underscore.  This option has no effect if -x is also specified.

       -x, --line-regexp
              Select only those matches that exactly  match  the  whole  line.
              For  a  regular  expression pattern, this is like parenthesizing
              the pattern and then surrounding it with ^ and $.

   General Output Control
       -c, --count
              Suppress normal output; instead print a count of matching  lines
              for  each  input  file.  With the -v, --invert-match option (see
              above), count non-matching lines.

       --color[=WHEN], --colour[=WHEN]
              Surround  the  matched  (non-empty)  strings,  matching   lines,
              context  lines,  file  names,  line  numbers,  byte offsets, and
              separators (for fields and groups of context lines) with  escape
              sequences  to display them in color on the terminal.  The colors
              are defined by the environment variable  GREP_COLORS.   WHEN  is
              never, always, or auto.

       -L, --files-without-match
              Suppress  normal  output;  instead  print the name of each input
              file from which no output would normally have been printed.

       -l, --files-with-matches
              Suppress normal output; instead print the  name  of  each  input
              file  from  which  output  would  normally  have  been  printed.
              Scanning each input file stops upon first match.

       -m NUM, --max-count=NUM
              Stop reading a file after NUM matching lines.  If NUM  is  zero,
              grep  stops  right  away  without reading input.  A NUM of -1 is
              treated as infinity and grep does not stop; this is the default.
              If  the  input  is  standard  input from a regular file, and NUM
              matching lines are output, grep ensures that the standard  input
              is  positioned  to  just  after  the  last  matching line before
              exiting, regardless of the presence of trailing  context  lines.
              This  enables  a  calling process to resume a search.  When grep
              stops after NUM matching lines, it outputs any trailing  context
              lines.   When  the  -c or --count option is also used, grep does
              not  output  a  count  greater  than  NUM.   When  the   -v   or
              --invert-match  option is also used, grep stops after outputting
              NUM non-matching lines.

       -o, --only-matching
              Print only the matched (non-empty) parts  of  a  matching  line,
              with each such part on a separate output line.

       -q, --quiet, --silent
              Quiet;   do   not  write  anything  to  standard  output.   Exit
              immediately with zero status if any match is found, even  if  an
              error was detected.  Also see the -s or --no-messages option.

       -s, --no-messages
              Suppress error messages about nonexistent or unreadable files.

   Output Line Prefix Control
       -b, --byte-offset
              Print  the 0-based byte offset within the input file before each
              line of output.  If -o (--only-matching) is specified, print the
              offset of the matching part itself.

       -H, --with-filename
              Print  the  file  name for each match.  This is the default when
              there is more than one file to search.  This is a GNU extension.

       -h, --no-filename
              Suppress the prefixing of file names on  output.   This  is  the
              default  when there is only one file (or only standard input) to
              search.

       --label=LABEL
              Display input actually  coming  from  standard  input  as  input
              coming  from  file  LABEL.  This can be useful for commands that
              transform a file's contents before  searching,  e.g.,  gzip  -cd
              foo.gz  |  grep  --label=foo -H 'some pattern'.  See also the -H
              option.

       -n, --line-number
              Prefix each line of output with the 1-based line  number  within
              its input file.

       -T, --initial-tab
              Make  sure  that the first character of actual line content lies
              on a tab stop, so that the alignment of tabs looks normal.  This
              is  useful  with  options that prefix their output to the actual
              content: -H,-n, and -b.  In order  to  improve  the  probability
              that lines from a single file will all start at the same column,
              this also causes the line number and byte offset (if present) to
              be printed in a minimum size field width.

       -Z, --null
              Output  a  zero  byte  (the  ASCII NUL character) instead of the
              character that normally follows a file name.  For example,  grep
              -lZ  outputs  a  zero  byte  after each file name instead of the
              usual newline.  This option makes the output  unambiguous,  even
              in the presence of file names containing unusual characters like
              newlines.  This option can  be  used  with  commands  like  find
              -print0,  perl  -0,  sort  -z, and xargs -0 to process arbitrary
              file names, even those that contain newline characters.

   Context Line Control
       -A NUM, --after-context=NUM
              Print NUM  lines  of  trailing  context  after  matching  lines.
              Places   a  line  containing  a  group  separator  (--)  between
              contiguous groups of matches.  With the  -o  or  --only-matching
              option, this has no effect and a warning is given.

       -B NUM, --before-context=NUM
              Print  NUM  lines  of  leading  context  before  matching lines.
              Places  a  line  containing  a  group  separator  (--)   between
              contiguous  groups  of  matches.  With the -o or --only-matching
              option, this has no effect and a warning is given.

       -C NUM, -NUM, --context=NUM
              Print NUM lines of output context.  Places a line  containing  a
              group separator (--) between contiguous groups of matches.  With
              the -o or --only-matching option,  this  has  no  effect  and  a
              warning is given.

       --group-separator=SEP
              When  -A,  -B, or -C are in use, print SEP instead of -- between
              groups of lines.

       --no-group-separator
              When -A, -B, or -C are in use, do not print a separator  between
              groups of lines.

   File and Directory Selection
       -a, --text
              Process  a binary file as if it were text; this is equivalent to
              the --binary-files=text option.

       --binary-files=TYPE
              If a file's data or metadata indicate  that  the  file  contains
              binary  data,  assume  that  the file is of type TYPE.  Non-text
              bytes indicate binary data; these are either output  bytes  that
              are  improperly  encoded  for  the current locale, or null input
              bytes when the -z option is not given.

              By default, TYPE is binary, and  grep  suppresses  output  after
              null  input  binary  data  is  discovered, and suppresses output
              lines that contain improperly encoded data.  When some output is
              suppressed,  grep  follows any output with a message to standard
              error saying that a binary file matches.

              If TYPE is without-match, when grep discovers null input  binary
              data  it  assumes that the rest of the file does not match; this
              is equivalent to the -I option.

              If TYPE is text, grep processes a binary  file  as  if  it  were
              text; this is equivalent to the -a option.

              When  type  is  binary,  grep  may  treat non-text bytes as line
              terminators even without the -z  option.   This  means  choosing
              binary  versus text can affect whether a pattern matches a file.
              For example, when type is binary the pattern q$  might  match  q
              immediately  followed  by  a  null byte, even though this is not
              matched when type is text.  Conversely, when type is binary  the
              pattern . (period) might not match a null byte.

              Warning:  The  -a  option might output binary garbage, which can
              have nasty side effects if the output is a terminal and  if  the
              terminal driver interprets some of it as commands.  On the other
              hand, when reading files whose text encodings  are  unknown,  it
              can   be  helpful  to  use  -a  or  to  set  LC_ALL='C'  in  the
              environment, in order to find more matches even if  the  matches
              are unsafe for direct display.

       -D ACTION, --devices=ACTION
              If  an  input  file  is  a device, FIFO or socket, use ACTION to
              process it.  By  default,  ACTION  is  read,  which  means  that
              devices are read just as if they were ordinary files.  If ACTION
              is skip, devices are silently skipped.

       -d ACTION, --directories=ACTION
              If an input file is a directory, use ACTION to process  it.   By
              default,  ACTION is read, i.e., read directories just as if they
              were  ordinary  files.   If  ACTION  is  skip,   silently   skip
              directories.   If  ACTION  is recurse, read all files under each
              directory, recursively, following symbolic links  only  if  they
              are on the command line.  This is equivalent to the -r option.

       --exclude=GLOB
              Skip  any  command-line file with a name suffix that matches the
              pattern GLOB, using wildcard matching; a name suffix  is  either
              the  whole name, or a trailing part that starts with a non-slash
              character immediately after a  slash  (/)  in  the  name.   When
              searching  recursively, skip any subfile whose base name matches
              GLOB; the base name is the part after the last slash.  A pattern
              can  use *, ?, and [...] as wildcards, and \ to quote a wildcard
              or backslash character literally.

       --exclude-from=FILE
              Skip files whose base name matches any of  the  file-name  globs
              read  from  FILE  (using  wildcard  matching  as described under
              --exclude).

       --exclude-dir=GLOB
              Skip any command-line directory with a name suffix that  matches
              the   pattern   GLOB.   When  searching  recursively,  skip  any
              subdirectory whose base name matches GLOB.  Ignore any redundant
              trailing slashes in GLOB.

       -I     Process  a  binary  file as if it did not contain matching data;
              this is equivalent to the --binary-files=without-match option.

       --include=GLOB
              Search only files whose base name matches GLOB  (using  wildcard
              matching   as  described  under  --exclude).   If  contradictory
              --include and --exclude options are given, the last matching one
              wins.   If  no  --include  or --exclude options match, a file is
              included unless the first such option is --include.

       -r, --recursive
              Read all files  under  each  directory,  recursively,  following
              symbolic  links only if they are on the command line.  Note that
              if  no  file  operand  is  given,  grep  searches  the   working
              directory.  This is equivalent to the -d recurse option.

       -R, --dereference-recursive
              Read  all  files  under each directory, recursively.  Follow all
              symbolic links, unlike -r.

   Other Options
       --line-buffered
              Use line buffering on output.   This  can  cause  a  performance
              penalty.

       -U, --binary
              Treat  the  file(s) as binary.  By default, under MS-DOS and MS-
              Windows, grep guesses whether  a  file  is  text  or  binary  as
              described  for  the  --binary-files option.  If grep decides the
              file is a text file,  it  strips  the  CR  characters  from  the
              original file contents (to make regular expressions with ^ and $
              work  correctly).   Specifying  -U  overrules  this   guesswork,
              causing  all  files  to  be  read  and  passed  to  the matching
              mechanism verbatim; if the file is a text file with CR/LF  pairs
              at   the  end  of  each  line,  this  will  cause  some  regular
              expressions to fail.  This option has  no  effect  on  platforms
              other than MS-DOS and MS-Windows.

       -z, --null-data
              Treat  input  and  output  data  as  sequences  of  lines,  each
              terminated by a zero byte (the ASCII NUL character) instead of a
              newline.   Like the -Z or --null option, this option can be used
              with commands like sort -z to process arbitrary file names.

EXECUTION EXAMPLE:
COMMAND INPUT:
grep "root" /etc/passwd

COMMAND OUTPUT:
(No output)

===

COMMAND: sort

DESCRIPTION: sort - sort lines of text files

USAGE: sort [OPTION]... [FILE]...
       sort [OPTION]... --files0-from=F

EXECUTION EXAMPLE:
COMMAND INPUT:
sort /etc/passwd | head -3

COMMAND OUTPUT:
Debian-exim:x:100:102::/var/spool/exim4:/usr/sbin/nologin
_apt:x:42:65534::/nonexistent:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin

===

COMMAND: uniq

DESCRIPTION: uniq - report or omit repeated lines

USAGE: uniq [OPTION]... [INPUT [OUTPUT]]

EXECUTION EXAMPLE:
COMMAND INPUT:
uniq -c <<< $'apple\napple\nbanana'

COMMAND OUTPUT:
/bin/sh: 1: Syntax error: redirection unexpected

===

COMMAND: who

DESCRIPTION: who - show who is logged on

USAGE: who [OPTION]... [ FILE | ARG1 ARG2 ]

EXECUTION EXAMPLE:
COMMAND INPUT:
who

COMMAND OUTPUT:
vega     pts/0        2025-03-03 22:44 (130.208.133.151)

===

COMMAND: ping

DESCRIPTION: ping - send ICMP ECHO_REQUEST to network hosts

USAGE: ping [-aAbBdCDefhLnOqrRUvV46] [-c count] [-F flowlabel] [-i interval]
            [-I interface] [-l preload] [-m mark] [-M pmtudisc_option]
            [-N nodeinfo_option] [-w deadline] [-W timeout] [-p pattern]
            [-Q tos] [-s packetsize] [-S sndbuf] [-t ttl]
            [-T timestamp option] [hop...] {destination}

OPTIONS:
-4
           Use IPv4 only.

       -6
           Use IPv6 only.

       -a
           Audible ping.

       -A
           Adaptive ping. Interpacket interval adapts to round-trip time, so
           that effectively not more than one (or more, if preload is set)
           unanswered probe is present in the network. Minimal interval is
           200msec unless super-user. On networks with low RTT this mode is
           essentially equivalent to flood mode.

       -b
           Allow pinging a broadcast address.

       -B
           Do not allow ping to change source address of probes. The address
           is bound to one selected when ping starts.

       -c count
           Stop after sending count ECHO_REQUEST packets. With deadline
           option, ping waits for count ECHO_REPLY packets, until the timeout
           expires.

       -C
           Call connect() syscall on socket creation.

       -d
           Set the SO_DEBUG option on the socket being used. Essentially, this
           socket option is not used by Linux kernel.

       -e
           Set the identification field of ECHO_REQUEST. Value 0 implies using
           raw socket (not supported on ICMP datagram socket). The value of
           the field may be printed with -v option.

       -D
           Print timestamp (unix time + microseconds as in gettimeofday)
           before each line.

       -f
           Flood ping. For every ECHO_REQUEST sent a period "." is printed,
           while for every ECHO_REPLY received a backspace is printed. This
           provides a rapid display of how many packets are being dropped. If
           interval is not given, it sets interval to zero and outputs packets
           as fast as they come back or one hundred times per second,
           whichever is more. Only the super-user may use this option with
           zero interval.

       -F flow label
           IPv6 only. Allocate and set 20 bit flow label (in hex) on echo
           request packets. If value is zero, kernel allocates random flow
           label.

       -h
           Show help.

       -i interval
           Wait interval seconds between sending each packet. Real number
           allowed with dot as a decimal separator (regardless locale setup).
           The default is to wait for one second between each packet normally,
           or not to wait in flood mode. Only super-user may set interval to
           values less than 2 ms.

       -I interface
           interface is either an address, an interface name or a VRF name. If
           interface is an address, it sets source address to specified
           interface address. If interface is an interface name, it sets
           source interface to specified interface. If interface is a VRF
           name, each packet is routed using the corresponding routing table;
           in this case, the -I option can be repeated to specify a source
           address. NOTE: For IPv6, when doing ping to a link-local scope
           address, link specification (by the '%'-notation in destination, or
           by this option) can be used but it is no longer required.

       -l preload
           If preload is specified, ping sends that many packets not waiting
           for reply. Only the super-user may select preload more than 3.

       -L
           Suppress loopback of multicast packets. This flag only applies if
           the ping destination is a multicast address.

       -m mark
           use mark to tag the packets going out. This is useful for variety
           of reasons within the kernel such as using policy routing to select
           specific outbound processing.

       -M pmtudisc_opt
           Select Path MTU Discovery strategy.  pmtudisc_option may be either
           do (prohibit fragmentation, even local one), want (do PMTU
           discovery, fragment locally when packet size is large), or dont (do
           not set DF flag).

       -N nodeinfo_option
           IPv6 only. Send ICMPv6 Node Information Queries (RFC4620), instead
           of Echo Request. CAP_NET_RAW capability is required.

           help
               Show help for NI support.

           name
               Queries for Node Names.

           ipv6
               Queries for IPv6 Addresses. There are several IPv6 specific
               flags.

               ipv6-global
                   Request IPv6 global-scope addresses.

               ipv6-sitelocal
                   Request IPv6 site-local addresses.

               ipv6-linklocal
                   Request IPv6 link-local addresses.

               ipv6-all
                   Request IPv6 addresses on other interfaces.

           ipv4
               Queries for IPv4 Addresses. There is one IPv4 specific flag.

               ipv4-all
                   Request IPv4 addresses on other interfaces.

           subject-ipv6=ipv6addr
               IPv6 subject address.

           subject-ipv4=ipv4addr
               IPv4 subject address.

           subject-name=nodename
               Subject name. If it contains more than one dot, fully-qualified
               domain name is assumed.

           subject-fqdn=nodename
               Subject name. Fully-qualified domain name is always assumed.

       -n
           Numeric output only. No attempt will be made to lookup symbolic
           names for host addresses.

       -O
           Report outstanding ICMP ECHO reply before sending next packet. This
           is useful together with the timestamp -D to log output to a
           diagnostic file and search for missing answers.

       -p pattern
           You may specify up to 16 "pad" bytes to fill out the packet you
           send. This is useful for diagnosing data-dependent problems in a
           network. For example, -p ff will cause the sent packet to be filled
           with all ones.

       -q
           Quiet output. Nothing is displayed except the summary lines at
           startup time and when finished.

       -Q tos
           Set Quality of Service -related bits in ICMP datagrams.  tos can be
           decimal (ping only) or hex number.

           In RFC2474, these fields are interpreted as 8-bit Differentiated
           Services (DS), consisting of: bits 0-1 (2 lowest bits) of separate
           data, and bits 2-7 (highest 6 bits) of Differentiated Services
           Codepoint (DSCP). In RFC2481 and RFC3168, bits 0-1 are used for
           ECN.

           Historically (RFC1349, obsoleted by RFC2474), these were
           interpreted as: bit 0 (lowest bit) for reserved (currently being
           redefined as congestion control), 1-4 for Type of Service and bits
           5-7 (highest bits) for Precedence.

       -r
           Bypass the normal routing tables and send directly to a host on an
           attached interface. If the host is not on a directly-attached
           network, an error is returned. This option can be used to ping a
           local host through an interface that has no route through it
           provided the option -I is also used.

       -R
           ping only. Record route. Includes the RECORD_ROUTE option in the
           ECHO_REQUEST packet and displays the route buffer on returned
           packets. Note that the IP header is only large enough for nine such
           routes. Many hosts ignore or discard this option.

       -s packetsize
           Specifies the number of data bytes to be sent. The default is 56,
           which translates into 64 ICMP data bytes when combined with the 8
           bytes of ICMP header data.

       -S sndbuf
           Set socket sndbuf. If not specified, it is selected to buffer not
           more than one packet.

       -t ttl
           ping only. Set the IP Time to Live.

       -T timestamp option
           Set special IP timestamp options.  timestamp option may be either
           tsonly (only timestamps), tsandaddr (timestamps and addresses) or
           tsprespec host1 [host2 [host3 [host4]]] (timestamp prespecified
           hops).

       -U
           Print full user-to-user latency (the old behaviour). Normally ping
           prints network round trip time, which can be different f.e. due to
           DNS failures.

       -v
           Verbose output. Do not suppress DUP replies when pinging multicast
           address.

       -V
           Show version and exit.

       -w deadline
           Specify a timeout, in seconds, before ping exits regardless of how
           many packets have been sent or received. In this case ping does not
           stop after count packet are sent, it waits either for deadline
           expire or until count probes are answered or for some error
           notification from network.

       -W timeout
           Time to wait for a response, in seconds. The option affects only
           timeout in absence of any responses, otherwise ping waits for two
           RTTs. Real number allowed with dot as a decimal separator
           (regardless locale setup). 0 means infinite timeout.

       When using ping for fault isolation, it should first be run on the
       local host, to verify that the local network interface is up and
       running. Then, hosts and gateways further and further away should be
       "pinged". Round-trip times and packet loss statistics are computed. If
       duplicate packets are received, they are not included in the packet
       loss calculation, although the round trip time of these packets is used
       in calculating the minimum/average/maximum/mdev round-trip time
       numbers.

       Population standard deviation (mdev), essentially an average of how far
       each ping RTT is from the mean RTT. The higher mdev is, the more
       variable the RTT is (over time). With a high RTT variability, you will
       have speed issues with bulk transfers (they will take longer than is
       strictly speaking necessary, as the variability will eventually cause
       the sender to wait for ACKs) and you will have middling to poor VoIP
       quality.

       When the specified number of packets have been sent (and received) or
       if the program is terminated with a SIGINT, a brief summary is
       displayed. Shorter current statistics can be obtained without
       termination of process with signal SIGQUIT.

       If ping does not receive any reply packets at all it will exit with
       code 1. If a packet count and deadline are both specified, and fewer
       than count packets are received by the time the deadline has arrived,
       it will also exit with code 1. On other error it exits with code 2.
       Otherwise it exits with code 0. This makes it possible to use the exit
       code to see if a host is alive or not.

       This program is intended for use in network testing, measurement and
       management. Because of the load it can impose on the network, it is
       unwise to use ping during normal operations or from automated scripts.

EXECUTION EXAMPLE:
COMMAND INPUT:
ping -c 2 8.8.8.8

COMMAND OUTPUT:
PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.
64 bytes from 8.8.8.8: icmp_seq=1 ttl=118 time=12.8 ms
64 bytes from 8.8.8.8: icmp_seq=2 ttl=118 time=10.6 ms

--- 8.8.8.8 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1002ms
rtt min/avg/max/mdev = 10.630/11.723/12.817/1.093 ms

===

COMMAND: ifconfig

DESCRIPTION: ifconfig - configure a network interface

USAGE: ifconfig [-v] [-a] [-s] [interface]
       ifconfig [-v] interface [aftype] options | address ...

OPTIONS:
-a     display all interfaces which are currently  available,  even  if
              down

       -s     display a short list (like netstat -i)

       -v     be more verbose for some error conditions

       interface
              The  name  of the interface.  This is usually a driver name fol-
              lowed by a unit number, for example eth0 for the first  Ethernet
              interface.  If  your  kernel  supports alias interfaces, you can
              specify them with syntax like eth0:0  for  the  first  alias  of
              eth0.  You  can  use them to assign more addresses. To delete an
              alias interface use ifconfig eth0:0 down.  Note: for every scope
              (i.e. same net with address/netmask combination) all aliases are
              deleted, if you delete the first (primary).

       up     This flag causes the interface to be activated.  It  is  implic-
              itly  specified  if an address is assigned to the interface; you
              can suppress this behavior when using an alias interface by  ap-
              pending  an  -  to  the  alias (e.g.  eth0:0-).  It is also sup-
              pressed when using the IPv4 0.0.0.0 address as the  kernel  will
              use this to implicitly delete alias interfaces.

       down   This flag causes the driver for this interface to be shut down.

       [-]arp Enable or disable the use of the ARP protocol on this interface.

       [-]promisc
              Enable or disable the promiscuous mode of the interface.  If se-
              lected, all packets on the network will be received by  the  in-
              terface.

       [-]allmulti
              Enable  or  disable all-multicast mode.  If selected, all multi-
              cast packets on the network will be received by the interface.

       mtu N  This parameter sets the Maximum Transfer Unit (MTU) of an inter-
              face.

       dstaddr addr
              Set  the  remote  IP  address for a point-to-point link (such as
              PPP).  This keyword is now obsolete; use the pointopoint keyword
              instead.

       netmask addr
              Set the IP network mask for this interface.  This value defaults
              to the usual class A, B or C network mask (as derived  from  the
              interface IP address), but it can be set to any value.

       add addr/prefixlen
              Add an IPv6 address to an interface.

       del addr/prefixlen
              Remove an IPv6 address from an interface.

       tunnel ::aa.bb.cc.dd
              Create  a new SIT (IPv6-in-IPv4) device, tunnelling to the given
              destination.

       irq addr
              Set the interrupt line used by this device.  Not all devices can
              dynamically change their IRQ setting.

       io_addr addr
              Set the start address in I/O space for this device.

       mem_start addr
              Set  the  start  address  for shared memory used by this device.
              Only a few devices need this.

       media type
              Set the physical port or medium type to be used by  the  device.
              Not all devices can change this setting, and those that can vary
              in what values  they  support.   Typical  values  for  type  are
              10base2 (thin Ethernet), 10baseT (twisted-pair 10Mbps Ethernet),
              AUI (external transceiver) and so on.  The special  medium  type
              of  auto can be used to tell the driver to auto-sense the media.
              Again, not all drivers can do this.

       [-]broadcast [addr]
              If the address argument is given, set the protocol broadcast ad-
              dress  for  this  interface.   Otherwise,  set  (or  clear)  the
              IFF_BROADCAST flag for the interface.

       [-]pointopoint [addr]
              This keyword enables the point-to-point mode  of  an  interface,
              meaning  that  it is a direct link between two machines with no-
              body else listening on it.
              If the address argument is also given, set the protocol  address
              of  the  other  side of the link, just like the obsolete dstaddr
              keyword does.  Otherwise, set or clear the IFF_POINTOPOINT  flag
              for the interface.

       hw class address
              Set the hardware address of this interface, if the device driver
              supports this operation.  The keyword must be  followed  by  the
              name of the hardware class and the printable ASCII equivalent of
              the hardware address.  Hardware classes currently supported  in-
              clude  ether  (Ethernet),  ax25  (AMPR AX.25), ARCnet and netrom
              (AMPR NET/ROM).

       multicast
              Set the multicast flag on the interface. This  should  not  nor-
              mally  be  needed  as  the  drivers set the flag correctly them-
              selves.

       address
              The IP address to be assigned to this interface.

       txqueuelen length
              Set the length of the transmit queue of the device. It is useful
              to  set  this to small values for slower devices with a high la-
              tency (modem links, ISDN) to prevent fast  bulk  transfers  from
              disturbing interactive traffic like telnet too much.

       name newname
              Change the name of this interface to newname. The interface must
              be shut down first.

EXECUTION EXAMPLE:
COMMAND INPUT:
ifconfig

COMMAND OUTPUT:
# Error executing 'ifconfig': [Errno 2] No such file or directory: 'ifconfig'

===

COMMAND: wget

DESCRIPTION: Wget - The non-interactive network downloader.

USAGE: wget [option]... [URL]...

OPTIONS:
Option Syntax
       Since Wget uses GNU getopt to process command-line arguments, every
       option has a long form along with the short one.  Long options are more
       convenient to remember, but take time to type.  You may freely mix
       different option styles, or specify options after the command-line
       arguments.  Thus you may write:

               wget -r --tries=10 http://fly.srk.fer.hr/ -o log

       The space between the option accepting an argument and the argument may
       be omitted.  Instead of -o log you can write -olog.

       You may put several options that do not require arguments together,
       like:

               wget -drc <URL>

       This is completely equivalent to:

               wget -d -r -c <URL>

       Since the options can be specified after the arguments, you may
       terminate them with --.  So the following will try to download URL -x,
       reporting failure to log:

               wget -o log -- -x

       The options that accept comma-separated lists all respect the
       convention that specifying an empty list clears its value.  This can be
       useful to clear the .wgetrc settings.  For instance, if your .wgetrc
       sets "exclude_directories" to /cgi-bin, the following example will
       first reset it, and then set it to exclude /~nobody and /~somebody.
       You can also clear the lists in .wgetrc.

               wget -X "" -X /~nobody,/~somebody

       Most options that do not accept arguments are boolean options, so named
       because their state can be captured with a yes-or-no ("boolean")
       variable.  For example, --follow-ftp tells Wget to follow FTP links
       from HTML files and, on the other hand, --no-glob tells it not to
       perform file globbing on FTP URLs.  A boolean option is either
       affirmative or negative (beginning with --no).  All such options share
       several properties.

       Unless stated otherwise, it is assumed that the default behavior is the
       opposite of what the option accomplishes.  For example, the documented
       existence of --follow-ftp assumes that the default is to not follow FTP
       links from HTML pages.

       Affirmative options can be negated by prepending the --no- to the
       option name; negative options can be negated by omitting the --no-
       prefix.  This might seem superfluous---if the default for an
       affirmative option is to not do something, then why provide a way to
       explicitly turn it off?  But the startup file may in fact change the
       default.  For instance, using "follow_ftp = on" in .wgetrc makes Wget
       follow FTP links by default, and using --no-follow-ftp is the only way
       to restore the factory default from the command line.

   Basic Startup Options
       -V
       --version
           Display the version of Wget.

       -h
       --help
           Print a help message describing all of Wget's command-line options.

       -b
       --background
           Go to background immediately after startup.  If no output file is
           specified via the -o, output is redirected to wget-log.

       -e command
       --execute command
           Execute command as if it were a part of .wgetrc.  A command thus
           invoked will be executed after the commands in .wgetrc, thus taking
           precedence over them.  If you need to specify more than one wgetrc
           command, use multiple instances of -e.

   Logging and Input File Options
       -o logfile
       --output-file=logfile
           Log all messages to logfile.  The messages are normally reported to
           standard error.

       -a logfile
       --append-output=logfile
           Append to logfile.  This is the same as -o, only it appends to
           logfile instead of overwriting the old log file.  If logfile does
           not exist, a new file is created.

       -d
       --debug
           Turn on debug output, meaning various information important to the
           developers of Wget if it does not work properly.  Your system
           administrator may have chosen to compile Wget without debug
           support, in which case -d will not work.  Please note that
           compiling with debug support is always safe---Wget compiled with
           the debug support will not print any debug info unless requested
           with -d.

       -q
       --quiet
           Turn off Wget's output.

       -v
       --verbose
           Turn on verbose output, with all the available data.  The default
           output is verbose.

       -nv
       --no-verbose
           Turn off verbose without being completely quiet (use -q for that),
           which means that error messages and basic information still get
           printed.

       --report-speed=type
           Output bandwidth as type.  The only accepted value is bits.

       -i file
       --input-file=file
           Read URLs from a local or external file.  If - is specified as
           file, URLs are read from the standard input.  (Use ./- to read from
           a file literally named -.)

           If this function is used, no URLs need be present on the command
           line.  If there are URLs both on the command line and in an input
           file, those on the command lines will be the first ones to be
           retrieved.  If --force-html is not specified, then file should
           consist of a series of URLs, one per line.

           However, if you specify --force-html, the document will be regarded
           as html.  In that case you may have problems with relative links,
           which you can solve either by adding "<base href="url">" to the
           documents or by specifying --base=url on the command line.

           If the file is an external one, the document will be automatically
           treated as html if the Content-Type matches text/html.
           Furthermore, the file's location will be implicitly used as base
           href if none was specified.

       --input-metalink=file
           Downloads files covered in local Metalink file. Metalink version 3
           and 4 are supported.

       --keep-badhash
           Keeps downloaded Metalink's files with a bad hash. It appends
           .badhash to the name of Metalink's files which have a checksum
           mismatch, except without overwriting existing files.

       --metalink-over-http
           Issues HTTP HEAD request instead of GET and extracts Metalink
           metadata from response headers. Then it switches to Metalink
           download.  If no valid Metalink metadata is found, it falls back to
           ordinary HTTP download.  Enables Content-Type:
           application/metalink4+xml files download/processing.

       --metalink-index=number
           Set the Metalink application/metalink4+xml metaurl ordinal NUMBER.
           From 1 to the total number of "application/metalink4+xml"
           available.  Specify 0 or inf to choose the first good one.
           Metaurls, such as those from a --metalink-over-http, may have been
           sorted by priority key's value; keep this in mind to choose the
           right NUMBER.

       --preferred-location
           Set preferred location for Metalink resources. This has effect if
           multiple resources with same priority are available.

       --xattr
           Enable use of file system's extended attributes to save the
           original URL and the Referer HTTP header value if used.

           Be aware that the URL might contain private information like access
           tokens or credentials.

       -F
       --force-html
           When input is read from a file, force it to be treated as an HTML
           file.  This enables you to retrieve relative links from existing
           HTML files on your local disk, by adding "<base href="url">" to
           HTML, or using the --base command-line option.

       -B URL
       --base=URL
           Resolves relative links using URL as the point of reference, when
           reading links from an HTML file specified via the -i/--input-file
           option (together with --force-html, or when the input file was
           fetched remotely from a server describing it as HTML). This is
           equivalent to the presence of a "BASE" tag in the HTML input file,
           with URL as the value for the "href" attribute.

           For instance, if you specify http://foo/bar/a.html for URL, and
           Wget reads ../baz/b.html from the input file, it would be resolved
           to http://foo/baz/b.html.

       --config=FILE
           Specify the location of a startup file you wish to use instead of
           the default one(s). Use --no-config to disable reading of config
           files.  If both --config and --no-config are given, --no-config is
           ignored.

       --rejected-log=logfile
           Logs all URL rejections to logfile as comma separated values.  The
           values include the reason of rejection, the URL and the parent URL
           it was found in.

   Download Options
       --bind-address=ADDRESS
           When making client TCP/IP connections, bind to ADDRESS on the local
           machine.  ADDRESS may be specified as a hostname or IP address.
           This option can be useful if your machine is bound to multiple IPs.

       --bind-dns-address=ADDRESS
           [libcares only] This address overrides the route for DNS requests.
           If you ever need to circumvent the standard settings from
           /etc/resolv.conf, this option together with --dns-servers is your
           friend.  ADDRESS must be specified either as IPv4 or IPv6 address.
           Wget needs to be built with libcares for this option to be
           available.

       --dns-servers=ADDRESSES
           [libcares only] The given address(es) override the standard
           nameserver addresses,  e.g. as configured in /etc/resolv.conf.
           ADDRESSES may be specified either as IPv4 or IPv6 addresses, comma-
           separated.  Wget needs to be built with libcares for this option to
           be available.

       -t number
       --tries=number
           Set number of tries to number. Specify 0 or inf for infinite
           retrying.  The default is to retry 20 times, with the exception of
           fatal errors like "connection refused" or "not found" (404), which
           are not retried.

       -O file
       --output-document=file
           The documents will not be written to the appropriate files, but all
           will be concatenated together and written to file.  If - is used as
           file, documents will be printed to standard output, disabling link
           conversion.  (Use ./- to print to a file literally named -.)

           Use of -O is not intended to mean simply "use the name file instead
           of the one in the URL;" rather, it is analogous to shell
           redirection: wget -O file http://foo is intended to work like wget
           -O - http://foo > file; file will be truncated immediately, and all
           downloaded content will be written there.

           For this reason, -N (for timestamp-checking) is not supported in
           combination with -O: since file is always newly created, it will
           always have a very new timestamp. A warning will be issued if this
           combination is used.

           Similarly, using -r or -p with -O may not work as you expect: Wget
           won't just download the first file to file and then download the
           rest to their normal names: all downloaded content will be placed
           in file. This was disabled in version 1.11, but has been reinstated
           (with a warning) in 1.11.2, as there are some cases where this
           behavior can actually have some use.

           A combination with -nc is only accepted if the given output file
           does not exist.

           Note that a combination with -k is only permitted when downloading
           a single document, as in that case it will just convert all
           relative URIs to external ones; -k makes no sense for multiple URIs
           when they're all being downloaded to a single file; -k can be used
           only when the output is a regular file.

       -nc
       --no-clobber
           If a file is downloaded more than once in the same directory,
           Wget's behavior depends on a few options, including -nc.  In
           certain cases, the local file will be clobbered, or overwritten,
           upon repeated download.  In other cases it will be preserved.

           When running Wget without -N, -nc, -r, or -p, downloading the same
           file in the same directory will result in the original copy of file
           being preserved and the second copy being named file.1.  If that
           file is downloaded yet again, the third copy will be named file.2,
           and so on.  (This is also the behavior with -nd, even if -r or -p
           are in effect.)  When -nc is specified, this behavior is
           suppressed, and Wget will refuse to download newer copies of file.
           Therefore, ""no-clobber"" is actually a misnomer in this
           mode---it's not clobbering that's prevented (as the numeric
           suffixes were already preventing clobbering), but rather the
           multiple version saving that's prevented.

           When running Wget with -r or -p, but without -N, -nd, or -nc, re-
           downloading a file will result in the new copy simply overwriting
           the old.  Adding -nc will prevent this behavior, instead causing
           the original version to be preserved and any newer copies on the
           server to be ignored.

           When running Wget with -N, with or without -r or -p, the decision
           as to whether or not to download a newer copy of a file depends on
           the local and remote timestamp and size of the file.  -nc may not
           be specified at the same time as -N.

           A combination with -O/--output-document is only accepted if the
           given output file does not exist.

           Note that when -nc is specified, files with the suffixes .html or
           .htm will be loaded from the local disk and parsed as if they had
           been retrieved from the Web.

       --backups=backups
           Before (over)writing a file, back up an existing file by adding a
           .1 suffix (_1 on VMS) to the file name.  Such backup files are
           rotated to .2, .3, and so on, up to backups (and lost beyond that).

       --no-netrc
           Do not try to obtain credentials from .netrc file. By default
           .netrc file is searched for credentials in case none have been
           passed on command line and authentication is required.

       -c
       --continue
           Continue getting a partially-downloaded file.  This is useful when
           you want to finish up a download started by a previous instance of
           Wget, or by another program.  For instance:

                   wget -c ftp://sunsite.doc.ic.ac.uk/ls-lR.Z

           If there is a file named ls-lR.Z in the current directory, Wget
           will assume that it is the first portion of the remote file, and
           will ask the server to continue the retrieval from an offset equal
           to the length of the local file.

           Note that you don't need to specify this option if you just want
           the current invocation of Wget to retry downloading a file should
           the connection be lost midway through.  This is the default
           behavior.  -c only affects resumption of downloads started prior to
           this invocation of Wget, and whose local files are still sitting
           around.

           Without -c, the previous example would just download the remote
           file to ls-lR.Z.1, leaving the truncated ls-lR.Z file alone.

           If you use -c on a non-empty file, and the server does not support
           continued downloading, Wget will restart the download from scratch
           and overwrite the existing file entirely.

           Beginning with Wget 1.7, if you use -c on a file which is of equal
           size as the one on the server, Wget will refuse to download the
           file and print an explanatory message.  The same happens when the
           file is smaller on the server than locally (presumably because it
           was changed on the server since your last download
           attempt)---because "continuing" is not meaningful, no download
           occurs.

           On the other side of the coin, while using -c, any file that's
           bigger on the server than locally will be considered an incomplete
           download and only "(length(remote) - length(local))" bytes will be
           downloaded and tacked onto the end of the local file.  This
           behavior can be desirable in certain cases---for instance, you can
           use wget -c to download just the new portion that's been appended
           to a data collection or log file.

           However, if the file is bigger on the server because it's been
           changed, as opposed to just appended to, you'll end up with a
           garbled file.  Wget has no way of verifying that the local file is
           really a valid prefix of the remote file.  You need to be
           especially careful of this when using -c in conjunction with -r,
           since every file will be considered as an "incomplete download"
           candidate.

           Another instance where you'll get a garbled file if you try to use
           -c is if you have a lame HTTP proxy that inserts a "transfer
           interrupted" string into the local file.  In the future a
           "rollback" option may be added to deal with this case.

           Note that -c only works with FTP servers and with HTTP servers that
           support the "Range" header.

       --start-pos=OFFSET
           Start downloading at zero-based position OFFSET.  Offset may be
           expressed in bytes, kilobytes with the `k' suffix, or megabytes
           with the `m' suffix, etc.

           --start-pos has higher precedence over --continue.  When
           --start-pos and --continue are both specified, wget will emit a
           warning then proceed as if --continue was absent.

           Server support for continued download is required, otherwise
           --start-pos cannot help.  See -c for details.

       --progress=type
           Select the type of the progress indicator you wish to use.  Legal
           indicators are "dot" and "bar".

           The "bar" indicator is used by default.  It draws an ASCII progress
           bar graphics (a.k.a "thermometer" display) indicating the status of
           retrieval.  If the output is not a TTY, the "dot" bar will be used
           by default.

           Use --progress=dot to switch to the "dot" display.  It traces the
           retrieval by printing dots on the screen, each dot representing a
           fixed amount of downloaded data.

           The progress type can also take one or more parameters.  The
           parameters vary based on the type selected.  Parameters to type are
           passed by appending them to the type sperated by a colon (:) like
           this: --progress=type:parameter1:parameter2.

           When using the dotted retrieval, you may set the style by
           specifying the type as dot:style.  Different styles assign
           different meaning to one dot.  With the "default" style each dot
           represents 1K, there are ten dots in a cluster and 50 dots in a
           line.  The "binary" style has a more "computer"-like
           orientation---8K dots, 16-dots clusters and 48 dots per line (which
           makes for 384K lines).  The "mega" style is suitable for
           downloading large files---each dot represents 64K retrieved, there
           are eight dots in a cluster, and 48 dots on each line (so each line
           contains 3M).  If "mega" is not enough then you can use the "giga"
           style---each dot represents 1M retrieved, there are eight dots in a
           cluster, and 32 dots on each line (so each line contains 32M).

           With --progress=bar, there are currently two possible parameters,
           force and noscroll.

           When the output is not a TTY, the progress bar always falls back to
           "dot", even if --progress=bar was passed to Wget during invocation.
           This behaviour can be overridden and the "bar" output forced by
           using the "force" parameter as --progress=bar:force.

           By default, the bar style progress bar scroll the name of the file
           from left to right for the file being downloaded if the filename
           exceeds the maximum length allotted for its display.  In certain
           cases, such as with --progress=bar:force, one may not want the
           scrolling filename in the progress bar.  By passing the "noscroll"
           parameter, Wget can be forced to display as much of the filename as
           possible without scrolling through it.

           Note that you can set the default style using the "progress"
           command in .wgetrc.  That setting may be overridden from the
           command line.  For example, to force the bar output without
           scrolling, use --progress=bar:force:noscroll.

       --show-progress
           Force wget to display the progress bar in any verbosity.

           By default, wget only displays the progress bar in verbose mode.
           One may however, want wget to display the progress bar on screen in
           conjunction with any other verbosity modes like --no-verbose or
           --quiet.  This is often a desired a property when invoking wget to
           download several small/large files.  In such a case, wget could
           simply be invoked with this parameter to get a much cleaner output
           on the screen.

           This option will also force the progress bar to be printed to
           stderr when used alongside the --output-file option.

       -N
       --timestamping
           Turn on time-stamping.

       --no-if-modified-since
           Do not send If-Modified-Since header in -N mode. Send preliminary
           HEAD request instead. This has only effect in -N mode.

       --no-use-server-timestamps
           Don't set the local file's timestamp by the one on the server.

           By default, when a file is downloaded, its timestamps are set to
           match those from the remote file. This allows the use of
           --timestamping on subsequent invocations of wget. However, it is
           sometimes useful to base the local file's timestamp on when it was
           actually downloaded; for that purpose, the
           --no-use-server-timestamps option has been provided.

       -S
       --server-response
           Print the headers sent by HTTP servers and responses sent by FTP
           servers.

       --spider
           When invoked with this option, Wget will behave as a Web spider,
           which means that it will not download the pages, just check that
           they are there.  For example, you can use Wget to check your
           bookmarks:

                   wget --spider --force-html -i bookmarks.html

           This feature needs much more work for Wget to get close to the
           functionality of real web spiders.

       -T seconds
       --timeout=seconds
           Set the network timeout to seconds seconds.  This is equivalent to
           specifying --dns-timeout, --connect-timeout, and --read-timeout,
           all at the same time.

           When interacting with the network, Wget can check for timeout and
           abort the operation if it takes too long.  This prevents anomalies
           like hanging reads and infinite connects.  The only timeout enabled
           by default is a 900-second read timeout.  Setting a timeout to 0
           disables it altogether.  Unless you know what you are doing, it is
           best not to change the default timeout settings.

           All timeout-related options accept decimal values, as well as
           subsecond values.  For example, 0.1 seconds is a legal (though
           unwise) choice of timeout.  Subsecond timeouts are useful for
           checking server response times or for testing network latency.

       --dns-timeout=seconds
           Set the DNS lookup timeout to seconds seconds.  DNS lookups that
           don't complete within the specified time will fail.  By default,
           there is no timeout on DNS lookups, other than that implemented by
           system libraries.

       --connect-timeout=seconds
           Set the connect timeout to seconds seconds.  TCP connections that
           take longer to establish will be aborted.  By default, there is no
           connect timeout, other than that implemented by system libraries.

       --read-timeout=seconds
           Set the read (and write) timeout to seconds seconds.  The "time" of
           this timeout refers to idle time: if, at any point in the download,
           no data is received for more than the specified number of seconds,
           reading fails and the download is restarted.  This option does not
           directly affect the duration of the entire download.

           Of course, the remote server may choose to terminate the connection
           sooner than this option requires.  The default read timeout is 900
           seconds.

       --limit-rate=amount
           Limit the download speed to amount bytes per second.  Amount may be
           expressed in bytes, kilobytes with the k suffix, or megabytes with
           the m suffix.  For example, --limit-rate=20k will limit the
           retrieval rate to 20KB/s.  This is useful when, for whatever
           reason, you don't want Wget to consume the entire available
           bandwidth.

           This option allows the use of decimal numbers, usually in
           conjunction with power suffixes; for example, --limit-rate=2.5k is
           a legal value.

           Note that Wget implements the limiting by sleeping the appropriate
           amount of time after a network read that took less time than
           specified by the rate.  Eventually this strategy causes the TCP
           transfer to slow down to approximately the specified rate.
           However, it may take some time for this balance to be achieved, so
           don't be surprised if limiting the rate doesn't work well with very
           small files.

       -w seconds
       --wait=seconds
           Wait the specified number of seconds between the retrievals.  Use
           of this option is recommended, as it lightens the server load by
           making the requests less frequent.  Instead of in seconds, the time
           can be specified in minutes using the "m" suffix, in hours using
           "h" suffix, or in days using "d" suffix.

           Specifying a large value for this option is useful if the network
           or the destination host is down, so that Wget can wait long enough
           to reasonably expect the network error to be fixed before the
           retry.  The waiting interval specified by this function is
           influenced by "--random-wait", which see.

       --waitretry=seconds
           If you don't want Wget to wait between every retrieval, but only
           between retries of failed downloads, you can use this option.  Wget
           will use linear backoff, waiting 1 second after the first failure
           on a given file, then waiting 2 seconds after the second failure on
           that file, up to the maximum number of seconds you specify.

           By default, Wget will assume a value of 10 seconds.

       --random-wait
           Some web sites may perform log analysis to identify retrieval
           programs such as Wget by looking for statistically significant
           similarities in the time between requests. This option causes the
           time between requests to vary between 0.5 and 1.5 * wait seconds,
           where wait was specified using the --wait option, in order to mask
           Wget's presence from such analysis.

           A 2001 article in a publication devoted to development on a popular
           consumer platform provided code to perform this analysis on the
           fly.  Its author suggested blocking at the class C address level to
           ensure automated retrieval programs were blocked despite changing
           DHCP-supplied addresses.

           The --random-wait option was inspired by this ill-advised
           recommendation to block many unrelated users from a web site due to
           the actions of one.

       --no-proxy
           Don't use proxies, even if the appropriate *_proxy environment
           variable is defined.

       -Q quota
       --quota=quota
           Specify download quota for automatic retrievals.  The value can be
           specified in bytes (default), kilobytes (with k suffix), or
           megabytes (with m suffix).

           Note that quota will never affect downloading a single file.  So if
           you specify wget -Q10k https://example.com/ls-lR.gz, all of the
           ls-lR.gz will be downloaded.  The same goes even when several URLs
           are specified on the command-line.  The quota is checked only at
           the end of each downloaded file, so it will never result in a
           partially downloaded file. Thus you may safely type wget -Q2m -i
           sites---download will be aborted after the file that exhausts the
           quota is completely downloaded.

           Setting quota to 0 or to inf unlimits the download quota.

       --no-dns-cache
           Turn off caching of DNS lookups.  Normally, Wget remembers the IP
           addresses it looked up from DNS so it doesn't have to repeatedly
           contact the DNS server for the same (typically small) set of hosts
           it retrieves from.  This cache exists in memory only; a new Wget
           run will contact DNS again.

           However, it has been reported that in some situations it is not
           desirable to cache host names, even for the duration of a short-
           running application like Wget.  With this option Wget issues a new
           DNS lookup (more precisely, a new call to "gethostbyname" or
           "getaddrinfo") each time it makes a new connection.  Please note
           that this option will not affect caching that might be performed by
           the resolving library or by an external caching layer, such as
           NSCD.

           If you don't understand exactly what this option does, you probably
           won't need it.

       --restrict-file-names=modes
           Change which characters found in remote URLs must be escaped during
           generation of local filenames.  Characters that are restricted by
           this option are escaped, i.e. replaced with %HH, where HH is the
           hexadecimal number that corresponds to the restricted character.
           This option may also be used to force all alphabetical cases to be
           either lower- or uppercase.

           By default, Wget escapes the characters that are not valid or safe
           as part of file names on your operating system, as well as control
           characters that are typically unprintable.  This option is useful
           for changing these defaults, perhaps because you are downloading to
           a non-native partition, or because you want to disable escaping of
           the control characters, or you want to further restrict characters
           to only those in the ASCII range of values.

           The modes are a comma-separated set of text values. The acceptable
           values are unix, windows, nocontrol, ascii, lowercase, and
           uppercase. The values unix and windows are mutually exclusive (one
           will override the other), as are lowercase and uppercase. Those
           last are special cases, as they do not change the set of characters
           that would be escaped, but rather force local file paths to be
           converted either to lower- or uppercase.

           When "unix" is specified, Wget escapes the character / and the
           control characters in the ranges 0--31 and 128--159.  This is the
           default on Unix-like operating systems.

           When "windows" is given, Wget escapes the characters \, |, /, :, ?,
           ", *, <, >, and the control characters in the ranges 0--31 and
           128--159.  In addition to this, Wget in Windows mode uses + instead
           of : to separate host and port in local file names, and uses @
           instead of ? to separate the query portion of the file name from
           the rest.  Therefore, a URL that would be saved as
           www.xemacs.org:4300/search.pl?input=blah in Unix mode would be
           saved as www.xemacs.org+4300/search.pl@input=blah in Windows mode.
           This mode is the default on Windows.

           If you specify nocontrol, then the escaping of the control
           characters is also switched off. This option may make sense when
           you are downloading URLs whose names contain UTF-8 characters, on a
           system which can save and display filenames in UTF-8 (some possible
           byte values used in UTF-8 byte sequences fall in the range of
           values designated by Wget as "controls").

           The ascii mode is used to specify that any bytes whose values are
           outside the range of ASCII characters (that is, greater than 127)
           shall be escaped. This can be useful when saving filenames whose
           encoding does not match the one used locally.

       -4
       --inet4-only
       -6
       --inet6-only
           Force connecting to IPv4 or IPv6 addresses.  With --inet4-only or
           -4, Wget will only connect to IPv4 hosts, ignoring AAAA records in
           DNS, and refusing to connect to IPv6 addresses specified in URLs.
           Conversely, with --inet6-only or -6, Wget will only connect to IPv6
           hosts and ignore A records and IPv4 addresses.

           Neither options should be needed normally.  By default, an
           IPv6-aware Wget will use the address family specified by the host's
           DNS record.  If the DNS responds with both IPv4 and IPv6 addresses,
           Wget will try them in sequence until it finds one it can connect
           to.  (Also see "--prefer-family" option described below.)

           These options can be used to deliberately force the use of IPv4 or
           IPv6 address families on dual family systems, usually to aid
           debugging or to deal with broken network configuration.  Only one
           of --inet6-only and --inet4-only may be specified at the same time.
           Neither option is available in Wget compiled without IPv6 support.

       --prefer-family=none/IPv4/IPv6
           When given a choice of several addresses, connect to the addresses
           with specified address family first.  The address order returned by
           DNS is used without change by default.

           This avoids spurious errors and connect attempts when accessing
           hosts that resolve to both IPv6 and IPv4 addresses from IPv4
           networks.  For example, www.kame.net resolves to
           2001:200:0:8002:203:47ff:fea5:3085 and to 203.178.141.194.  When
           the preferred family is "IPv4", the IPv4 address is used first;
           when the preferred family is "IPv6", the IPv6 address is used
           first; if the specified value is "none", the address order returned
           by DNS is used without change.

           Unlike -4 and -6, this option doesn't inhibit access to any address
           family, it only changes the order in which the addresses are
           accessed.  Also note that the reordering performed by this option
           is stable---it doesn't affect order of addresses of the same
           family.  That is, the relative order of all IPv4 addresses and of
           all IPv6 addresses remains intact in all cases.

       --retry-connrefused
           Consider "connection refused" a transient error and try again.
           Normally Wget gives up on a URL when it is unable to connect to the
           site because failure to connect is taken as a sign that the server
           is not running at all and that retries would not help.  This option
           is for mirroring unreliable sites whose servers tend to disappear
           for short periods of time.

       --user=user
       --password=password
           Specify the username user and password password for both FTP and
           HTTP file retrieval.  These parameters can be overridden using the
           --ftp-user and --ftp-password options for FTP connections and the
           --http-user and --http-password options for HTTP connections.

       --ask-password
           Prompt for a password for each connection established. Cannot be
           specified when --password is being used, because they are mutually
           exclusive.

       --use-askpass=command
           Prompt for a user and password using the specified command.  If no
           command is specified then the command in the environment variable
           WGET_ASKPASS is used.  If WGET_ASKPASS is not set then the command
           in the environment variable SSH_ASKPASS is used.

           You can set the default command for use-askpass in the .wgetrc.
           That setting may be overridden from the command line.

       --no-iri
           Turn off internationalized URI (IRI) support. Use --iri to turn it
           on. IRI support is activated by default.

           You can set the default state of IRI support using the "iri"
           command in .wgetrc. That setting may be overridden from the command
           line.

       --local-encoding=encoding
           Force Wget to use encoding as the default system encoding. That
           affects how Wget converts URLs specified as arguments from locale
           to UTF-8 for IRI support.

           Wget use the function "nl_langinfo()" and then the "CHARSET"
           environment variable to get the locale. If it fails, ASCII is used.

           You can set the default local encoding using the "local_encoding"
           command in .wgetrc. That setting may be overridden from the command
           line.

       --remote-encoding=encoding
           Force Wget to use encoding as the default remote server encoding.
           That affects how Wget converts URIs found in files from remote
           encoding to UTF-8 during a recursive fetch. This options is only
           useful for IRI support, for the interpretation of non-ASCII
           characters.

           For HTTP, remote encoding can be found in HTTP "Content-Type"
           header and in HTML "Content-Type http-equiv" meta tag.

           You can set the default encoding using the "remoteencoding" command
           in .wgetrc. That setting may be overridden from the command line.

       --unlink
           Force Wget to unlink file instead of clobbering existing file. This
           option is useful for downloading to the directory with hardlinks.

   Directory Options
       -nd
       --no-directories
           Do not create a hierarchy of directories when retrieving
           recursively.  With this option turned on, all files will get saved
           to the current directory, without clobbering (if a name shows up
           more than once, the filenames will get extensions .n).

       -x
       --force-directories
           The opposite of -nd---create a hierarchy of directories, even if
           one would not have been created otherwise.  E.g. wget -x
           http://fly.srk.fer.hr/robots.txt will save the downloaded file to
           fly.srk.fer.hr/robots.txt.

       -nH
       --no-host-directories
           Disable generation of host-prefixed directories.  By default,
           invoking Wget with -r http://fly.srk.fer.hr/ will create a
           structure of directories beginning with fly.srk.fer.hr/.  This
           option disables such behavior.

       --protocol-directories
           Use the protocol name as a directory component of local file names.
           For example, with this option, wget -r http://host will save to
           http/host/... rather than just to host/....

       --cut-dirs=number
           Ignore number directory components.  This is useful for getting a
           fine-grained control over the directory where recursive retrieval
           will be saved.

           Take, for example, the directory at
           ftp://ftp.xemacs.org/pub/xemacs/.  If you retrieve it with -r, it
           will be saved locally under ftp.xemacs.org/pub/xemacs/.  While the
           -nH option can remove the ftp.xemacs.org/ part, you are still stuck
           with pub/xemacs.  This is where --cut-dirs comes in handy; it makes
           Wget not "see" number remote directory components.  Here are
           several examples of how --cut-dirs option works.

                   No options        -> ftp.xemacs.org/pub/xemacs/
                   -nH               -> pub/xemacs/
                   -nH --cut-dirs=1  -> xemacs/
                   -nH --cut-dirs=2  -> .

                   --cut-dirs=1      -> ftp.xemacs.org/xemacs/
                   ...

           If you just want to get rid of the directory structure, this option
           is similar to a combination of -nd and -P.  However, unlike -nd,
           --cut-dirs does not lose with subdirectories---for instance, with
           -nH --cut-dirs=1, a beta/ subdirectory will be placed to
           xemacs/beta, as one would expect.

       -P prefix
       --directory-prefix=prefix
           Set directory prefix to prefix.  The directory prefix is the
           directory where all other files and subdirectories will be saved
           to, i.e. the top of the retrieval tree.  The default is . (the
           current directory).

   HTTP Options
       --default-page=name
           Use name as the default file name when it isn't known (i.e., for
           URLs that end in a slash), instead of index.html.

       -E
       --adjust-extension
           If a file of type application/xhtml+xml or text/html is downloaded
           and the URL does not end with the regexp \.[Hh][Tt][Mm][Ll]?, this
           option will cause the suffix .html to be appended to the local
           filename.  This is useful, for instance, when you're mirroring a
           remote site that uses .asp pages, but you want the mirrored pages
           to be viewable on your stock Apache server.  Another good use for
           this is when you're downloading CGI-generated materials.  A URL
           like http://site.com/article.cgi?25 will be saved as
           article.cgi?25.html.

           Note that filenames changed in this way will be re-downloaded every
           time you re-mirror a site, because Wget can't tell that the local
           X.html file corresponds to remote URL X (since it doesn't yet know
           that the URL produces output of type text/html or
           application/xhtml+xml.

           As of version 1.12, Wget will also ensure that any downloaded files
           of type text/css end in the suffix .css, and the option was renamed
           from --html-extension, to better reflect its new behavior. The old
           option name is still acceptable, but should now be considered
           deprecated.

           As of version 1.19.2, Wget will also ensure that any downloaded
           files with a "Content-Encoding" of br, compress, deflate or gzip
           end in the suffix .br, .Z, .zlib and .gz respectively.

           At some point in the future, this option may well be expanded to
           include suffixes for other types of content, including content
           types that are not parsed by Wget.

       --http-user=user
       --http-password=password
           Specify the username user and password password on an HTTP server.
           According to the type of the challenge, Wget will encode them using
           either the "basic" (insecure), the "digest", or the Windows "NTLM"
           authentication scheme.

           Another way to specify username and password is in the URL itself.
           Either method reveals your password to anyone who bothers to run
           "ps".  To prevent the passwords from being seen, use the
           --use-askpass or store them in .wgetrc or .netrc, and make sure to
           protect those files from other users with "chmod".  If the
           passwords are really important, do not leave them lying in those
           files either---edit the files and delete them after Wget has
           started the download.

       --no-http-keep-alive
           Turn off the "keep-alive" feature for HTTP downloads.  Normally,
           Wget asks the server to keep the connection open so that, when you
           download more than one document from the same server, they get
           transferred over the same TCP connection.  This saves time and at
           the same time reduces the load on the server.

           This option is useful when, for some reason, persistent (keep-
           alive) connections don't work for you, for example due to a server
           bug or due to the inability of server-side scripts to cope with the
           connections.

       --no-cache
           Disable server-side cache.  In this case, Wget will send the remote
           server appropriate directives (Cache-Control: no-cache and Pragma:
           no-cache) to get the file from the remote service, rather than
           returning the cached version. This is especially useful for
           retrieving and flushing out-of-date documents on proxy servers.

           Caching is allowed by default.

       --no-cookies
           Disable the use of cookies.  Cookies are a mechanism for
           maintaining server-side state.  The server sends the client a
           cookie using the "Set-Cookie" header, and the client responds with
           the same cookie upon further requests.  Since cookies allow the
           server owners to keep track of visitors and for sites to exchange
           this information, some consider them a breach of privacy.  The
           default is to use cookies; however, storing cookies is not on by
           default.

       --load-cookies file
           Load cookies from file before the first HTTP retrieval.  file is a
           textual file in the format originally used by Netscape's
           cookies.txt file.

           You will typically use this option when mirroring sites that
           require that you be logged in to access some or all of their
           content.  The login process typically works by the web server
           issuing an HTTP cookie upon receiving and verifying your
           credentials.  The cookie is then resent by the browser when
           accessing that part of the site, and so proves your identity.

           Mirroring such a site requires Wget to send the same cookies your
           browser sends when communicating with the site.  This is achieved
           by --load-cookies---simply point Wget to the location of the
           cookies.txt file, and it will send the same cookies your browser
           would send in the same situation.  Different browsers keep textual
           cookie files in different locations:

           "Netscape 4.x."
               The cookies are in ~/.netscape/cookies.txt.

           "Mozilla and Netscape 6.x."
               Mozilla's cookie file is also named cookies.txt, located
               somewhere under ~/.mozilla, in the directory of your profile.
               The full path usually ends up looking somewhat like
               ~/.mozilla/default/some-weird-string/cookies.txt.

           "Internet Explorer."
               You can produce a cookie file Wget can use by using the File
               menu, Import and Export, Export Cookies.  This has been tested
               with Internet Explorer 5; it is not guaranteed to work with
               earlier versions.

           "Other browsers."
               If you are using a different browser to create your cookies,
               --load-cookies will only work if you can locate or produce a
               cookie file in the Netscape format that Wget expects.

           If you cannot use --load-cookies, there might still be an
           alternative.  If your browser supports a "cookie manager", you can
           use it to view the cookies used when accessing the site you're
           mirroring.  Write down the name and value of the cookie, and
           manually instruct Wget to send those cookies, bypassing the
           "official" cookie support:

                   wget --no-cookies --header "Cookie: <name>=<value>"

       --save-cookies file
           Save cookies to file before exiting.  This will not save cookies
           that have expired or that have no expiry time (so-called "session
           cookies"), but also see --keep-session-cookies.

       --keep-session-cookies
           When specified, causes --save-cookies to also save session cookies.
           Session cookies are normally not saved because they are meant to be
           kept in memory and forgotten when you exit the browser.  Saving
           them is useful on sites that require you to log in or to visit the
           home page before you can access some pages.  With this option,
           multiple Wget runs are considered a single browser session as far
           as the site is concerned.

           Since the cookie file format does not normally carry session
           cookies, Wget marks them with an expiry timestamp of 0.  Wget's
           --load-cookies recognizes those as session cookies, but it might
           confuse other browsers.  Also note that cookies so loaded will be
           treated as other session cookies, which means that if you want
           --save-cookies to preserve them again, you must use
           --keep-session-cookies again.

       --ignore-length
           Unfortunately, some HTTP servers (CGI programs, to be more precise)
           send out bogus "Content-Length" headers, which makes Wget go wild,
           as it thinks not all the document was retrieved.  You can spot this
           syndrome if Wget retries getting the same document again and again,
           each time claiming that the (otherwise normal) connection has
           closed on the very same byte.

           With this option, Wget will ignore the "Content-Length" header---as
           if it never existed.

       --header=header-line
           Send header-line along with the rest of the headers in each HTTP
           request.  The supplied header is sent as-is, which means it must
           contain name and value separated by colon, and must not contain
           newlines.

           You may define more than one additional header by specifying
           --header more than once.

                   wget --header='Accept-Charset: iso-8859-2' \
                        --header='Accept-Language: hr'        \
                          http://fly.srk.fer.hr/

           Specification of an empty string as the header value will clear all
           previous user-defined headers.

           As of Wget 1.10, this option can be used to override headers
           otherwise generated automatically.  This example instructs Wget to
           connect to localhost, but to specify foo.bar in the "Host" header:

                   wget --header="Host: foo.bar" http://localhost/

           In versions of Wget prior to 1.10 such use of --header caused
           sending of duplicate headers.

       --compression=type
           Choose the type of compression to be used.  Legal values are auto,
           gzip and none.

           If auto or gzip are specified, Wget asks the server to compress the
           file using the gzip compression format. If the server compresses
           the file and responds with the "Content-Encoding" header field set
           appropriately, the file will be decompressed automatically.

           If none is specified, wget will not ask the server to compress the
           file and will not decompress any server responses. This is the
           default.

           Compression support is currently experimental. In case it is turned
           on, please report any bugs to "bug-wget@gnu.org".

       --max-redirect=number
           Specifies the maximum number of redirections to follow for a
           resource.  The default is 20, which is usually far more than
           necessary. However, on those occasions where you want to allow more
           (or fewer), this is the option to use.

       --proxy-user=user
       --proxy-password=password
           Specify the username user and password password for authentication
           on a proxy server.  Wget will encode them using the "basic"
           authentication scheme.

           Security considerations similar to those with --http-password
           pertain here as well.

       --referer=url
           Include `Referer: url' header in HTTP request.  Useful for
           retrieving documents with server-side processing that assume they
           are always being retrieved by interactive web browsers and only
           come out properly when Referer is set to one of the pages that
           point to them.

       --save-headers
           Save the headers sent by the HTTP server to the file, preceding the
           actual contents, with an empty line as the separator.

       -U agent-string
       --user-agent=agent-string
           Identify as agent-string to the HTTP server.

           The HTTP protocol allows the clients to identify themselves using a
           "User-Agent" header field.  This enables distinguishing the WWW
           software, usually for statistical purposes or for tracing of
           protocol violations.  Wget normally identifies as Wget/version,
           version being the current version number of Wget.

           However, some sites have been known to impose the policy of
           tailoring the output according to the "User-Agent"-supplied
           information.  While this is not such a bad idea in theory, it has
           been abused by servers denying information to clients other than
           (historically) Netscape or, more frequently, Microsoft Internet
           Explorer.  This option allows you to change the "User-Agent" line
           issued by Wget.  Use of this option is discouraged, unless you
           really know what you are doing.

           Specifying empty user agent with --user-agent="" instructs Wget not
           to send the "User-Agent" header in HTTP requests.

       --post-data=string
       --post-file=file
           Use POST as the method for all HTTP requests and send the specified
           data in the request body.  --post-data sends string as data,
           whereas --post-file sends the contents of file.  Other than that,
           they work in exactly the same way. In particular, they both expect
           content of the form "key1=value1&key2=value2", with percent-
           encoding for special characters; the only difference is that one
           expects its content as a command-line parameter and the other
           accepts its content from a file. In particular, --post-file is not
           for transmitting files as form attachments: those must appear as
           "key=value" data (with appropriate percent-coding) just like
           everything else. Wget does not currently support
           "multipart/form-data" for transmitting POST data; only
           "application/x-www-form-urlencoded". Only one of --post-data and
           --post-file should be specified.

           Please note that wget does not require the content to be of the
           form "key1=value1&key2=value2", and neither does it test for it.
           Wget will simply transmit whatever data is provided to it. Most
           servers however expect the POST data to be in the above format when
           processing HTML Forms.

           When sending a POST request using the --post-file option, Wget
           treats the file as a binary file and will send every character in
           the POST request without stripping trailing newline or formfeed
           characters. Any other control characters in the text will also be
           sent as-is in the POST request.

           Please be aware that Wget needs to know the size of the POST data
           in advance.  Therefore the argument to "--post-file" must be a
           regular file; specifying a FIFO or something like /dev/stdin won't
           work.  It's not quite clear how to work around this limitation
           inherent in HTTP/1.0.  Although HTTP/1.1 introduces chunked
           transfer that doesn't require knowing the request length in
           advance, a client can't use chunked unless it knows it's talking to
           an HTTP/1.1 server.  And it can't know that until it receives a
           response, which in turn requires the request to have been completed
           -- a chicken-and-egg problem.

           Note: As of version 1.15 if Wget is redirected after the POST
           request is completed, its behaviour will depend on the response
           code returned by the server.  In case of a 301 Moved Permanently,
           302 Moved Temporarily or 307 Temporary Redirect, Wget will, in
           accordance with RFC2616, continue to send a POST request.  In case
           a server wants the client to change the Request method upon
           redirection, it should send a 303 See Other response code.

           This example shows how to log in to a server using POST and then
           proceed to download the desired pages, presumably only accessible
           to authorized users:

                   # Log in to the server.  This can be done only once.
                   wget --save-cookies cookies.txt \
                        --post-data 'user=foo&password=bar' \
                        http://example.com/auth.php

                   # Now grab the page or pages we care about.
                   wget --load-cookies cookies.txt \
                        -p http://example.com/interesting/article.php

           If the server is using session cookies to track user
           authentication, the above will not work because --save-cookies will
           not save them (and neither will browsers) and the cookies.txt file
           will be empty.  In that case use --keep-session-cookies along with
           --save-cookies to force saving of session cookies.

       --method=HTTP-Method
           For the purpose of RESTful scripting, Wget allows sending of other
           HTTP Methods without the need to explicitly set them using
           --header=Header-Line.  Wget will use whatever string is passed to
           it after --method as the HTTP Method to the server.

       --body-data=Data-String
       --body-file=Data-File
           Must be set when additional data needs to be sent to the server
           along with the Method specified using --method.  --body-data sends
           string as data, whereas --body-file sends the contents of file.
           Other than that, they work in exactly the same way.

           Currently, --body-file is not for transmitting files as a whole.
           Wget does not currently support "multipart/form-data" for
           transmitting data; only "application/x-www-form-urlencoded". In the
           future, this may be changed so that wget sends the --body-file as a
           complete file instead of sending its contents to the server. Please
           be aware that Wget needs to know the contents of BODY Data in
           advance, and hence the argument to --body-file should be a regular
           file. See --post-file for a more detailed explanation.  Only one of
           --body-data and --body-file should be specified.

           If Wget is redirected after the request is completed, Wget will
           suspend the current method and send a GET request till the
           redirection is completed.  This is true for all redirection
           response codes except 307 Temporary Redirect which is used to
           explicitly specify that the request method should not change.
           Another exception is when the method is set to "POST", in which
           case the redirection rules specified under --post-data are
           followed.

       --content-disposition
           If this is set to on, experimental (not fully-functional) support
           for "Content-Disposition" headers is enabled. This can currently
           result in extra round-trips to the server for a "HEAD" request, and
           is known to suffer from a few bugs, which is why it is not
           currently enabled by default.

           This option is useful for some file-downloading CGI programs that
           use "Content-Disposition" headers to describe what the name of a
           downloaded file should be.

           When combined with --metalink-over-http and --trust-server-names, a
           Content-Type: application/metalink4+xml file is named using the
           "Content-Disposition" filename field, if available.

       --content-on-error
           If this is set to on, wget will not skip the content when the
           server responds with a http status code that indicates error.

       --trust-server-names
           If this is set, on a redirect, the local file name will be based on
           the redirection URL.  By default the local file name is based on
           the original URL.  When doing recursive retrieving this can be
           helpful because in many web sites redirected URLs correspond to an
           underlying file structure, while link URLs do not.

       --auth-no-challenge
           If this option is given, Wget will send Basic HTTP authentication
           information (plaintext username and password) for all requests,
           just like Wget 1.10.2 and prior did by default.

           Use of this option is not recommended, and is intended only to
           support some few obscure servers, which never send HTTP
           authentication challenges, but accept unsolicited auth info, say,
           in addition to form-based authentication.

       --retry-on-host-error
           Consider host errors, such as "Temporary failure in name
           resolution", as non-fatal, transient errors.

       --retry-on-http-error=code[,code,...]
           Consider given HTTP response codes as non-fatal, transient errors.
           Supply a comma-separated list of 3-digit HTTP response codes as
           argument. Useful to work around special circumstances where retries
           are required, but the server responds with an error code normally
           not retried by Wget. Such errors might be 503 (Service Unavailable)
           and 429 (Too Many Requests). Retries enabled by this option are
           performed subject to the normal retry timing and retry count
           limitations of Wget.

           Using this option is intended to support special use cases only and
           is generally not recommended, as it can force retries even in cases
           where the server is actually trying to decrease its load. Please
           use wisely and only if you know what you are doing.

   HTTPS (SSL/TLS) Options
       To support encrypted HTTP (HTTPS) downloads, Wget must be compiled with
       an external SSL library. The current default is GnuTLS.  In addition,
       Wget also supports HSTS (HTTP Strict Transport Security).  If Wget is
       compiled without SSL support, none of these options are available.

       --secure-protocol=protocol
           Choose the secure protocol to be used.  Legal values are auto,
           SSLv2, SSLv3, TLSv1, TLSv1_1, TLSv1_2, TLSv1_3 and PFS.  If auto is
           used, the SSL library is given the liberty of choosing the
           appropriate protocol automatically, which is achieved by sending a
           TLSv1 greeting. This is the default.

           Specifying SSLv2, SSLv3, TLSv1, TLSv1_1, TLSv1_2 or TLSv1_3 forces
           the use of the corresponding protocol.  This is useful when talking
           to old and buggy SSL server implementations that make it hard for
           the underlying SSL library to choose the correct protocol version.
           Fortunately, such servers are quite rare.

           Specifying PFS enforces the use of the so-called Perfect Forward
           Security cipher suites. In short, PFS adds security by creating a
           one-time key for each SSL connection. It has a bit more CPU impact
           on client and server.  We use known to be secure ciphers (e.g. no
           MD4) and the TLS protocol. This mode also explicitly excludes non-
           PFS key exchange methods, such as RSA.

       --https-only
           When in recursive mode, only HTTPS links are followed.

       --ciphers
           Set the cipher list string. Typically this string sets the cipher
           suites and other SSL/TLS options that the user wish should be used,
           in a set order of preference (GnuTLS calls it 'priority string').
           This string will be fed verbatim to the SSL/TLS engine (OpenSSL or
           GnuTLS) and hence its format and syntax is dependent on that. Wget
           will not process or manipulate it in any way. Refer to the OpenSSL
           or GnuTLS documentation for more information.

       --no-check-certificate
           Don't check the server certificate against the available
           certificate authorities.  Also don't require the URL host name to
           match the common name presented by the certificate.

           As of Wget 1.10, the default is to verify the server's certificate
           against the recognized certificate authorities, breaking the SSL
           handshake and aborting the download if the verification fails.
           Although this provides more secure downloads, it does break
           interoperability with some sites that worked with previous Wget
           versions, particularly those using self-signed, expired, or
           otherwise invalid certificates.  This option forces an "insecure"
           mode of operation that turns the certificate verification errors
           into warnings and allows you to proceed.

           If you encounter "certificate verification" errors or ones saying
           that "common name doesn't match requested host name", you can use
           this option to bypass the verification and proceed with the
           download.  Only use this option if you are otherwise convinced of
           the site's authenticity, or if you really don't care about the
           validity of its certificate.  It is almost always a bad idea not to
           check the certificates when transmitting confidential or important
           data.  For self-signed/internal certificates, you should download
           the certificate and verify against that instead of forcing this
           insecure mode.  If you are really sure of not desiring any
           certificate verification, you can specify --check-certificate=quiet
           to tell wget to not print any warning about invalid certificates,
           albeit in most cases this is the wrong thing to do.

       --certificate=file
           Use the client certificate stored in file.  This is needed for
           servers that are configured to require certificates from the
           clients that connect to them.  Normally a certificate is not
           required and this switch is optional.

       --certificate-type=type
           Specify the type of the client certificate.  Legal values are PEM
           (assumed by default) and DER, also known as ASN1.

       --private-key=file
           Read the private key from file.  This allows you to provide the
           private key in a file separate from the certificate.

       --private-key-type=type
           Specify the type of the private key.  Accepted values are PEM (the
           default) and DER.

       --ca-certificate=file
           Use file as the file with the bundle of certificate authorities
           ("CA") to verify the peers.  The certificates must be in PEM
           format.

           Without this option Wget looks for CA certificates at the system-
           specified locations, chosen at OpenSSL installation time.

       --ca-directory=directory
           Specifies directory containing CA certificates in PEM format.  Each
           file contains one CA certificate, and the file name is based on a
           hash value derived from the certificate.  This is achieved by
           processing a certificate directory with the "c_rehash" utility
           supplied with OpenSSL.  Using --ca-directory is more efficient than
           --ca-certificate when many certificates are installed because it
           allows Wget to fetch certificates on demand.

           Without this option Wget looks for CA certificates at the system-
           specified locations, chosen at OpenSSL installation time.

       --crl-file=file
           Specifies a CRL file in file.  This is needed for certificates that
           have been revocated by the CAs.

       --pinnedpubkey=file/hashes
           Tells wget to use the specified public key file (or hashes) to
           verify the peer.  This can be a path to a file which contains a
           single public key in PEM or DER format, or any number of base64
           encoded sha256 hashes preceded by "sha256//" and separated by ";"

           When negotiating a TLS or SSL connection, the server sends a
           certificate indicating its identity. A public key is extracted from
           this certificate and if it does not exactly match the public key(s)
           provided to this option, wget will abort the connection before
           sending or receiving any data.

       --random-file=file
           [OpenSSL and LibreSSL only] Use file as the source of random data
           for seeding the pseudo-random number generator on systems without
           /dev/urandom.

           On such systems the SSL library needs an external source of
           randomness to initialize.  Randomness may be provided by EGD (see
           --egd-file below) or read from an external source specified by the
           user.  If this option is not specified, Wget looks for random data
           in $RANDFILE or, if that is unset, in $HOME/.rnd.

           If you're getting the "Could not seed OpenSSL PRNG; disabling SSL."
           error, you should provide random data using some of the methods
           described above.

       --egd-file=file
           [OpenSSL only] Use file as the EGD socket.  EGD stands for Entropy
           Gathering Daemon, a user-space program that collects data from
           various unpredictable system sources and makes it available to
           other programs that might need it.  Encryption software, such as
           the SSL library, needs sources of non-repeating randomness to seed
           the random number generator used to produce cryptographically
           strong keys.

           OpenSSL allows the user to specify his own source of entropy using
           the "RAND_FILE" environment variable.  If this variable is unset,
           or if the specified file does not produce enough randomness,
           OpenSSL will read random data from EGD socket specified using this
           option.

           If this option is not specified (and the equivalent startup command
           is not used), EGD is never contacted.  EGD is not needed on modern
           Unix systems that support /dev/urandom.

       --no-hsts
           Wget supports HSTS (HTTP Strict Transport Security, RFC 6797) by
           default.  Use --no-hsts to make Wget act as a non-HSTS-compliant
           UA. As a consequence, Wget would ignore all the
           "Strict-Transport-Security" headers, and would not enforce any
           existing HSTS policy.

       --hsts-file=file
           By default, Wget stores its HSTS database in ~/.wget-hsts.  You can
           use --hsts-file to override this. Wget will use the supplied file
           as the HSTS database. Such file must conform to the correct HSTS
           database format used by Wget. If Wget cannot parse the provided
           file, the behaviour is unspecified.

           The Wget's HSTS database is a plain text file. Each line contains
           an HSTS entry (ie. a site that has issued a
           "Strict-Transport-Security" header and that therefore has specified
           a concrete HSTS policy to be applied). Lines starting with a dash
           ("#") are ignored by Wget. Please note that in spite of this
           convenient human-readability hand-hacking the HSTS database is
           generally not a good idea.

           An HSTS entry line consists of several fields separated by one or
           more whitespace:

           "<hostname> SP [<port>] SP <include subdomains> SP <created> SP
           <max-age>"

           The hostname and port fields indicate the hostname and port to
           which the given HSTS policy applies. The port field may be zero,
           and it will, in most of the cases. That means that the port number
           will not be taken into account when deciding whether such HSTS
           policy should be applied on a given request (only the hostname will
           be evaluated). When port is different to zero, both the target
           hostname and the port will be evaluated and the HSTS policy will
           only be applied if both of them match. This feature has been
           included for testing/development purposes only.  The Wget testsuite
           (in testenv/) creates HSTS databases with explicit ports with the
           purpose of ensuring Wget's correct behaviour. Applying HSTS
           policies to ports other than the default ones is discouraged by RFC
           6797 (see Appendix B "Differences between HSTS Policy and Same-
           Origin Policy"). Thus, this functionality should not be used in
           production environments and port will typically be zero. The last
           three fields do what they are expected to. The field
           include_subdomains can either be 1 or 0 and it signals whether the
           subdomains of the target domain should be part of the given HSTS
           policy as well. The created and max-age fields hold the timestamp
           values of when such entry was created (first seen by Wget) and the
           HSTS-defined value 'max-age', which states how long should that
           HSTS policy remain active, measured in seconds elapsed since the
           timestamp stored in created. Once that time has passed, that HSTS
           policy will no longer be valid and will eventually be removed from
           the database.

           If you supply your own HSTS database via --hsts-file, be aware that
           Wget may modify the provided file if any change occurs between the
           HSTS policies requested by the remote servers and those in the
           file. When Wget exits, it effectively updates the HSTS database by
           rewriting the database file with the new entries.

           If the supplied file does not exist, Wget will create one. This
           file will contain the new HSTS entries. If no HSTS entries were
           generated (no "Strict-Transport-Security" headers were sent by any
           of the servers) then no file will be created, not even an empty
           one. This behaviour applies to the default database file
           (~/.wget-hsts) as well: it will not be created until some server
           enforces an HSTS policy.

           Care is taken not to override possible changes made by other Wget
           processes at the same time over the HSTS database. Before dumping
           the updated HSTS entries on the file, Wget will re-read it and
           merge the changes.

           Using a custom HSTS database and/or modifying an existing one is
           discouraged.  For more information about the potential security
           threats arose from such practice, see section 14 "Security
           Considerations" of RFC 6797, specially section 14.9 "Creative
           Manipulation of HSTS Policy Store".

       --warc-file=file
           Use file as the destination WARC file.

       --warc-header=string
           Use string into as the warcinfo record.

       --warc-max-size=size
           Set the maximum size of the WARC files to size.

       --warc-cdx
           Write CDX index files.

       --warc-dedup=file
           Do not store records listed in this CDX file.

       --no-warc-compression
           Do not compress WARC files with GZIP.

       --no-warc-digests
           Do not calculate SHA1 digests.

       --no-warc-keep-log
           Do not store the log file in a WARC record.

       --warc-tempdir=dir
           Specify the location for temporary files created by the WARC
           writer.

   FTP Options
       --ftp-user=user
       --ftp-password=password
           Specify the username user and password password on an FTP server.
           Without this, or the corresponding startup option, the password
           defaults to -wget@, normally used for anonymous FTP.

           Another way to specify username and password is in the URL itself.
           Either method reveals your password to anyone who bothers to run
           "ps".  To prevent the passwords from being seen, store them in
           .wgetrc or .netrc, and make sure to protect those files from other
           users with "chmod".  If the passwords are really important, do not
           leave them lying in those files either---edit the files and delete
           them after Wget has started the download.

       --no-remove-listing
           Don't remove the temporary .listing files generated by FTP
           retrievals.  Normally, these files contain the raw directory
           listings received from FTP servers.  Not removing them can be
           useful for debugging purposes, or when you want to be able to
           easily check on the contents of remote server directories (e.g. to
           verify that a mirror you're running is complete).

           Note that even though Wget writes to a known filename for this
           file, this is not a security hole in the scenario of a user making
           .listing a symbolic link to /etc/passwd or something and asking
           "root" to run Wget in his or her directory.  Depending on the
           options used, either Wget will refuse to write to .listing, making
           the globbing/recursion/time-stamping operation fail, or the
           symbolic link will be deleted and replaced with the actual .listing
           file, or the listing will be written to a .listing.number file.

           Even though this situation isn't a problem, though, "root" should
           never run Wget in a non-trusted user's directory.  A user could do
           something as simple as linking index.html to /etc/passwd and asking
           "root" to run Wget with -N or -r so the file will be overwritten.

       --no-glob
           Turn off FTP globbing.  Globbing refers to the use of shell-like
           special characters (wildcards), like *, ?, [ and ] to retrieve more
           than one file from the same directory at once, like:

                   wget ftp://gnjilux.srk.fer.hr/*.msg

           By default, globbing will be turned on if the URL contains a
           globbing character.  This option may be used to turn globbing on or
           off permanently.

           You may have to quote the URL to protect it from being expanded by
           your shell.  Globbing makes Wget look for a directory listing,
           which is system-specific.  This is why it currently works only with
           Unix FTP servers (and the ones emulating Unix "ls" output).

       --no-passive-ftp
           Disable the use of the passive FTP transfer mode.  Passive FTP
           mandates that the client connect to the server to establish the
           data connection rather than the other way around.

           If the machine is connected to the Internet directly, both passive
           and active FTP should work equally well.  Behind most firewall and
           NAT configurations passive FTP has a better chance of working.
           However, in some rare firewall configurations, active FTP actually
           works when passive FTP doesn't.  If you suspect this to be the
           case, use this option, or set "passive_ftp=off" in your init file.

       --preserve-permissions
           Preserve remote file permissions instead of permissions set by
           umask.

       --retr-symlinks
           By default, when retrieving FTP directories recursively and a
           symbolic link is encountered, the symbolic link is traversed and
           the pointed-to files are retrieved.  Currently, Wget does not
           traverse symbolic links to directories to download them
           recursively, though this feature may be added in the future.

           When --retr-symlinks=no is specified, the linked-to file is not
           downloaded.  Instead, a matching symbolic link is created on the
           local filesystem.  The pointed-to file will not be retrieved unless
           this recursive retrieval would have encountered it separately and
           downloaded it anyway.  This option poses a security risk where a
           malicious FTP Server may cause Wget to write to files outside of
           the intended directories through a specially crafted .LISTING file.

           Note that when retrieving a file (not a directory) because it was
           specified on the command-line, rather than because it was recursed
           to, this option has no effect.  Symbolic links are always traversed
           in this case.

   FTPS Options
       --ftps-implicit
           This option tells Wget to use FTPS implicitly. Implicit FTPS
           consists of initializing SSL/TLS from the very beginning of the
           control connection. This option does not send an "AUTH TLS"
           command: it assumes the server speaks FTPS and directly starts an
           SSL/TLS connection. If the attempt is successful, the session
           continues just like regular FTPS ("PBSZ" and "PROT" are sent,
           etc.).  Implicit FTPS is no longer a requirement for FTPS
           implementations, and thus many servers may not support it. If
           --ftps-implicit is passed and no explicit port number specified,
           the default port for implicit FTPS, 990, will be used, instead of
           the default port for the "normal" (explicit) FTPS which is the same
           as that of FTP, 21.

       --no-ftps-resume-ssl
           Do not resume the SSL/TLS session in the data channel. When
           starting a data connection, Wget tries to resume the SSL/TLS
           session previously started in the control connection.  SSL/TLS
           session resumption avoids performing an entirely new handshake by
           reusing the SSL/TLS parameters of a previous session. Typically,
           the FTPS servers want it that way, so Wget does this by default.
           Under rare circumstances however, one might want to start an
           entirely new SSL/TLS session in every data connection.  This is
           what --no-ftps-resume-ssl is for.

       --ftps-clear-data-connection
           All the data connections will be in plain text. Only the control
           connection will be under SSL/TLS. Wget will send a "PROT C" command
           to achieve this, which must be approved by the server.

       --ftps-fallback-to-ftp
           Fall back to FTP if FTPS is not supported by the target server. For
           security reasons, this option is not asserted by default. The
           default behaviour is to exit with an error.  If a server does not
           successfully reply to the initial "AUTH TLS" command, or in the
           case of implicit FTPS, if the initial SSL/TLS connection attempt is
           rejected, it is considered that such server does not support FTPS.

   Recursive Retrieval Options
       -r
       --recursive
           Turn on recursive retrieving.    The default maximum depth is 5.

       -l depth
       --level=depth
           Set the maximum number of subdirectories that Wget will recurse
           into to depth.  In order to prevent one from accidentally
           downloading very large websites when using recursion this is
           limited to a depth of 5 by default, i.e., it will traverse at most
           5 directories deep starting from the provided URL.  Set -l 0 or -l
           inf for infinite recursion depth.

                   wget -r -l 0 http://<site>/1.html

           Ideally, one would expect this to download just 1.html.  but
           unfortunately this is not the case, because -l 0 is equivalent to
           -l inf---that is, infinite recursion.  To download a single HTML
           page (or a handful of them), specify them all on the command line
           and leave away -r and -l. To download the essential items to view a
           single HTML page, see page requisites.

       --delete-after
           This option tells Wget to delete every single file it downloads,
           after having done so.  It is useful for pre-fetching popular pages
           through a proxy, e.g.:

                   wget -r -nd --delete-after http://whatever.com/~popular/page/

           The -r option is to retrieve recursively, and -nd to not create
           directories.

           Note that --delete-after deletes files on the local machine.  It
           does not issue the DELE command to remote FTP sites, for instance.
           Also note that when --delete-after is specified, --convert-links is
           ignored, so .orig files are simply not created in the first place.

       -k
       --convert-links
           After the download is complete, convert the links in the document
           to make them suitable for local viewing.  This affects not only the
           visible hyperlinks, but any part of the document that links to
           external content, such as embedded images, links to style sheets,
           hyperlinks to non-HTML content, etc.

           Each link will be changed in one of the two ways:

           o   The links to files that have been downloaded by Wget will be
               changed to refer to the file they point to as a relative link.

               Example: if the downloaded file /foo/doc.html links to
               /bar/img.gif, also downloaded, then the link in doc.html will
               be modified to point to ../bar/img.gif.  This kind of
               transformation works reliably for arbitrary combinations of
               directories.

           o   The links to files that have not been downloaded by Wget will
               be changed to include host name and absolute path of the
               location they point to.

               Example: if the downloaded file /foo/doc.html links to
               /bar/img.gif (or to ../bar/img.gif), then the link in doc.html
               will be modified to point to http://hostname/bar/img.gif.

           Because of this, local browsing works reliably: if a linked file
           was downloaded, the link will refer to its local name; if it was
           not downloaded, the link will refer to its full Internet address
           rather than presenting a broken link.  The fact that the former
           links are converted to relative links ensures that you can move the
           downloaded hierarchy to another directory.

           Note that only at the end of the download can Wget know which links
           have been downloaded.  Because of that, the work done by -k will be
           performed at the end of all the downloads.

       --convert-file-only
           This option converts only the filename part of the URLs, leaving
           the rest of the URLs untouched. This filename part is sometimes
           referred to as the "basename", although we avoid that term here in
           order not to cause confusion.

           It works particularly well in conjunction with --adjust-extension,
           although this coupling is not enforced. It proves useful to
           populate Internet caches with files downloaded from different
           hosts.

           Example: if some link points to //foo.com/bar.cgi?xyz with
           --adjust-extension asserted and its local destination is intended
           to be ./foo.com/bar.cgi?xyz.css, then the link would be converted
           to //foo.com/bar.cgi?xyz.css. Note that only the filename part has
           been modified. The rest of the URL has been left untouched,
           including the net path ("//") which would otherwise be processed by
           Wget and converted to the effective scheme (ie. "http://").

       -K
       --backup-converted
           When converting a file, back up the original version with a .orig
           suffix.  Affects the behavior of -N.

       -m
       --mirror
           Turn on options suitable for mirroring.  This option turns on
           recursion and time-stamping, sets infinite recursion depth and
           keeps FTP directory listings.  It is currently equivalent to -r -N
           -l inf --no-remove-listing.

       -p
       --page-requisites
           This option causes Wget to download all the files that are
           necessary to properly display a given HTML page.  This includes
           such things as inlined images, sounds, and referenced stylesheets.

           Ordinarily, when downloading a single HTML page, any requisite
           documents that may be needed to display it properly are not
           downloaded.  Using -r together with -l can help, but since Wget
           does not ordinarily distinguish between external and inlined
           documents, one is generally left with "leaf documents" that are
           missing their requisites.

           For instance, say document 1.html contains an "<IMG>" tag
           referencing 1.gif and an "<A>" tag pointing to external document
           2.html.  Say that 2.html is similar but that its image is 2.gif and
           it links to 3.html.  Say this continues up to some arbitrarily high
           number.

           If one executes the command:

                   wget -r -l 2 http://<site>/1.html

           then 1.html, 1.gif, 2.html, 2.gif, and 3.html will be downloaded.
           As you can see, 3.html is without its requisite 3.gif because Wget
           is simply counting the number of hops (up to 2) away from 1.html in
           order to determine where to stop the recursion.  However, with this
           command:

                   wget -r -l 2 -p http://<site>/1.html

           all the above files and 3.html's requisite 3.gif will be
           downloaded.  Similarly,

                   wget -r -l 1 -p http://<site>/1.html

           will cause 1.html, 1.gif, 2.html, and 2.gif to be downloaded.  One
           might think that:

                   wget -r -l 0 -p http://<site>/1.html

           would download just 1.html and 1.gif, but unfortunately this is not
           the case, because -l 0 is equivalent to -l inf---that is, infinite
           recursion.  To download a single HTML page (or a handful of them,
           all specified on the command-line or in a -i URL input file) and
           its (or their) requisites, simply leave off -r and -l:

                   wget -p http://<site>/1.html

           Note that Wget will behave as if -r had been specified, but only
           that single page and its requisites will be downloaded.  Links from
           that page to external documents will not be followed.  Actually, to
           download a single page and all its requisites (even if they exist
           on separate websites), and make sure the lot displays properly
           locally, this author likes to use a few options in addition to -p:

                   wget -E -H -k -K -p http://<site>/<document>

           To finish off this topic, it's worth knowing that Wget's idea of an
           external document link is any URL specified in an "<A>" tag, an
           "<AREA>" tag, or a "<LINK>" tag other than "<LINK
           REL="stylesheet">".

       --strict-comments
           Turn on strict parsing of HTML comments.  The default is to
           terminate comments at the first occurrence of -->.

           According to specifications, HTML comments are expressed as SGML
           declarations.  Declaration is special markup that begins with <!
           and ends with >, such as <!DOCTYPE ...>, that may contain comments
           between a pair of -- delimiters.  HTML comments are "empty
           declarations", SGML declarations without any non-comment text.
           Therefore, <!--foo--> is a valid comment, and so is <!--one--
           --two-->, but <!--1--2--> is not.

           On the other hand, most HTML writers don't perceive comments as
           anything other than text delimited with <!-- and -->, which is not
           quite the same.  For example, something like <!------------> works
           as a valid comment as long as the number of dashes is a multiple of
           four (!).  If not, the comment technically lasts until the next --,
           which may be at the other end of the document.  Because of this,
           many popular browsers completely ignore the specification and
           implement what users have come to expect: comments delimited with
           <!-- and -->.

           Until version 1.9, Wget interpreted comments strictly, which
           resulted in missing links in many web pages that displayed fine in
           browsers, but had the misfortune of containing non-compliant
           comments.  Beginning with version 1.9, Wget has joined the ranks of
           clients that implements "naive" comments, terminating each comment
           at the first occurrence of -->.

           If, for whatever reason, you want strict comment parsing, use this
           option to turn it on.

   Recursive Accept/Reject Options
       -A acclist --accept acclist
       -R rejlist --reject rejlist
           Specify comma-separated lists of file name suffixes or patterns to
           accept or reject. Note that if any of the wildcard characters, *,
           ?, [ or ], appear in an element of acclist or rejlist, it will be
           treated as a pattern, rather than a suffix.  In this case, you have
           to enclose the pattern into quotes to prevent your shell from
           expanding it, like in -A "*.mp3" or -A '*.mp3'.

       --accept-regex urlregex
       --reject-regex urlregex
           Specify a regular expression to accept or reject the complete URL.

       --regex-type regextype
           Specify the regular expression type.  Possible types are posix or
           pcre.  Note that to be able to use pcre type, wget has to be
           compiled with libpcre support.

       -D domain-list
       --domains=domain-list
           Set domains to be followed.  domain-list is a comma-separated list
           of domains.  Note that it does not turn on -H.

       --exclude-domains domain-list
           Specify the domains that are not to be followed.

       --follow-ftp
           Follow FTP links from HTML documents.  Without this option, Wget
           will ignore all the FTP links.

       --follow-tags=list
           Wget has an internal table of HTML tag / attribute pairs that it
           considers when looking for linked documents during a recursive
           retrieval.  If a user wants only a subset of those tags to be
           considered, however, he or she should be specify such tags in a
           comma-separated list with this option.

       --ignore-tags=list
           This is the opposite of the --follow-tags option.  To skip certain
           HTML tags when recursively looking for documents to download,
           specify them in a comma-separated list.

           In the past, this option was the best bet for downloading a single
           page and its requisites, using a command-line like:

                   wget --ignore-tags=a,area -H -k -K -r http://<site>/<document>

           However, the author of this option came across a page with tags
           like "<LINK REL="home" HREF="/">" and came to the realization that
           specifying tags to ignore was not enough.  One can't just tell Wget
           to ignore "<LINK>", because then stylesheets will not be
           downloaded.  Now the best bet for downloading a single page and its
           requisites is the dedicated --page-requisites option.

       --ignore-case
           Ignore case when matching files and directories.  This influences
           the behavior of -R, -A, -I, and -X options, as well as globbing
           implemented when downloading from FTP sites.  For example, with
           this option, -A "*.txt" will match file1.txt, but also file2.TXT,
           file3.TxT, and so on.  The quotes in the example are to prevent the
           shell from expanding the pattern.

       -H
       --span-hosts
           Enable spanning across hosts when doing recursive retrieving.

       -L
       --relative
           Follow relative links only.  Useful for retrieving a specific home
           page without any distractions, not even those from the same hosts.

       -I list
       --include-directories=list
           Specify a comma-separated list of directories you wish to follow
           when downloading.  Elements of list may contain wildcards.

       -X list
       --exclude-directories=list
           Specify a comma-separated list of directories you wish to exclude
           from download.  Elements of list may contain wildcards.

       -np
       --no-parent
           Do not ever ascend to the parent directory when retrieving
           recursively.  This is a useful option, since it guarantees that
           only the files below a certain hierarchy will be downloaded.

EXECUTION EXAMPLE:
COMMAND INPUT:
wget --version

COMMAND OUTPUT:
GNU Wget 1.21.3 built on linux-gnu.

-cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls 
+ntlm +opie +psl +ssl/gnutls 

Wgetrc: 
    /etc/wgetrc (system)
Locale: 
    /usr/share/locale 
Compile: 
    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC="/etc/wgetrc" 
    -DLOCALEDIR="/usr/share/locale" -I. -I../../src -I../lib 
    -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 
    -I/usr/include/p11-kit-1 -DHAVE_LIBGNUTLS -DNDEBUG -g -O2 
    -ffile-prefix-map=/build/wget-z9r8qt/wget-1.21.3=. 
    -fstack-protector-strong -Wformat -Werror=format-security 
    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall 
Link: 
    gcc -I/usr/include/p11-kit-1 -DHAVE_LIBGNUTLS -DNDEBUG -g -O2 
    -ffile-prefix-map=/build/wget-z9r8qt/wget-1.21.3=. 
    -fstack-protector-strong -Wformat -Werror=format-security 
    -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-z,relro -Wl,-z,now 
    -lpcre2-8 -luuid -lidn2 -lnettle -lgnutls -lz -lpsl ../lib/libgnu.a 

Copyright (C) 2015 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later
<http://www.gnu.org/licenses/gpl.html>.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Originally written by Hrvoje Niksic <hniksic@xemacs.org>.
Please send bug reports and questions to <bug-wget@gnu.org>.

===

COMMAND: curl

DESCRIPTION: curl - transfer a URL

USAGE: curl [options / URLs]

OPTIONS:
Options start with one or two dashes. Many of the  options  require  an
       additional value next to them.

       The  short  "single-dash"  form  of the options, -d for example, may be
       used with or without a space between it and its value, although a space
       is a recommended separator. The long "double-dash" form, -d, --data for
       example, requires a space between it and its value.

       Short version options that do not need any  additional  values  can  be
       used  immediately  next to each other, like for example you can specify
       all the options -O, -L and -v at once as -OLv.

       In general, all boolean options are enabled with --option and yet again
       disabled  with  --no-option.  That is, you use the same option name but
       prefix it with "no-". However, in this list we  mostly  only  list  and
       show the --option version of them.

       --abstract-unix-socket <path>
              (HTTP)  Connect  through an abstract Unix domain socket, instead
              of using the network.  Note: netstat shows the path  of  an  ab-
              stract  socket  prefixed  with  '@', however the <path> argument
              should not have this leading character.

              If --abstract-unix-socket is provided several  times,  the  last
              set value will be used.

              Example:
               curl --abstract-unix-socket socketpath https://example.com

              See also --unix-socket. Added in 7.53.0.

       --alt-svc <file name>
              (HTTPS)  This  option enables the alt-svc parser in curl. If the
              file name points to an existing alt-svc cache file, that will be
              used. After a completed transfer, the cache will be saved to the
              file name again if it has been modified.

              Specify a "" file name (zero length) to avoid loading/saving and
              make curl just handle the cache in memory.

              If  this  option  is used several times, curl will load contents
              from all the files but the last one will be used for saving.

              --alt-svc can be used several times in a command line

              Example:
               curl --alt-svc svc.txt https://example.com

              See also --resolve and --connect-to. Added in 7.64.1.

       --anyauth
              (HTTP) Tells curl to figure out authentication method by itself,
              and  use  the most secure one the remote site claims to support.
              This is done by first doing a request and checking the response-
              headers,  thus  possibly  inducing  an extra network round-trip.
              This is  used  instead  of  setting  a  specific  authentication
              method,  which  you  can  do with --basic, --digest, --ntlm, and
              --negotiate.

              Using --anyauth is not recommended if you do uploads from stdin,
              since  it  may require data to be sent twice and then the client
              must be able to rewind. If the need should arise when  uploading
              from stdin, the upload operation will fail.

              Used together with -u, --user.

              Providing --anyauth multiple times has no extra effect.

              Example:
               curl --anyauth --user me:pwd https://example.com

              See also --proxy-anyauth, --basic and --digest.

       -a, --append
              (FTP SFTP) When used in an upload, this makes curl append to the
              target file instead of overwriting it. If the remote  file  does
              not exist, it will be created. Note that this flag is ignored by
              some SFTP servers (including OpenSSH).

              Providing -a, --append multiple times has no extra effect.  Dis-
              able it again with --no-append.

              Example:
               curl --upload-file local --append ftp://example.com/

              See also -r, --range and -C, --continue-at.

       --aws-sigv4 <provider1[:provider2[:region[:service]]]>
              Use AWS V4 signature authentication in the transfer.

              The  provider argument is a string that is used by the algorithm
              when creating outgoing authentication headers.

              The region argument is a string that points to a geographic area
              of  a resources collection (region-code) when the region name is
              omitted from the endpoint.

              The service argument is a string that points to a function  pro-
              vided by a cloud (service-code) when the service name is omitted
              from the endpoint.

              If --aws-sigv4 is provided several times,  the  last  set  value
              will be used.

              Example:
               curl --aws-sigv4 "aws:amz:east-2:es" --user "key:secret" https://example.com

              See also --basic and -u, --user. Added in 7.75.0.

       --basic
              (HTTP)  Tells curl to use HTTP Basic authentication with the re-
              mote host. This is the default and this option is usually point-
              less, unless you use it to override a previously set option that
              sets a different authentication method (such  as  --ntlm,  --di-
              gest, or --negotiate).

              Used together with -u, --user.

              Providing --basic multiple times has no extra effect.

              Example:
               curl -u name:password --basic https://example.com

              See also --proxy-basic.

       --cacert <file>
              (TLS) Tells curl to use the specified certificate file to verify
              the peer. The file may contain  multiple  CA  certificates.  The
              certificate(s)  must be in PEM format. Normally curl is built to
              use a default file for this, so this option is typically used to
              alter that default file.

              curl  recognizes the environment variable named 'CURL_CA_BUNDLE'
              if it is set, and uses the given path as a path  to  a  CA  cert
              bundle. This option overrides that variable.

              The  windows  version  of  curl will automatically look for a CA
              certs file named 'curl-ca-bundle.crt', either in the same direc-
              tory as curl.exe, or in the Current Working Directory, or in any
              folder along your PATH.

              If curl is built against  the  NSS  SSL  library,  the  NSS  PEM
              PKCS#11 module (libnsspem.so) needs to be available for this op-
              tion to work properly.

              (iOS and macOS only) If curl is built against Secure  Transport,
              then  this  option  is supported for backward compatibility with
              other SSL engines, but it should not be set. If  the  option  is
              not  set,  then curl will use the certificates in the system and
              user Keychain to verify the peer, which is the preferred  method
              of verifying the peer's certificate chain.

              (Schannel only) This option is supported for Schannel in Windows
              7 or later with libcurl 7.60 or later. This option is  supported
              for backward compatibility with other SSL engines; instead it is
              recommended to use Windows' store of root certificates (the  de-
              fault for Schannel).

              If  --cacert  is provided several times, the last set value will
              be used.

              Example:
               curl --cacert CA-file.txt https://example.com

              See also --capath and -k, --insecure.

       --capath <dir>
              (TLS) Tells curl to use the specified certificate  directory  to
              verify  the  peer.  Multiple paths can be provided by separating
              them with ":" (e.g.  "path1:path2:path3"). The certificates must
              be  in PEM format, and if curl is built against OpenSSL, the di-
              rectory must have been processed using the c_rehash utility sup-
              plied  with  OpenSSL.  Using  --capath can allow OpenSSL-powered
              curl to make SSL-connections much more  efficiently  than  using
              --cacert if the --cacert file contains many CA certificates.

              If this option is set, the default capath value will be ignored.

              If  --capath  is provided several times, the last set value will
              be used.

              Example:
               curl --capath /local/directory https://example.com

              See also --cacert and -k, --insecure.

       --cert-status
              (TLS) Tells curl to verify the status of the server  certificate
              by using the Certificate Status Request (aka. OCSP stapling) TLS
              extension.

              If this option is enabled and the server sends an invalid  (e.g.
              expired) response, if the response suggests that the server cer-
              tificate has been revoked, or no response at  all  is  received,
              the verification fails.

              This  is  currently  only implemented in the OpenSSL, GnuTLS and
              NSS backends.

              Providing --cert-status multiple  times  has  no  extra  effect.
              Disable it again with --no-cert-status.

              Example:
               curl --cert-status https://example.com

              See also --pinnedpubkey. Added in 7.41.0.

       --cert-type <type>
              (TLS)  Tells  curl  what type the provided client certificate is
              using. PEM, DER, ENG and P12 are recognized types.

              The default type depends on the TLS backend and is usually  PEM,
              however  for  Secure  Transport  and  Schannel it is P12. If -E,
              --cert is a pkcs11: URI then ENG is the default type.

              If --cert-type is provided several times,  the  last  set  value
              will be used.

              Example:
               curl --cert-type PEM --cert file https://example.com

              See also -E, --cert, --key and --key-type.

       -E, --cert <certificate[:password]>
              (TLS)  Tells  curl  to use the specified client certificate file
              when getting a file with HTTPS, FTPS or another SSL-based proto-
              col.  The  certificate must be in PKCS#12 format if using Secure
              Transport, or PEM format if using any other engine. If  the  op-
              tional  password is not specified, it will be queried for on the
              terminal. Note that this option assumes a certificate file  that
              is  the private key and the client certificate concatenated. See
              -E, --cert and --key to specify them independently.

              In the <certificate> portion of the argument,  you  must  escape
              the  character  ":"  as "\:" so that it is not recognized as the
              password delimiter. Similarly, you must escape the character "\"
              as "\\" so that it is not recognized as an escape character.

              If  curl  is  built against the NSS SSL library then this option
              can tell curl the nickname of the certificate to use within  the
              NSS  database defined by the environment variable SSL_DIR (or by
              default /etc/pki/nssdb). If the NSS  PEM  PKCS#11  module  (lib-
              nsspem.so) is available then PEM files may be loaded.

              If  you  provide  a  path relative to the current directory, you
              must prefix the path with "./" in order to avoid confusion  with
              an NSS database nickname.

              If  curl is built against OpenSSL library, and the engine pkcs11
              is available, then a PKCS#11 URI (RFC 7512) can be used to spec-
              ify  a  certificate located in a PKCS#11 device. A string begin-
              ning with "pkcs11:" will be interpreted as a PKCS#11 URI.  If  a
              PKCS#11 URI is provided, then the --engine option will be set as
              "pkcs11" if none was provided and the --cert-type option will be
              set as "ENG" if none was provided.

              (iOS  and macOS only) If curl is built against Secure Transport,
              then the certificate string can either be the name of a certifi-
              cate/private  key in the system or user keychain, or the path to
              a PKCS#12-encoded certificate and private key. If  you  want  to
              use  a  file  from the current directory, please precede it with
              "./" prefix, in order to avoid confusion with a nickname.

              (Schannel only) Client certificates must be specified by a  path
              expression  to  a  certificate  store.  (Loading PFX is not sup-
              ported; you can import it to a store first). You can use "<store
              location>\<store  name>\<thumbprint>"  to refer to a certificate
              in  the  system  certificates  store,  for   example,   "Curren-
              tUser\MY\934a7ac6f8a5d579285a74fa61e19f23ddfe8d7a".   Thumbprint
              is usually a SHA-1 hex string which you can see  in  certificate
              details.  Following  store locations are supported: CurrentUser,
              LocalMachine, CurrentService, Services,  CurrentUserGroupPolicy,
              LocalMachineGroupPolicy, LocalMachineEnterprise.

              If -E, --cert is provided several times, the last set value will
              be used.

              Example:
               curl --cert certfile --key keyfile https://example.com

              See also --cert-type, --key and --key-type.

       --ciphers <list of ciphers>
              (TLS) Specifies which ciphers to use in the connection. The list
              of  ciphers  must  specify  valid ciphers. Read up on SSL cipher
              list details on this URL:

               https://curl.se/docs/ssl-ciphers.html

              If --ciphers is provided several times, the last set value  will
              be used.

              Example:
               curl --ciphers ECDHE-ECDSA-AES256-CCM8 https://example.com

              See also --tlsv1.3.

       --compressed-ssh
              (SCP SFTP) Enables built-in SSH compression.  This is a request,
              not an order; the server may or may not do it.

              Providing --compressed-ssh multiple times has no  extra  effect.
              Disable it again with --no-compressed-ssh.

              Example:
               curl --compressed-ssh sftp://example.com/

              See also --compressed. Added in 7.56.0.

       --compressed
              (HTTP) Request a compressed response using one of the algorithms
              curl supports, and automatically decompress the content. Headers
              are not modified.

              If  this  option is used and the server sends an unsupported en-
              coding, curl will report an error. This is a request, not an or-
              der; the server may or may not deliver data compressed.

              Providing --compressed multiple times has no extra effect.  Dis-
              able it again with --no-compressed.

              Example:
               curl --compressed https://example.com

              See also --compressed-ssh.

       -K, --config <file>
              Specify a text file to read curl  arguments  from.  The  command
              line  arguments  found  in the text file will be used as if they
              were provided on the command line.

              Options and their parameters must be specified on the same  line
              in the file, separated by whitespace, colon, or the equals sign.
              Long option names can optionally be given  in  the  config  file
              without the initial double dashes and if so, the colon or equals
              characters can be used as separators. If the option is specified
              with  one or two dashes, there can be no colon or equals charac-
              ter between the option and its parameter.

              If the parameter contains whitespace (or starts with  :  or  =),
              the  parameter  must  be  enclosed  within quotes. Within double
              quotes, the following escape sequences are  available:  \\,  \",
              \t, \n, \r and \v. A backslash preceding any other letter is ig-
              nored.

              If the first column of a config line is  a  '#'  character,  the
              rest of the line will be treated as a comment.

              Only write one option per physical line in the config file.

              Specify  the  filename  to -K, --config as '-' to make curl read
              the file from stdin.

              Note that to be able to specify a URL in the  config  file,  you
              need  to  specify  it  using the --url option, and not by simply
              writing the URL on its own line. So, it could  look  similar  to
              this:

              url = "https://curl.se/docs/"

               # --- Example file ---
               # this is a comment
               url = "example.com"
               output = "curlhere.html"
               user-agent = "superagent/1.0"

               # and fetch another URL too
               url = "example.com/docs/manpage.html"
               -O
               referer = "http://nowhereatall.example.com/"
               # --- End of example file ---

              When  curl  is invoked, it (unless -q, --disable is used) checks
              for a default config file and uses it if found,  even  when  -K,
              --config  is used. The default config file is checked for in the
              following places in this order:

              1) "$CURL_HOME/.curlrc"

              2) "$XDG_CONFIG_HOME/.curlrc" (Added in 7.73.0)

              3) "$HOME/.curlrc"

              4) Windows: "%USERPROFILE%\.curlrc"

              5) Windows: "%APPDATA%\.curlrc"

              6) Windows: "%USERPROFILE%\Application Data\.curlrc"

              7) Non-Windows: use getpwuid to find the home directory

              8) On Windows, if it finds no .curlrc file in the  sequence  de-
              scribed  above,  it checks for one in the same dir the curl exe-
              cutable is placed.

              On Windows two filenames are checked per location:  .curlrc  and
              _curlrc,  preferring  the  former.  Older  versions  on  Windows
              checked for _curlrc only.

              -K, --config can be used several times in a command line

              Example:
               curl --config file.txt https://example.com

              See also -q, --disable.

       --connect-timeout <fractional seconds>
              Maximum time in seconds that  you  allow  curl's  connection  to
              take.   This  only  limits the connection phase, so if curl con-
              nects within the given period it will continue - if not it  will
              exit.  Since version 7.32.0, this option accepts decimal values.

              The "connection phase" is considered complete when the requested
              TCP, TLS or QUIC handshakes are done.

              The decimal value needs to provided using a dot (.)  as  decimal
              separator  - not the local version even if it might be using an-
              other separator.

              If --connect-timeout is provided several  times,  the  last  set
              value will be used.

              Examples:
               curl --connect-timeout 20 https://example.com
               curl --connect-timeout 3.14 https://example.com

              See also -m, --max-time.

       --connect-to <HOST1:PORT1:HOST2:PORT2>

              For  a  request  to  the  given  HOST1:PORT1  pair,  connect  to
              HOST2:PORT2 instead.  This option is suitable to direct requests
              at a specific server, e.g. at a specific cluster node in a clus-
              ter of servers. This option is only used to establish  the  net-
              work  connection.  It  does NOT affect the hostname/port that is
              used for TLS/SSL (e.g. SNI, certificate verification) or for the
              application  protocols.  "HOST1"  and  "PORT1"  may be the empty
              string, meaning "any host/port". "HOST2" and "PORT2" may also be
              the   empty   string,   meaning   "use  the  request's  original
              host/port".

              A "host" specified to this option is compared as a string, so it
              needs  to  match  the name used in request URL. It can be either
              numerical such as "127.0.0.1" or the full host name such as "ex-
              ample.org".

              --connect-to can be used several times in a command line

              Example:
               curl --connect-to example.com:443:example.net:8443 https://example.com

              See also --resolve and -H, --header. Added in 7.49.0.

       -C, --continue-at <offset>
              Continue/Resume  a  previous  file transfer at the given offset.
              The given offset is the exact  number  of  bytes  that  will  be
              skipped,  counting  from the beginning of the source file before
              it is transferred to the destination. If used with uploads,  the
              FTP server command SIZE will not be used by curl.

              Use  "-C  -" to tell curl to automatically find out where/how to
              resume the transfer. It then uses the given  output/input  files
              to figure that out.

              If  -C,  --continue-at  is  provided several times, the last set
              value will be used.

              Examples:
               curl -C - https://example.com
               curl -C 400 https://example.com

              See also -r, --range.

       -c, --cookie-jar <filename>
              (HTTP) Specify to which file you want curl to write all  cookies
              after  a  completed  operation. Curl writes all cookies from its
              in-memory cookie storage to the given file at the end of  opera-
              tions.  If  no  cookies  are known, no data will be written. The
              file will be written using the Netscape cookie file  format.  If
              you set the file name to a single dash, "-", the cookies will be
              written to stdout.

              This command line option will activate the  cookie  engine  that
              makes curl record and use cookies. Another way to activate it is
              to use the -b, --cookie option.

              If the cookie jar cannot be created or  written  to,  the  whole
              curl  operation  will  not fail or even report an error clearly.
              Using -v, --verbose will get a warning displayed,  but  that  is
              the  only  visible  feedback  you get about this possibly lethal
              situation.

              If -c, --cookie-jar is provided  several  times,  the  last  set
              value will be used.

              Examples:
               curl -c store-here.txt https://example.com
               curl -c store-here.txt -b read-these https://example.com

              See also -b, --cookie.

       -b, --cookie <data|filename>
              (HTTP) Pass the data to the HTTP server in the Cookie header. It
              is supposedly the data previously received from the server in  a
              "Set-Cookie:"   line.   The   data   should  be  in  the  format
              "NAME1=VALUE1; NAME2=VALUE2". This makes  curl  use  the  cookie
              header  with this content explicitly in all outgoing request(s).
              If multiple requests are done due  to  authentication,  followed
              redirects or similar, they will all get this cookie passed on.

              If  no '=' symbol is used in the argument, it is instead treated
              as a filename to read previously stored cookie from. This option
              also activates the cookie engine which will make curl record in-
              coming cookies, which may be handy if you are using this in com-
              bination  with  the  -L,  --location  option  or do multiple URL
              transfers on the same invoke. If the file name is exactly a  mi-
              nus ("-"), curl will instead read the contents from stdin.

              The file format of the file to read cookies from should be plain
              HTTP headers (Set-Cookie style) or the  Netscape/Mozilla  cookie
              file format.

              The  file  specified with -b, --cookie is only used as input. No
              cookies will be written to the file. To store cookies,  use  the
              -c, --cookie-jar option.

              If  you  use the Set-Cookie file format and do not specify a do-
              main then the cookie is not sent since  the  domain  will  never
              match.  To  address this, set a domain in Set-Cookie line (doing
              that will include sub-domains) or preferably: use  the  Netscape
              format.

              Users  often want to both read cookies from a file and write up-
              dated cookies back to a file, so using both -b, --cookie and -c,
              --cookie-jar in the same command line is common.

              -b, --cookie can be used several times in a command line

              Examples:
               curl -b cookiefile https://example.com
               curl -b cookiefile -c cookiefile https://example.com

              See also -c, --cookie-jar and -j, --junk-session-cookies.

       --create-dirs
              When used in conjunction with the -o, --output option, curl will
              create the necessary local directory hierarchy as  needed.  This
              option  creates  the directories mentioned with the -o, --output
              option, nothing else. If the -o, --output file name uses no  di-
              rectory, or if the directories it mentions already exist, no di-
              rectories will be created.

              Created dirs are made with mode 0750 on unix style file systems.

              To create remote directories when using FTP or SFTP, try  --ftp-
              create-dirs.

              Providing  --create-dirs  multiple  times  has  no extra effect.
              Disable it again with --no-create-dirs.

              Example:
               curl --create-dirs --output local/dir/file https://example.com

              See also --ftp-create-dirs and --output-dir.

       --create-file-mode <mode>
              (SFTP SCP FILE) When curl is used to create files remotely using
              one  of  the supported protocols, this option allows the user to
              set which 'mode' to set on the file at creation time, instead of
              the default 0644.

              This option takes an octal number as argument.

              If  --create-file-mode  is  provided several times, the last set
              value will be used.

              Example:
               curl --create-file-mode 0777 -T localfile sftp://example.com/new

              See also --ftp-create-dirs. Added in 7.75.0.

       --crlf (FTP SMTP)  Convert  LF  to  CRLF  in  upload.  Useful  for  MVS
              (OS/390).

              (SMTP added in 7.40.0)

              Providing --crlf multiple times has no extra effect.  Disable it
              again with --no-crlf.

              Example:
               curl --crlf -T file ftp://example.com/

              See also -B, --use-ascii.

       --crlfile <file>
              (TLS) Provide a file using PEM format with a Certificate Revoca-
              tion List that may specify peer certificates that are to be con-
              sidered revoked.

              If --crlfile is provided several times, the last set value  will
              be used.

              Example:
               curl --crlfile rejects.txt https://example.com

              See also --cacert and --capath.

       --curves <algorithm list>
              (TLS)  Tells  curl  to request specific curves to use during SSL
              session establishment according to RFC 8422, 5.1.  Multiple  al-
              gorithms  can  be  provided  by  separating  them with ":" (e.g.
              "X25519:P-521").  The parameter is available identically in  the
              "openssl s_client/s_server" utilities.

              --curves  allows  a OpenSSL powered curl to make SSL-connections
              with exactly the (EC) curve requested by  the  client,  avoiding
              nontransparent client/server negotiations.

              If  this  option  is  set,  the  default  curves list built into
              openssl will be ignored.

              If --curves is provided several times, the last set  value  will
              be used.

              Example:
               curl --curves X25519 https://example.com

              See also --ciphers. Added in 7.73.0.

       --data-ascii <data>
              (HTTP) This is just an alias for -d, --data.

              --data-ascii can be used several times in a command line

              Example:
               curl --data-ascii @file https://example.com

              See also --data-binary, --data-raw and --data-urlencode.

       --data-binary <data>
              (HTTP)  This  posts data exactly as specified with no extra pro-
              cessing whatsoever.

              If you start the data with the letter @, the rest  should  be  a
              filename. Data is posted in a similar manner as -d, --data does,
              except that newlines and carriage returns are preserved and con-
              versions are never done.

              Like  -d,  --data the default content-type sent to the server is
              application/x-www-form-urlencoded. If you want the  data  to  be
              treated as arbitrary binary data by the server then set the con-
              tent-type to octet-stream: -H "Content-Type:  application/octet-
              stream".

              If  this  option  is  used several times, the ones following the
              first will append data as described in -d, --data.

              --data-binary can be used several times in a command line

              Example:
               curl --data-binary @filename https://example.com

              See also --data-ascii.

       --data-raw <data>
              (HTTP) This posts data similarly to -d, --data but  without  the
              special interpretation of the @ character.

              --data-raw can be used several times in a command line

              Examples:
               curl --data-raw "hello" https://example.com
               curl --data-raw "@at@at@" https://example.com

              See also -d, --data. Added in 7.43.0.

       --data-urlencode <data>
              (HTTP)  This posts data, similar to the other -d, --data options
              with the exception that this performs URL-encoding.

              To be CGI-compliant, the <data> part should begin  with  a  name
              followed  by a separator and a content specification. The <data>
              part can be passed to curl using one of the following syntaxes:

              content
                     This will make curl URL-encode the content and pass  that
                     on.  Just be careful so that the content does not contain
                     any = or @ symbols, as that will  then  make  the  syntax
                     match one of the other cases below!

              =content
                     This  will make curl URL-encode the content and pass that
                     on. The preceding = symbol is not included in the data.

              name=content
                     This will make curl URL-encode the content part and  pass
                     that  on.  Note that the name part is expected to be URL-
                     encoded already.

              @filename
                     This will make curl load data from the  given  file  (in-
                     cluding  any  newlines), URL-encode that data and pass it
                     on in the POST.

              name@filename
                     This will make curl load data from the  given  file  (in-
                     cluding  any  newlines), URL-encode that data and pass it
                     on in the POST. The name part  gets  an  equal  sign  ap-
                     pended,  resulting  in name=urlencoded-file-content. Note
                     that the name is expected to be URL-encoded already.

       --data-urlencode can be used several times in a command line

       Examples:
        curl --data-urlencode name=val https://example.com
        curl --data-urlencode =encodethis https://example.com
        curl --data-urlencode name@file https://example.com
        curl --data-urlencode @fileonly https://example.com

       See also -d, --data and --data-raw.

       -d, --data <data>
              (HTTP MQTT) Sends the specified data in a POST  request  to  the
              HTTP server, in the same way that a browser does when a user has
              filled in an HTML form and presses the submit button. This  will
              cause curl to pass the data to the server using the content-type
              application/x-www-form-urlencoded. Compare to -F, --form.

              --data-raw is almost the same but does not have a special inter-
              pretation  of  the  @ character. To post data purely binary, you
              should instead use the --data-binary option. To  URL-encode  the
              value of a form field you may use --data-urlencode.

              If  any of these options is used more than once on the same com-
              mand line, the data pieces specified will be merged with a sepa-
              rating  &-symbol.  Thus,  using  '-d name=daniel -d skill=lousy'
              would    generate    a    post    chunk    that    looks    like
              'name=daniel&skill=lousy'.

              If  you  start  the data with the letter @, the rest should be a
              file name to read the data from, or - if you want curl  to  read
              the  data  from  stdin.  Posting data from a file named 'foobar'
              would thus be done with -d, --data @foobar. When -d,  --data  is
              told  to  read  from a file like that, carriage returns and new-
              lines will be stripped out. If you do not want the  @  character
              to have a special interpretation use --data-raw instead.

              -d, --data can be used several times in a command line

              Examples:
               curl -d "name=curl" https://example.com
               curl -d "name=curl" -d "tool=cmdline" https://example.com
               curl -d @filename https://example.com

              See  also  --data-binary,  --data-urlencode and --data-raw. This
              option is mutually exclusive to -F, --form and  -I,  --head  and
              -T, --upload-file.

       --delegation <LEVEL>
              (GSS/kerberos)  Set  LEVEL to tell the server what it is allowed
              to delegate when it comes to user credentials.

              none   Do not allow any delegation.

              policy Delegates if and only if the OK-AS-DELEGATE flag  is  set
                     in  the  Kerberos  service  ticket,  which is a matter of
                     realm policy.

              always Unconditionally allow the server to delegate.

       If --delegation is provided several times, the last set value  will  be
       used.

       Example:
        curl --delegation "none" https://example.com

       See also -k, --insecure and --ssl.

       --digest
              (HTTP)  Enables HTTP Digest authentication. This is an authenti-
              cation scheme that prevents the password from  being  sent  over
              the  wire in clear text. Use this in combination with the normal
              -u, --user option to set user name and password.

              Providing --digest multiple times has no extra effect.   Disable
              it again with --no-digest.

              Example:
               curl -u name:password --digest https://example.com

              See  also  -u, --user, --proxy-digest and --anyauth. This option
              is mutually exclusive to --basic and --ntlm and --negotiate.

       --disable-eprt
              (FTP) Tell curl to disable the use of the EPRT and LPRT commands
              when doing active FTP transfers. Curl will normally always first
              attempt to use EPRT, then LPRT before using PORT, but with  this
              option,  it  will  use PORT right away. EPRT and LPRT are exten-
              sions to the original FTP protocol, and  may  not  work  on  all
              servers, but they enable more functionality in a better way than
              the traditional PORT command.

              --eprt can be used to explicitly enable EPRT again and --no-eprt
              is an alias for --disable-eprt.

              If  the  server is accessed using IPv6, this option will have no
              effect as EPRT is necessary then.

              Disabling EPRT only changes the active behavior. If you want  to
              switch  to  passive  mode  you need to not use -P, --ftp-port or
              force it with --ftp-pasv.

              Providing --disable-eprt multiple times  has  no  extra  effect.
              Disable it again with --no-disable-eprt.

              Example:
               curl --disable-eprt ftp://example.com/

              See also --disable-epsv and -P, --ftp-port.

       --disable-epsv
              (FTP)  Tell curl to disable the use of the EPSV command when do-
              ing passive FTP transfers. Curl will normally always  first  at-
              tempt to use EPSV before PASV, but with this option, it will not
              try using EPSV.

              --epsv can be used to explicitly enable EPSV again and --no-epsv
              is an alias for --disable-epsv.

              If  the  server is an IPv6 host, this option will have no effect
              as EPSV is necessary then.

              Disabling EPSV only changes the passive behavior. If you want to
              switch to active mode you need to use -P, --ftp-port.

              Providing  --disable-epsv  multiple  times  has no extra effect.
              Disable it again with --no-disable-epsv.

              Example:
               curl --disable-epsv ftp://example.com/

              See also --disable-eprt and -P, --ftp-port.

       -q, --disable
              If used as the first parameter on the command line,  the  curlrc
              config  file will not be read and used. See the -K, --config for
              details on the default config file search path.

              Providing -q, --disable multiple  times  has  no  extra  effect.
              Disable it again with --no-disable.

              Example:
               curl -q https://example.com

              See also -K, --config.

       --disallow-username-in-url
              (HTTP)  This  tells  curl  to  exit if passed a URL containing a
              username. This is probably most useful when  the  URL  is  being
              provided at runtime or similar.

              Providing --disallow-username-in-url multiple times has no extra
              effect.  Disable it again with --no-disallow-username-in-url.

              Example:
               curl --disallow-username-in-url https://example.com

              See also --proto. Added in 7.61.0.

       --dns-interface <interface>
              (DNS) Tell curl to send outgoing DNS  requests  through  <inter-
              face>.  This  option is a counterpart to --interface (which does
              not affect DNS). The supplied string must be an  interface  name
              (not an address).

              If --dns-interface is provided several times, the last set value
              will be used.

              Example:
               curl --dns-interface eth0 https://example.com

              See also --dns-ipv4-addr  and  --dns-ipv6-addr.  --dns-interface
              requires  that  the  underlying  libcurl was built to support c-
              ares. Added in 7.33.0.

       --dns-ipv4-addr <address>
              (DNS) Tell curl to bind to <ip-address> when making IPv4 DNS re-
              quests,  so  that  the DNS requests originate from this address.
              The argument should be a single IPv4 address.

              If --dns-ipv4-addr is provided several times, the last set value
              will be used.

              Example:
               curl --dns-ipv4-addr 10.1.2.3 https://example.com

              See  also  --dns-interface  and --dns-ipv6-addr. --dns-ipv4-addr
              requires that the underlying libcurl was  built  to  support  c-
              ares. Added in 7.33.0.

       --dns-ipv6-addr <address>
              (DNS) Tell curl to bind to <ip-address> when making IPv6 DNS re-
              quests, so that the DNS requests originate  from  this  address.
              The argument should be a single IPv6 address.

              If --dns-ipv6-addr is provided several times, the last set value
              will be used.

              Example:
               curl --dns-ipv6-addr 2a04:4e42::561 https://example.com

              See also --dns-interface  and  --dns-ipv4-addr.  --dns-ipv6-addr
              requires  that  the  underlying  libcurl was built to support c-
              ares. Added in 7.33.0.

       --dns-servers <addresses>
              Set the list of DNS servers to be used instead of the system de-
              fault.   The  list of IP addresses should be separated with com-
              mas. Port numbers may also optionally be given as :<port-number>
              after each IP address.

              If  --dns-servers  is provided several times, the last set value
              will be used.

              Example:
               curl --dns-servers 192.168.0.1,192.168.0.2 https://example.com

              See also --dns-interface and --dns-ipv4-addr. --dns-servers  re-
              quires  that the underlying libcurl was built to support c-ares.
              Added in 7.33.0.

       --doh-cert-status
              Same as --cert-status but used for DoH (DNS-over-HTTPS).

              Providing --doh-cert-status multiple times has no extra  effect.
              Disable it again with --no-doh-cert-status.

              Example:
               curl --doh-cert-status --doh-url https://doh.example https://example.com

              See also --doh-insecure. Added in 7.76.0.

       --doh-insecure
              Same as -k, --insecure but used for DoH (DNS-over-HTTPS).

              Providing  --doh-insecure  multiple  times  has no extra effect.
              Disable it again with --no-doh-insecure.

              Example:
               curl --doh-insecure --doh-url https://doh.example https://example.com

              See also --doh-url. Added in 7.76.0.

       --doh-url <URL>
              Specifies which DNS-over-HTTPS (DoH) server to  use  to  resolve
              hostnames, instead of using the default name resolver mechanism.
              The URL must be HTTPS.

              Some SSL options that you set for your transfer  will  apply  to
              DoH  since  the  name  lookups take place over SSL. However, the
              certificate verification settings are not inherited and  can  be
              controlled separately via --doh-insecure and --doh-cert-status.

              This  option  is unset if an empty string "" is used as the URL.
              (Added in 7.85.0)

              If --doh-url is provided several times, the last set value  will
              be used.

              Example:
               curl --doh-url https://doh.example https://example.com

              See also --doh-insecure. Added in 7.62.0.

       -D, --dump-header <filename>
              (HTTP  FTP) Write the received protocol headers to the specified
              file. If no headers are received, the use of  this  option  will
              create an empty file.

              When  used  in FTP, the FTP server response lines are considered
              being "headers" and thus are saved there.

              Having multiple transfers in one set  of  operations  (i.e.  the
              URLs  in  one  -:,  --next clause), will append them to the same
              file, separated by a blank line.

              If -D, --dump-header is provided several  times,  the  last  set
              value will be used.

              Example:
               curl --dump-header store.txt https://example.com

              See also -o, --output.

       --egd-file <file>
              (TLS)  Deprecated  option.  This option is ignored by curl since
              7.84.0. Prior to that it only had an effect on curl if built  to
              use old versions of OpenSSL.

              Specify  the  path  name to the Entropy Gathering Daemon socket.
              The socket is used to seed the random  engine  for  SSL  connec-
              tions.

              If --egd-file is provided several times, the last set value will
              be used.

              Example:
               curl --egd-file /random/here https://example.com

              See also --random-file.

       --engine <name>
              (TLS) Select the OpenSSL crypto engine to use for cipher  opera-
              tions. Use --engine list to print a list of build-time supported
              engines. Note that not all (and possibly none)  of  the  engines
              may be available at runtime.

              If  --engine  is provided several times, the last set value will
              be used.

              Example:
               curl --engine flavor https://example.com

              See also --ciphers and --curves.

       --etag-compare <file>
              (HTTP) This option makes a conditional HTTP request for the spe-
              cific ETag read from the given file by sending a custom If-None-
              Match header using the stored ETag.

              For correct results, make sure that the specified file  contains
              only  a  single  line  with  the  desired ETag. An empty file is
              parsed as an empty ETag.

              Use the option --etag-save to first save the  ETag  from  a  re-
              sponse,  and  then  use this option to compare against the saved
              ETag in a subsequent request.

              If --etag-compare is provided several times, the last set  value
              will be used.

              Example:
               curl --etag-compare etag.txt https://example.com

              See also --etag-save and -z, --time-cond. Added in 7.68.0.

       --etag-save <file>
              (HTTP)  This option saves an HTTP ETag to the specified file. An
              ETag is a caching related header,  usually  returned  in  a  re-
              sponse.

              If no ETag is sent by the server, an empty file is created.

              If  --etag-save  is  provided  several times, the last set value
              will be used.

              Example:
               curl --etag-save storetag.txt https://example.com

              See also --etag-compare. Added in 7.68.0.

       --expect100-timeout <seconds>
              (HTTP) Maximum time in seconds that you allow curl to wait for a
              100-continue  response  when curl emits an Expects: 100-continue
              header in its request. By default curl  will  wait  one  second.
              This  option accepts decimal values! When curl stops waiting, it
              will continue as if the response has been received.

              The decimal value needs to provided using a dot (.)  as  decimal
              separator  - not the local version even if it might be using an-
              other separator.

              If --expect100-timeout is provided several times, the  last  set
              value will be used.

              Example:
               curl --expect100-timeout 2.5 -T file https://example.com

              See also --connect-timeout. Added in 7.47.0.

       --fail-early
              Fail and exit on the first detected transfer error.

              When  curl is used to do multiple transfers on the command line,
              it will attempt to operate on each given URL, one by one. By de-
              fault,  it  will  ignore errors if there are more URLs given and
              the last URL's success will determine the error  code  curl  re-
              turns. So early failures will be "hidden" by subsequent success-
              ful transfers.

              Using this option, curl will instead  return  an  error  on  the
              first  transfer  that  fails,  independent of the amount of URLs
              that are given on the command line. This way, no transfer  fail-
              ures go undetected by scripts and similar.

              This option is global and does not need to be specified for each
              use of -:, --next.

              This option does not imply -f, --fail, which causes transfers to
              fail  due  to the server's HTTP status code. You can combine the
              two options, however note -f, --fail is not global and is there-
              fore contained by -:, --next.

              Providing --fail-early multiple times has no extra effect.  Dis-
              able it again with --no-fail-early.

              Example:
               curl --fail-early https://example.com https://two.example

              See also -f, --fail and --fail-with-body. Added in 7.52.0.

       --fail-with-body
              (HTTP) Return an error on server errors where the HTTP  response
              code  is  400  or  greater). In normal cases when an HTTP server
              fails to deliver a document, it returns an HTML document stating
              so  (which  often  also  describes why and more). This flag will
              still allow curl to output and save that content but also to re-
              turn error 22.

              This  is  an  alternative  option to -f, --fail which makes curl
              fail for the same circumstances but without saving the content.

              Providing --fail-with-body multiple times has no  extra  effect.
              Disable it again with --no-fail-with-body.

              Example:
               curl --fail-with-body https://example.com

              See  also  -f,  --fail. This option is mutually exclusive to -f,
              --fail. Added in 7.76.0.

       -f, --fail
              (HTTP) Fail fast with no output at all on server errors. This is
              useful  to  enable  scripts and users to better deal with failed
              attempts. In normal cases when an HTTP server fails to deliver a
              document,  it  returns  an HTML document stating so (which often
              also describes why and more). This flag will prevent  curl  from
              outputting that and return error 22.

              This  method is not fail-safe and there are occasions where non-
              successful response codes will slip through, especially when au-
              thentication is involved (response codes 401 and 407).

              Providing  -f,  --fail multiple times has no extra effect.  Dis-
              able it again with --no-fail.

              Example:
               curl --fail https://example.com

              See also --fail-with-body. This option is mutually exclusive  to
              --fail-with-body.

       --false-start
              (TLS)  Tells  curl  to use false start during the TLS handshake.
              False start is a mode where a TLS client will start sending  ap-
              plication  data  before verifying the server's Finished message,
              thus saving a round trip when performing a full handshake.

              This is currently only implemented in the NSS and Secure  Trans-
              port (on iOS 7.0 or later, or OS X 10.9 or later) backends.

              Providing  --false-start  multiple  times  has  no extra effect.
              Disable it again with --no-false-start.

              Example:
               curl --false-start https://example.com

              See also --tcp-fastopen. Added in 7.42.0.

       --form-escape
              (HTTP) Tells curl to pass on names of multipart form fields  and
              files using backslash-escaping instead of percent-encoding.

              If  --form-escape  is provided several times, the last set value
              will be used.

              Example:
               curl --form-escape -F 'field\name=curl' -F 'file=@load"this' https://example.com

              See also -F, --form. Added in 7.81.0.

       --form-string <name=string>
              (HTTP SMTP IMAP) Similar to -F, --form  except  that  the  value
              string  for  the  named parameter is used literally. Leading '@'
              and '<' characters, and the ';type=' string in the value have no
              special meaning. Use this in preference to -F, --form if there's
              any possibility that the string value may  accidentally  trigger
              the '@' or '<' features of -F, --form.

              --form-string can be used several times in a command line

              Example:
               curl --form-string "data" https://example.com

              See also -F, --form.

       -F, --form <name=content>
              (HTTP  SMTP  IMAP) For HTTP protocol family, this lets curl emu-
              late a filled-in form in which a user  has  pressed  the  submit
              button.  This  causes  curl  to POST data using the Content-Type
              multipart/form-data according to RFC 2388.

              For SMTP and IMAP protocols, this is the means to compose a mul-
              tipart mail message to transmit.

              This  enables  uploading of binary files etc. To force the 'con-
              tent' part to be a file, prefix the file name with an @ sign. To
              just get the content part from a file, prefix the file name with
              the symbol <. The difference between @ and  <  is  then  that  @
              makes  a  file  get attached in the post as a file upload, while
              the < makes a text field and just get the contents for that text
              field from a file.

              Tell  curl to read content from stdin instead of a file by using
              - as filename. This goes for both @ and < constructs. When stdin
              is used, the contents is buffered in memory first by curl to de-
              termine its size and allow a possible resend. Defining a  part's
              data from a named non-regular file (such as a named pipe or sim-
              ilar) is unfortunately not subject to buffering and will be  ef-
              fectively  read at transmission time; since the full size is un-
              known before the transfer starts, such data is sent as chunks by
              HTTP and rejected by IMAP.

              Example: send an image to an HTTP server, where 'profile' is the
              name of the form-field to which the file  portrait.jpg  will  be
              the input:

               curl -F profile=@portrait.jpg https://example.com/upload.cgi

              Example:  send your name and shoe size in two text fields to the
              server:

               curl -F name=John -F shoesize=11 https://example.com/

              Example: send your essay in a text field to the server. Send  it
              as  a plain text field, but get the contents for it from a local
              file:

               curl -F "story=<hugefile.txt" https://example.com/

              You can also  tell  curl  what  Content-Type  to  use  by  using
              'type=', in a manner similar to:

               curl -F "web=@index.html;type=text/html" example.com

              or

               curl -F "name=daniel;type=text/foo" example.com

              You  can  also explicitly change the name field of a file upload
              part by setting filename=, like this:

               curl -F "file=@localfile;filename=nameinpost" example.com

              If filename/path contains ',' or ';', it must be quoted by  dou-
              ble-quotes like:

               curl -F "file=@\"local,file\";filename=\"name;in;post\"" example.com

              or

               curl -F 'file=@"local,file";filename="name;in;post"' example.com

              Note  that  if  a  filename/path is quoted by double-quotes, any
              double-quote or backslash within the filename must be escaped by
              backslash.

              Quoting  must  also  be  applied to non-file data if it contains
              semicolons, leading/trailing spaces or leading double quotes:

               curl -F 'colors="red; green; blue";type=text/x-myapp' example.com

              You can add custom headers to the  field  by  setting  headers=,
              like

                curl -F "submit=OK;headers=\"X-submit-type: OK\"" example.com

              or

                curl -F "submit=OK;headers=@headerfile" example.com

              The  headers=  keyword may appear more that once and above notes
              about quoting apply. When headers are read from  a  file,  Empty
              lines and lines starting with '#' are comments and ignored; each
              header can be folded by splitting between two words and starting
              the  continuation  line  with a space; embedded carriage-returns
              and trailing spaces are stripped.   Here  is  an  example  of  a
              header file contents:

                # This file contain two headers.
                X-header-1: this is a header

                # The following header is folded.
                X-header-2: this is
                 another header

              To  support  sending  multipart mail messages, the syntax is ex-
              tended as follows:
              - name can be omitted: the equal sign is the first character  of
              the argument,
              -  if  data  starts with '(', this signals to start a new multi-
              part: it can be followed by a content type specification.
              - a multipart can be terminated with a '=)' argument.

              Example: the following command sends an SMTP mime email consist-
              ing in an inline part in two alternative formats: plain text and
              HTML. It attaches a text file:

               curl -F '=(;type=multipart/alternative' \
                    -F '=plain text message' \
                    -F '= <body>HTML message</body>;type=text/html' \
                    -F '=)' -F '=@textfile.txt' ...  smtp://example.com

              Data can be encoded for transfer using encoder=.  Available  en-
              codings are binary and 8bit that do nothing else than adding the
              corresponding Content-Transfer-Encoding header, 7bit  that  only
              rejects 8-bit characters with a transfer error, quoted-printable
              and base64 that encodes  data  according  to  the  corresponding
              schemes, limiting lines length to 76 characters.

              Example:  send  multipart mail with a quoted-printable text mes-
              sage and a base64 attached file:

               curl -F '=text message;encoder=quoted-printable' \
                    -F '=@localfile;encoder=base64' ... smtp://example.com

              See further examples and details in the MANUAL.

              -F, --form can be used several times in a command line

              Example:
               curl --form "name=curl" --form "file=@loadthis" https://example.com

              See also -d, --data, --form-string and --form-escape.  This  op-
              tion  is mutually exclusive to -d, --data and -I, --head and -T,
              --upload-file.

       --ftp-account <data>
              (FTP) When an FTP server asks for "account data" after user name
              and  password has been provided, this data is sent off using the
              ACCT command.

              If --ftp-account is provided several times, the last  set  value
              will be used.

              Example:
               curl --ftp-account "mr.robot" ftp://example.com/

              See also -u, --user.

       --ftp-alternative-to-user <command>
              (FTP)  If  authenticating with the USER and PASS commands fails,
              send this  command.   When  connecting  to  Tumbleweed's  Secure
              Transport  server  over  FTPS  using a client certificate, using
              "SITE AUTH" will tell the server to retrieve the  username  from
              the certificate.

              If --ftp-alternative-to-user is provided several times, the last
              set value will be used.

              Example:
               curl --ftp-alternative-to-user "U53r" ftp://example.com

              See also --ftp-account and -u, --user.

       --ftp-create-dirs
              (FTP SFTP) When an FTP or SFTP URL/operation uses  a  path  that
              does not currently exist on the server, the standard behavior of
              curl is to fail. Using this option, curl will instead attempt to
              create missing directories.

              Providing  --ftp-create-dirs multiple times has no extra effect.
              Disable it again with --no-ftp-create-dirs.

              Example:
               curl --ftp-create-dirs -T file ftp://example.com/remote/path/file

              See also --create-dirs.

       --ftp-method <method>
              (FTP) Control what method curl should use to reach a file on  an
              FTP(S)  server. The method argument should be one of the follow-
              ing alternatives:

              multicwd
                     curl does a single CWD operation for each  path  part  in
                     the  given URL. For deep hierarchies this means many com-
                     mands. This is how RFC 1738 says it should be done.  This
                     is the default but the slowest behavior.

              nocwd  curl  does  no  CWD at all. curl will do SIZE, RETR, STOR
                     etc and give a full path to the server for all these com-
                     mands. This is the fastest behavior.

              singlecwd
                     curl does one CWD with the full target directory and then
                     operates on the file "normally"  (like  in  the  multicwd
                     case).  This  is  somewhat  more standards compliant than
                     'nocwd' but without the full penalty of 'multicwd'.

       If --ftp-method is provided several times, the last set value  will  be
       used.

       Examples:
        curl --ftp-method multicwd ftp://example.com/dir1/dir2/file
        curl --ftp-method nocwd ftp://example.com/dir1/dir2/file
        curl --ftp-method singlecwd ftp://example.com/dir1/dir2/file

       See also -l, --list-only.

       --ftp-pasv
              (FTP)  Use  passive mode for the data connection. Passive is the
              internal default behavior, but using this option can be used  to
              override a previous -P, --ftp-port option.

              Reversing  an enforced passive really is not doable but you must
              then instead enforce the correct -P, --ftp-port again.

              Passive mode means that curl will try the EPSV command first and
              then PASV, unless --disable-epsv is used.

              Providing  --ftp-pasv  multiple times has no extra effect.  Dis-
              able it again with --no-ftp-pasv.

              Example:
               curl --ftp-pasv ftp://example.com/

              See also --disable-epsv.

       -P, --ftp-port <address>
              (FTP) Reverses the default initiator/listener  roles  when  con-
              necting  with  FTP. This option makes curl use active mode. curl
              then tells the server to connect back to the client's  specified
              address and port, while passive mode asks the server to setup an
              IP address and port for it to connect to.  <address>  should  be
              one of:

              interface
                     e.g.  "eth0"  to specify which interface's IP address you
                     want to use (Unix only)

              IP address
                     e.g. "192.168.10.1" to specify the exact IP address

              host name
                     e.g. "my.host.domain" to specify the machine

              -      make curl pick the same IP address that is  already  used
                     for the control connection

       Disable the use of PORT with --ftp-pasv. Disable the attempt to use the
       EPRT command instead of PORT by using --disable-eprt.  EPRT  is  really
       PORT++.

       You  can  also  append ":[start]-[end]" to the right of the address, to
       tell curl what TCP port range to use. That means  you  specify  a  port
       range,  from a lower to a higher number. A single number works as well,
       but do note that it increases the risk of failure since  the  port  may
       not be available.

       If -P, --ftp-port is provided several times, the last set value will be
       used.

       Examples:
        curl -P - ftp:/example.com
        curl -P eth0 ftp:/example.com
        curl -P 192.168.0.2 ftp:/example.com

       See also --ftp-pasv and --disable-eprt.

       --ftp-pret
              (FTP) Tell curl to send a PRET command before PASV  (and  EPSV).
              Certain  FTP  servers,  mainly drftpd, require this non-standard
              command for directory listings as well as up  and  downloads  in
              PASV mode.

              Providing  --ftp-pret  multiple times has no extra effect.  Dis-
              able it again with --no-ftp-pret.

              Example:
               curl --ftp-pret ftp://example.com/

              See also -P, --ftp-port and --ftp-pasv.

       --ftp-skip-pasv-ip
              (FTP) Tell curl to not use the IP address the server suggests in
              its  response to curl's PASV command when curl connects the data
              connection. Instead curl will re-use the same IP address it  al-
              ready uses for the control connection.

              Since curl 7.74.0 this option is enabled by default.

              This  option has no effect if PORT, EPRT or EPSV is used instead
              of PASV.

              Providing --ftp-skip-pasv-ip multiple times has no extra effect.
              Disable it again with --no-ftp-skip-pasv-ip.

              Example:
               curl --ftp-skip-pasv-ip ftp://example.com/

              See also --ftp-pasv.

       --ftp-ssl-ccc-mode <active/passive>
              (FTP)  Sets the CCC mode. The passive mode will not initiate the
              shutdown, but instead wait for the server to do it, and will not
              reply to the shutdown from the server. The active mode initiates
              the shutdown and waits for a reply from the server.

              Providing --ftp-ssl-ccc-mode multiple times has no extra effect.
              Disable it again with --no-ftp-ssl-ccc-mode.

              Example:
               curl --ftp-ssl-ccc-mode active --ftp-ssl-ccc ftps://example.com/

              See also --ftp-ssl-ccc.

       --ftp-ssl-ccc
              (FTP)  Use  CCC  (Clear  Command Channel) Shuts down the SSL/TLS
              layer after authenticating. The rest of the control channel com-
              munication  will be unencrypted. This allows NAT routers to fol-
              low the FTP transaction. The default mode is passive.

              Providing --ftp-ssl-ccc multiple  times  has  no  extra  effect.
              Disable it again with --no-ftp-ssl-ccc.

              Example:
               curl --ftp-ssl-ccc ftps://example.com/

              See also --ssl and --ftp-ssl-ccc-mode.

       --ftp-ssl-control
              (FTP)  Require  SSL/TLS  for  the FTP login, clear for transfer.
              Allows secure authentication, but non-encrypted  data  transfers
              for  efficiency.  Fails the transfer if the server does not sup-
              port SSL/TLS.

              Providing --ftp-ssl-control multiple times has no extra  effect.
              Disable it again with --no-ftp-ssl-control.

              Example:
               curl --ftp-ssl-control ftp://example.com

              See also --ssl.

       -G, --get
              When  used,  this  option  will make all data specified with -d,
              --data, --data-binary or --data-urlencode to be used in an  HTTP
              GET  request instead of the POST request that otherwise would be
              used. The data will be appended to the URL with a '?' separator.

              If used in combination with -I, --head, the POST data  will  in-
              stead be appended to the URL with a HEAD request.

              Providing -G, --get multiple times has no extra effect.  Disable
              it again with --no-get.

              Examples:
               curl --get https://example.com
               curl --get -d "tool=curl" -d "age=old" https://example.com
               curl --get -I -d "tool=curl" https://example.com

              See also -d, --data and -X, --request.

       -g, --globoff
              This option switches off the "URL globbing parser". When you set
              this  option, you can specify URLs that contain the letters {}[]
              without having curl itself interpret them. Note that these  let-
              ters  are  not  normal legal URL contents but they should be en-
              coded according to the URI standard.

              Providing -g, --globoff multiple  times  has  no  extra  effect.
              Disable it again with --no-globoff.

              Example:
               curl -g "https://example.com/{[]}}}}"

              See also -K, --config and -q, --disable.

       --happy-eyeballs-timeout-ms <milliseconds>
              Happy  Eyeballs is an algorithm that attempts to connect to both
              IPv4 and IPv6 addresses for  dual-stack  hosts,  giving  IPv6  a
              head-start  of the specified number of milliseconds. If the IPv6
              address cannot be connected to within that time, then a  connec-
              tion  attempt is made to the IPv4 address in parallel. The first
              connection to be established is the one that is used.

              The range of suggested useful values is limited. Happy  Eyeballs
              RFC  6555  says  "It  is RECOMMENDED that connection attempts be
              paced 150-250 ms apart to balance human factors against  network
              load."  libcurl currently defaults to 200 ms. Firefox and Chrome
              currently default to 300 ms.

              If --happy-eyeballs-timeout-ms is provided  several  times,  the
              last set value will be used.

              Example:
               curl --happy-eyeballs-timeout-ms 500 https://example.com

              See also -m, --max-time and --connect-timeout. Added in 7.59.0.

       --haproxy-protocol
              (HTTP)  Send a HAProxy PROXY protocol v1 header at the beginning
              of the connection. This is used by some load balancers  and  re-
              verse proxies to indicate the client's true IP address and port.

              This  option is primarily useful when sending test requests to a
              service that expects this header.

              Providing --haproxy-protocol multiple times has no extra effect.
              Disable it again with --no-haproxy-protocol.

              Example:
               curl --haproxy-protocol https://example.com

              See also -x, --proxy. Added in 7.60.0.

       -I, --head
              (HTTP FTP FILE) Fetch the headers only! HTTP-servers feature the
              command HEAD which this uses to get nothing but the header of  a
              document.  When  used  on an FTP or FILE file, curl displays the
              file size and last modification time only.

              Providing -I, --head multiple times has no extra  effect.   Dis-
              able it again with --no-head.

              Example:
               curl -I https://example.com

              See also -G, --get, -v, --verbose and --trace-ascii.

       -H, --header <header/@file>
              (HTTP  IMAP  SMTP)  Extra header to include in information sent.
              When used within an HTTP request, it is added to the regular re-
              quest headers.

              For an IMAP or SMTP MIME uploaded mail built with -F, --form op-
              tions, it is prepended to the resulting  MIME  document,  effec-
              tively including it at the mail global level. It does not affect
              raw uploaded mails (Added in 7.56.0).

              You may specify any number of extra headers. Note  that  if  you
              should  add a custom header that has the same name as one of the
              internal ones curl would use, your externally set header will be
              used  instead of the internal one.  This allows you to make even
              trickier stuff than curl would normally do. You should  not  re-
              place internally set headers without knowing perfectly well what
              you are doing. Remove an internal header by giving a replacement
              without  content  on  the  right  side  of  the colon, as in: -H
              "Host:". If you send the custom header with  no-value  then  its
              header  must  be terminated with a semicolon, such as -H "X-Cus-
              tom-Header;" to send "X-Custom-Header:".

              curl will make sure that each header  you  add/replace  is  sent
              with the proper end-of-line marker, you should thus not add that
              as a part of the header content: do not add newlines or carriage
              returns, they will only mess things up for you.

              This  option can take an argument in @filename style, which then
              adds a header for each line in the input  file.  Using  @-  will
              make curl read the header file from stdin. Added in 7.55.0.

              Please note that most anti-spam utilities check the presence and
              value of several MIME mail headers: these  are  "From:",  "To:",
              "Date:"  and  "Subject:"  among  others and should be added with
              this option.

              You need --proxy-header to send custom headers intended  for  an
              HTTP proxy. Added in 7.37.0.

              Passing  on  a "Transfer-Encoding: chunked" header when doing an
              HTTP request with a request body, will make curl send  the  data
              using chunked encoding.

              WARNING:  headers  set  with this option will be set in all HTTP
              requests - even after redirects are  followed,  like  when  told
              with  -L,  --location. This can lead to the header being sent to
              other hosts than the original host, so sensitive headers  should
              be used with caution combined with following redirects.

              -H, --header can be used several times in a command line

              Examples:
               curl -H "X-First-Name: Joe" https://example.com
               curl -H "User-Agent: yes-please/2000" https://example.com
               curl -H "Host:" https://example.com
               curl -H @headers.txt https://example.com

              See also -A, --user-agent and -e, --referer.

       -h, --help <category>
              Usage  help.  This  lists all commands of the <category>.  If no
              arg was provided, curl will display the most  important  command
              line  arguments.   If the argument "all" was provided, curl will
              display all options available.  If the argument  "category"  was
              provided, curl will display all categories and their meanings.

              Example:
               curl --help all

              See also -v, --verbose.

       --hostpubmd5 <md5>
              (SFTP  SCP)  Pass a string containing 32 hexadecimal digits. The
              string should be the 128 bit MD5 checksum of the  remote  host's
              public key, curl will refuse the connection with the host unless
              the md5sums match.

              If --hostpubmd5 is provided several times, the  last  set  value
              will be used.

              Example:
               curl --hostpubmd5 e5c1c49020640a5ab0f2034854c321a8 sftp://example.com/

              See also --hostpubsha256.

       --hostpubsha256 <sha256>
              (SFTP SCP) Pass a string containing a Base64-encoded SHA256 hash
              of the remote host's public key. Curl will refuse the connection
              with the host unless the hashes match.

              This  feature requires libcurl to be built with libssh2 and does
              not work with other SSH backends.

              If --hostpubsha256 is provided several times, the last set value
              will be used.

              Example:
               curl --hostpubsha256 NDVkMTQxMGQ1ODdmMjQ3MjczYjAyOTY5MmRkMjVmNDQ= sftp://example.com/

              See also --hostpubmd5. Added in 7.80.0.

       --hsts <file name>
              (HTTPS)  This  option enables HSTS for the transfer. If the file
              name points to an existing HSTS cache file, that will  be  used.
              After  a completed transfer, the cache will be saved to the file
              name again if it has been modified.

              If curl is told to use HTTP:// for a transfer involving  a  host
              name  that exists in the HSTS cache, it upgrades the transfer to
              use HTTPS. Each HSTS cache entry has an individual life time af-
              ter which the upgrade is no longer performed.

              Specify a "" file name (zero length) to avoid loading/saving and
              make curl just handle HSTS in memory.

              If this option is used several times, curl  will  load  contents
              from all the files but the last one will be used for saving.

              --hsts can be used several times in a command line

              Example:
               curl --hsts cache.txt https://example.com

              See also --proto. Added in 7.74.0.

       --http0.9
              (HTTP) Tells curl to be fine with HTTP version 0.9 response.

              HTTP/0.9  is  a completely headerless response and therefore you
              can also connect with this to non-HTTP servers and still  get  a
              response since curl will simply transparently downgrade - if al-
              lowed.

              Since curl 7.66.0, HTTP/0.9 is disabled by default.

              Providing --http0.9 multiple times has no extra effect.  Disable
              it again with --no-http0.9.

              Example:
               curl --http0.9 https://example.com

              See also --http1.1, --http2 and --http3. Added in 7.64.0.

       -0, --http1.0
              (HTTP)  Tells  curl to use HTTP version 1.0 instead of using its
              internally preferred HTTP version.

              Providing -0, --http1.0 multiple times has no extra effect.

              Example:
               curl --http1.0 https://example.com

              See also --http0.9 and --http1.1. This option is mutually exclu-
              sive  to  --http1.1  and --http2 and --http2-prior-knowledge and
              --http3.

       --http1.1
              (HTTP) Tells curl to use HTTP version 1.1.

              Providing --http1.1 multiple times has no extra effect.

              Example:
               curl --http1.1 https://example.com

              See also -0, --http1.0 and --http0.9. This  option  is  mutually
              exclusive  to -0, --http1.0 and --http2 and --http2-prior-knowl-
              edge and --http3. Added in 7.33.0.

       --http2-prior-knowledge
              (HTTP) Tells curl to  issue  its  non-TLS  HTTP  requests  using
              HTTP/2  without  HTTP/1.1  Upgrade.  It requires prior knowledge
              that the server supports HTTP/2 straight  away.  HTTPS  requests
              will  still  do HTTP/2 the standard way with negotiated protocol
              version in the TLS handshake.

              Providing --http2-prior-knowledge multiple times  has  no  extra
              effect.  Disable it again with --no-http2-prior-knowledge.

              Example:
               curl --http2-prior-knowledge https://example.com

              See  also  --http2 and --http3. --http2-prior-knowledge requires
              that the underlying libcurl was built to  support  HTTP/2.  This
              option  is mutually exclusive to --http1.1 and -0, --http1.0 and
              --http2 and --http3. Added in 7.49.0.

       --http2
              (HTTP) Tells curl to use HTTP version 2.

              For HTTPS, this means curl will attempt to negotiate  HTTP/2  in
              the TLS handshake. curl does this by default.

              For HTTP, this means curl will attempt to upgrade the request to
              HTTP/2 using the Upgrade: request header.

              When curl uses HTTP/2 over HTTPS, it does not itself  insist  on
              TLS 1.2 or higher even though that is required by the specifica-
              tion. A user can add this version requirement with --tlsv1.2.

              Providing --http2 multiple times has no extra effect.

              Example:
               curl --http2 https://example.com

              See also --http1.1 and --http3. --http2 requires that the under-
              lying  libcurl was built to support HTTP/2. This option is mutu-
              ally exclusive to --http1.1 and -0, --http1.0 and --http2-prior-
              knowledge and --http3. Added in 7.33.0.

       --http3-only
              (HTTP)  **WARNING**:  this option is experimental. Do not use in
              production.

              Instructs curl to use HTTP/3 to the host in  the  URL,  with  no
              fallback  to  earlier HTTP versions. HTTP/3 can only be used for
              HTTPS and not for HTTP URLs. For HTTP, this option will  trigger
              an error.

              This  option  allows a user to avoid using the Alt-Svc method of
              upgrading to HTTP/3 when you know that the target speaks  HTTP/3
              on the given host and port.

              This  option  will make curl fail if a QUIC connection cannot be
              established, it will not attempt any other HTTP version  on  its
              own. Use --http3 for similar functionality with a fallback.

              Providing --http3-only multiple times has no extra effect.

              Example:
               curl --http3-only https://example.com

              See  also  --http1.1, --http2 and --http3. --http3-only requires
              that the underlying libcurl was built to  support  HTTP/3.  This
              option  is mutually exclusive to --http1.1 and -0, --http1.0 and
              --http2  and  --http2-prior-knowledge  and  --http3.  Added   in
              7.88.0.

       --http3
              (HTTP)  **WARNING**:  this option is experimental. Do not use in
              production.

              Tells curl to try HTTP/3 to the host in the URL, but fallback to
              earlier  HTTP  versions  if  the HTTP/3 connection establishment
              fails. HTTP/3 is only available for HTTPS and not for HTTP URLs.

              This option allows a user to avoid using the Alt-Svc  method  of
              upgrading  to HTTP/3 when you know that the target speaks HTTP/3
              on the given host and port.

              When asked to use HTTP/3, curl will issue a separate attempt  to
              use  older  HTTP  versions with a slight delay, so if the HTTP/3
              transfer fails or is very slow, curl will still try  to  proceed
              with an older HTTP version.

              Use --http3-only for similar functionality without a fallback.

              Providing --http3 multiple times has no extra effect.

              Example:
               curl --http3 https://example.com

              See also --http1.1 and --http2. --http3 requires that the under-
              lying libcurl was built to support HTTP/3. This option is  mutu-
              ally  exclusive  to  --http1.1 and -0, --http1.0 and --http2 and
              --http2-prior-knowledge and --http3-only. Added in 7.66.0.

       --ignore-content-length
              (FTP HTTP) For HTTP, Ignore the Content-Length header.  This  is
              particularly  useful  for servers running Apache 1.x, which will
              report incorrect Content-Length for files larger  than  2  giga-
              bytes.

              For  FTP (since 7.46.0), skip the RETR command to figure out the
              size before downloading a file.

              This option does not work for HTTP if libcurl was built  to  use
              hyper.

              Providing  --ignore-content-length  multiple  times has no extra
              effect.  Disable it again with --no-ignore-content-length.

              Example:
               curl --ignore-content-length https://example.com

              See also --ftp-skip-pasv-ip.

       -i, --include
              Include the HTTP response headers in the output.  The  HTTP  re-
              sponse  headers  can  include  things like server name, cookies,
              date of the document, HTTP version and more...

              To view the request headers, consider the -v, --verbose option.

              Providing -i, --include multiple  times  has  no  extra  effect.
              Disable it again with --no-include.

              Example:
               curl -i https://example.com

              See also -v, --verbose.

       -k, --insecure
              (TLS SFTP SCP) By default, every secure connection curl makes is
              verified to be secure before the transfer takes place. This  op-
              tion  makes  curl skip the verification step and proceed without
              checking.

              When this option is not used for protocols using TLS, curl veri-
              fies  the server's TLS certificate before it continues: that the
              certificate contains the right name which matches the host  name
              used in the URL and that the certificate has been signed by a CA
              certificate present in the cert store.  See this online resource
              for further details:
               https://curl.se/docs/sslcerts.html

              For  SFTP  and  SCP, this option makes curl skip the known_hosts
              verification.  known_hosts is a  file  normally  stored  in  the
              user's home directory in the ".ssh" subdirectory, which contains
              host names and their public keys.

              WARNING: using this option makes the transfer insecure.

              When curl uses secure protocols it trusts responses  and  allows
              for  example  HSTS and Alt-Svc information to be stored and used
              subsequently. Using -k, --insecure can make curl trust  and  use
              such information from malicious servers.

              Providing  -k,  --insecure  multiple  times has no extra effect.
              Disable it again with --no-insecure.

              Example:
               curl --insecure https://example.com

              See also --proxy-insecure, --cacert and --capath.

       --interface <name>
              Perform an operation using a specified interface. You can  enter
              interface  name,  IP address or host name. An example could look
              like:

               curl --interface eth0:1 https://www.example.com/

              On Linux it can be used to specify a VRF, but the  binary  needs
              to  either  have CAP_NET_RAW or to be run as root. More informa-
              tion  about  Linux  VRF:   https://www.kernel.org/doc/Documenta-
              tion/networking/vrf.txt

              If  --interface  is  provided  several times, the last set value
              will be used.

              Example:
               curl --interface eth0 https://example.com

              See also --dns-interface.

       -4, --ipv4
              This option tells curl to use IPv4 addresses only, and  not  for
              example try IPv6.

              Providing  -4,  --ipv4 multiple times has no extra effect.  Dis-
              able it again with --no-ipv4.

              Example:
               curl --ipv4 https://example.com

              See also --http1.1 and --http2. This option is  mutually  exclu-
              sive to -6, --ipv6.

       -6, --ipv6
              This  option  tells curl to use IPv6 addresses only, and not for
              example try IPv4.

              Providing -6, --ipv6 multiple times has no extra  effect.   Dis-
              able it again with --no-ipv6.

              Example:
               curl --ipv6 https://example.com

              See  also  --http1.1 and --http2. This option is mutually exclu-
              sive to -4, --ipv4.

       --json <data>
              (HTTP) Sends the specified JSON data in a POST  request  to  the
              HTTP  server.  --json  works  as a shortcut for passing on these
              three options:

               --data [arg]
               --header "Content-Type: application/json"
               --header "Accept: application/json"

              There is no verification that the passed in data is actual  JSON
              or that the syntax is correct.

              If  you  start  the data with the letter @, the rest should be a
              file name to read the data from, or a single  dash  (-)  if  you
              want  curl to read the data from stdin. Posting data from a file
              named 'foobar' would thus be done with --json @foobar and to in-
              stead read the data from stdin, use --json @-.

              If  this option is used more than once on the same command line,
              the additional data pieces will be concatenated to the  previous
              before sending.

              The headers this option sets can be overridden with -H, --header
              as usual.

              --json can be used several times in a command line

              Examples:
               curl --json '{ "drink": "coffe" }' https://example.com
               curl --json '{ "drink":' --json ' "coffe" }' https://example.com
               curl --json @prepared https://example.com
               curl --json @- https://example.com < json.txt

              See also --data-binary and --data-raw. This option  is  mutually
              exclusive  to  -F,  --form and -I, --head and -T, --upload-file.
              Added in 7.82.0.

       -j, --junk-session-cookies
              (HTTP) When curl is told to read cookies from a given file, this
              option will make it discard all "session cookies". This will ba-
              sically have the same effect as if a  new  session  is  started.
              Typical  browsers  always  discard session cookies when they are
              closed down.

              Providing -j, --junk-session-cookies multiple times has no extra
              effect.  Disable it again with --no-junk-session-cookies.

              Example:
               curl --junk-session-cookies -b cookies.txt https://example.com

              See also -b, --cookie and -c, --cookie-jar.

       --keepalive-time <seconds>
              This  option sets the time a connection needs to remain idle be-
              fore sending keepalive probes and the  time  between  individual
              keepalive probes. It is currently effective on operating systems
              offering  the  TCP_KEEPIDLE  and  TCP_KEEPINTVL  socket  options
              (meaning  Linux,  recent  AIX,  HP-UX and more).  Keepalives are
              used by the TCP stack to detect broken networks on idle  connec-
              tions.  The  number  of missed keepalive probes before declaring
              the connection down is OS dependent and is  commonly  9  or  10.
              This option has no effect if --no-keepalive is used.

              If unspecified, the option defaults to 60 seconds.

              If  --keepalive-time  is  provided  several  times, the last set
              value will be used.

              Example:
               curl --keepalive-time 20 https://example.com

              See also --no-keepalive and -m, --max-time.

       --key-type <type>
              (TLS) Private key file type. Specify which type your --key  pro-
              vided  private  key  is. DER, PEM, and ENG are supported. If not
              specified, PEM is assumed.

              If --key-type is provided several times, the last set value will
              be used.

              Example:
               curl --key-type DER --key here https://example.com

              See also --key.

       --key <key>
              (TLS SSH) Private key file name. Allows you to provide your pri-
              vate key in this separate file. For SSH, if not specified,  curl
              tries   the  following  candidates  in  order:  '~/.ssh/id_rsa',
              '~/.ssh/id_dsa', './id_rsa', './id_dsa'.

              If curl is built against OpenSSL library, and the engine  pkcs11
              is available, then a PKCS#11 URI (RFC 7512) can be used to spec-
              ify a private key located in a PKCS#11 device. A  string  begin-
              ning  with  "pkcs11:" will be interpreted as a PKCS#11 URI. If a
              PKCS#11 URI is provided, then the --engine option will be set as
              "pkcs11"  if none was provided and the --key-type option will be
              set as "ENG" if none was provided.

              If curl is built against Secure Transport or Schannel then  this
              option is ignored for TLS protocols (HTTPS, etc). Those backends
              expect the private key to be already present in the keychain  or
              PKCS#12 file containing the certificate.

              If  --key  is provided several times, the last set value will be
              used.

              Example:
               curl --cert certificate --key here https://example.com

              See also --key-type and -E, --cert.

       --krb <level>
              (FTP) Enable Kerberos authentication and use. The level must  be
              entered and should be one of 'clear', 'safe', 'confidential', or
              'private'. Should you use a level that  is  not  one  of  these,
              'private' will instead be used.

              If  --krb  is provided several times, the last set value will be
              used.

              Example:
               curl --krb clear ftp://example.com/

              See also --delegation and --ssl. --krb requires that the  under-
              lying libcurl was built to support Kerberos.

       --libcurl <file>
              Append  this  option  to any ordinary curl command line, and you
              will get libcurl-using C source code written to  the  file  that
              does the equivalent of what your command-line operation does!

              This option is global and does not need to be specified for each
              use of -:, --next.

              If --libcurl is provided several times, the last set value  will
              be used.

              Example:
               curl --libcurl client.c https://example.com

              See also -v, --verbose.

       --limit-rate <speed>
              Specify  the  maximum  transfer  rate you want curl to use - for
              both downloads and uploads. This feature is useful if you have a
              limited  pipe  and  you would like your transfer not to use your
              entire bandwidth. To make it slower than it otherwise would be.

              The given speed is measured in bytes/second, unless a suffix  is
              appended.   Appending  'k' or 'K' will count the number as kilo-
              bytes, 'm' or 'M' makes it megabytes, while 'g' or 'G' makes  it
              gigabytes.  The suffixes (k, M, G, T, P) are 1024 based. For ex-
              ample 1k is 1024. Examples: 200K, 3m and 1G.

              The rate limiting logic works on averaging the transfer speed to
              no  more  than  the set threshold over a period of multiple sec-
              onds.

              If you also use the -Y, --speed-limit option, that  option  will
              take precedence and might cripple the rate-limiting slightly, to
              help keeping the speed-limit logic working.

              If --limit-rate is provided several times, the  last  set  value
              will be used.

              Examples:
               curl --limit-rate 100K https://example.com
               curl --limit-rate 1000 https://example.com
               curl --limit-rate 10M https://example.com

              See also --rate, -Y, --speed-limit and -y, --speed-time.

       -l, --list-only
              (FTP  POP3)  (FTP)  When  listing  an FTP directory, this switch
              forces a name-only view. This is especially useful if  the  user
              wants  to  machine-parse  the contents of an FTP directory since
              the normal directory view does not use a standard look  or  for-
              mat.  When  used like this, the option causes an NLST command to
              be sent to the server instead of LIST.

              Note: Some FTP servers list only  files  in  their  response  to
              NLST; they do not include sub-directories and symbolic links.

              (POP3)  When  retrieving a specific email from POP3, this switch
              forces a LIST command to be performed instead of RETR.  This  is
              particularly  useful if the user wants to see if a specific mes-
              sage-id exists on the server and what size it is.

              Note: When combined with -X, --request, this option can be  used
              to  send a UIDL command instead, so the user may use the email's
              unique identifier rather than its message-id  to  make  the  re-
              quest.

              Providing  -l,  --list-only  multiple times has no extra effect.
              Disable it again with --no-list-only.

              Example:
               curl --list-only ftp://example.com/dir/

              See also -Q, --quote and -X, --request.

       --local-port <num/range>
              Set a preferred single number or range (FROM-TO) of  local  port
              numbers to use for the connection(s).  Note that port numbers by
              nature are a scarce resource that will be busy at times so  set-
              ting  this range to something too narrow might cause unnecessary
              connection setup failures.

              If --local-port is provided several times, the  last  set  value
              will be used.

              Example:
               curl --local-port 1000-3000 https://example.com

              See also -g, --globoff.

       --location-trusted
              (HTTP)  Like  -L,  --location, but will allow sending the name +
              password to all hosts that the site may redirect to. This may or
              may not introduce a security breach if the site redirects you to
              a site to which you will send your authentication info (which is
              plaintext in the case of HTTP Basic authentication).

              Providing --location-trusted multiple times has no extra effect.
              Disable it again with --no-location-trusted.

              Example:
               curl --location-trusted -u user:password https://example.com

              See also -u, --user.

       -L, --location
              (HTTP) If the server reports that the requested page  has  moved
              to a different location (indicated with a Location: header and a
              3XX response code), this option will make curl redo the  request
              on  the  new  place.  If used together with -i, --include or -I,
              --head, headers from all requested pages will be shown. When au-
              thentication  is  used,  curl  only sends its credentials to the
              initial host. If a redirect takes curl to a different  host,  it
              will  not be able to intercept the user+password. See also --lo-
              cation-trusted on how to change this. You can limit  the  amount
              of redirects to follow by using the --max-redirs option.

              When  curl  follows  a redirect and if the request is a POST, it
              will send the following request with a GET if the HTTP  response
              was  301,  302,  or  303. If the response code was any other 3xx
              code, curl will re-send the following request using the same un-
              modified method.

              You can tell curl to not change POST requests to GET after a 30x
              response by using the dedicated  options  for  that:  --post301,
              --post302 and --post303.

              The  method  set  with  -X,  --request overrides the method curl
              would otherwise select to use.

              Providing -L, --location multiple times  has  no  extra  effect.
              Disable it again with --no-location.

              Example:
               curl -L https://example.com

              See also --resolve and --alt-svc.

       --login-options <options>
              (IMAP  LDAP  POP3  SMTP) Specify the login options to use during
              server authentication.

              You can use login options to specify protocol  specific  options
              that  may  be  used during authentication. At present only IMAP,
              POP3 and SMTP support login options. For more information  about
              login  options  please  see  RFC  2384,  RFC 5092 and IETF draft
              draft-earhart-url-smtp-00.txt

              If --login-options is provided several times, the last set value
              will be used.

              Example:
               curl --login-options 'AUTH=*' imap://example.com

              See also -u, --user. Added in 7.34.0.

       --mail-auth <address>
              (SMTP)  Specify  a  single address. This will be used to specify
              the authentication address (identity)  of  a  submitted  message
              that is being relayed to another server.

              If  --mail-auth  is  provided  several times, the last set value
              will be used.

              Example:
               curl --mail-auth user@example.come -T mail smtp://example.com/

              See also --mail-rcpt and --mail-from.

       --mail-from <address>
              (SMTP) Specify a single address that the given mail  should  get
              sent from.

              If  --mail-from  is  provided  several times, the last set value
              will be used.

              Example:
               curl --mail-from user@example.com -T mail smtp://example.com/

              See also --mail-rcpt and --mail-auth.

       --mail-rcpt-allowfails
              (SMTP) When sending data to multiple recipients, by default curl
              will  abort  SMTP conversation if at least one of the recipients
              causes RCPT TO command to return an error.

              The default behavior can be changed by  passing  --mail-rcpt-al-
              lowfails  command-line option which will make curl ignore errors
              and proceed with the remaining valid recipients.

              If all recipients trigger RCPT TO  failures  and  this  flag  is
              specified,  curl  will still abort the SMTP conversation and re-
              turn the error received from to the last RCPT TO command.

              Providing --mail-rcpt-allowfails multiple times has no extra ef-
              fect.  Disable it again with --no-mail-rcpt-allowfails.

              Example:
               curl --mail-rcpt-allowfails --mail-rcpt dest@example.com smtp://example.com

              See also --mail-rcpt. Added in 7.69.0.

       --mail-rcpt <address>
              (SMTP) Specify a single email address, user name or mailing list
              name. Repeat this option several times to send to  multiple  re-
              cipients.

              When  performing an address verification (VRFY command), the re-
              cipient should be specified as the user name or  user  name  and
              domain (as per Section 3.5 of RFC5321). (Added in 7.34.0)

              When performing a mailing list expand (EXPN command), the recip-
              ient should be specified using the mailing list  name,  such  as
              "Friends" or "London-Office".  (Added in 7.34.0)

              --mail-rcpt can be used several times in a command line

              Example:
               curl --mail-rcpt user@example.net smtp://example.com

              See also --mail-rcpt-allowfails.

       -M, --manual
              Manual. Display the huge help text.

              Example:
               curl --manual

              See also -v, --verbose, --libcurl and --trace.

       --max-filesize <bytes>
              (FTP HTTP MQTT) Specify the maximum size (in bytes) of a file to
              download. If the file requested is larger than this  value,  the
              transfer will not start and curl will return with exit code 63.

              A  size  modifier may be used. For example, Appending 'k' or 'K'
              will count  the  number  as  kilobytes,  'm'  or  'M'  makes  it
              megabytes,  while 'g' or 'G' makes it gigabytes. Examples: 200K,
              3m and 1G. (Added in 7.58.0)

              NOTE: The file size is not always known prior to  download,  and
              for such files this option has no effect even if the file trans-
              fer ends up being larger than this given limit.  If  --max-file-
              size is provided several times, the last set value will be used.

              Example:
               curl --max-filesize 100K https://example.com

              See also --limit-rate.

       --max-redirs <num>
              (HTTP)  Set  maximum  number of redirections to follow. When -L,
              --location is used, to prevent  curl  from  following  too  many
              redirects,  by  default,  the  limit is set to 50 redirects. Set
              this option to -1 to make it unlimited.

              If --max-redirs is provided several times, the  last  set  value
              will be used.

              Example:
               curl --max-redirs 3 --location https://example.com

              See also -L, --location.

       -m, --max-time <fractional seconds>
              Maximum  time  in  seconds that you allow each transfer to take.
              This is useful for preventing your batch jobs from  hanging  for
              hours  due  to slow networks or links going down.  Since 7.32.0,
              this option accepts decimal values, but the actual timeout  will
              decrease in accuracy as the specified timeout increases in deci-
              mal precision.

              If you enable retrying the transfer (--retry) then  the  maximum
              time counter is reset each time the transfer is retried. You can
              use --retry-max-time to limit the retry time.

              The decimal value needs to provided using a dot (.)  as  decimal
              separator  - not the local version even if it might be using an-
              other separator.

              If -m, --max-time is provided several times, the last set  value
              will be used.

              Examples:
               curl --max-time 10 https://example.com
               curl --max-time 2.92 https://example.com

              See also --connect-timeout and --retry-max-time.

       --metalink
              This  option was previously used to specify a metalink resource.
              Metalink support has been disabled in curl since 7.78.0 for  se-
              curity reasons.

              If --metalink is provided several times, the last set value will
              be used.

              Example:
               curl --metalink file https://example.com

              See also -Z, --parallel.

       --negotiate
              (HTTP) Enables Negotiate (SPNEGO) authentication.

              This option requires a library built with GSS-API or  SSPI  sup-
              port.  Use  -V,  --version  to  see  if  your curl supports GSS-
              API/SSPI or SPNEGO.

              When using this option, you must also provide a fake -u,  --user
              option  to  activate the authentication code properly. Sending a
              '-u :' is enough as the user name  and  password  from  the  -u,
              --user option are not actually used.

              If  this  option  is  used  several times, only the first one is
              used.

              Providing --negotiate multiple times has no extra effect.

              Example:
               curl --negotiate -u : https://example.com

              See also --basic, --ntlm, --anyauth and --proxy-negotiate.

       --netrc-file <filename>
              This option is similar to -n, --netrc, except that  you  provide
              the  path  (absolute  or  relative)  to the netrc file that curl
              should use. You can only specify one netrc file per invocation.

              It will abide by --netrc-optional if specified.

              If --netrc-file is provided several times, the  last  set  value
              will be used.

              Example:
               curl --netrc-file netrc https://example.com

              See  also  -n, --netrc, -u, --user and -K, --config. This option
              is mutually exclusive to -n, --netrc.

       --netrc-optional
              Similar to -n, --netrc, but this option makes the  .netrc  usage
              optional and not mandatory as the -n, --netrc option does.

              Providing  --netrc-optional  multiple times has no extra effect.
              Disable it again with --no-netrc-optional.

              Example:
               curl --netrc-optional https://example.com

              See also --netrc-file. This option is mutually exclusive to  -n,
              --netrc.

       -n, --netrc
              Makes  curl  scan  the  .netrc  (_netrc  on Windows) file in the
              user's home directory for login name and password. This is typi-
              cally  used for FTP on Unix. If used with HTTP, curl will enable
              user authentication. See netrc(5) and ftp(1) for details on  the
              file  format.  Curl will not complain if that file does not have
              the right permissions (it should be neither  world-  nor  group-
              readable).  The  environment variable "HOME" is used to find the
              home directory.

              A quick and simple example of how to setup  a  .netrc  to  allow
              curl  to  FTP to the machine host.domain.com with user name 'my-
              self' and password 'secret' could look similar to:

               machine host.domain.com
               login myself
               password secret

              Providing -n, --netrc multiple times has no extra effect.   Dis-
              able it again with --no-netrc.

              Example:
               curl --netrc https://example.com

              See  also --netrc-file, -K, --config and -u, --user. This option
              is mutually exclusive to --netrc-file and --netrc-optional.

       -:, --next
              Tells curl to use a separate operation for the following URL and
              associated  options.  This  allows  you  to send several URL re-
              quests, each with their own specific options, for example,  such
              as different user names or custom requests for each.

              -:,  --next  will  reset  all local options and only global ones
              will have their values survive over to the  operation  following
              the  -:,  --next  instruction. Global options include -v, --ver-
              bose, --trace, --trace-ascii and --fail-early.

              For example, you can do both a GET and a POST in a  single  com-
              mand line:

               curl www1.example.com --next -d postthis www2.example.com

              -:, --next can be used several times in a command line

              Examples:
               curl https://example.com --next -d postthis www2.example.com
               curl -I https://example.com --next https://example.net/

              See also -Z, --parallel and -K, --config. Added in 7.36.0.

       --no-alpn
              (HTTPS)  Disable  the ALPN TLS extension. ALPN is enabled by de-
              fault if libcurl was built with an  SSL  library  that  supports
              ALPN.  ALPN is used by a libcurl that supports HTTP/2 to negoti-
              ate HTTP/2 support with the server during https sessions.

              Providing --no-alpn multiple times has no extra effect.  Disable
              it again with --alpn.

              Example:
               curl --no-alpn https://example.com

              See  also  --no-npn and --http2. --no-alpn requires that the un-
              derlying libcurl was built to support TLS. Added in 7.36.0.

       -N, --no-buffer
              Disables the buffering of the output stream. In normal work sit-
              uations,  curl  will  use a standard buffered output stream that
              will have the effect that it will output the data in chunks, not
              necessarily  exactly  when  the data arrives.  Using this option
              will disable that buffering.

              Providing -N, --no-buffer multiple times has  no  extra  effect.
              Disable it again with --buffer.

              Example:
               curl --no-buffer https://example.com

              See also -#, --progress-bar.

       --no-clobber
              When  used  in  conjunction with the -o, --output, -J, --remote-
              header-name, -O, --remote-name,  or  --remote-name-all  options,
              curl avoids overwriting files that already exist. Instead, a dot
              and a number gets appended to the name of the file that would be
              created,  up  to filename.100 after which it will not create any
              file.

              Note that this is the negated option name documented.   You  can
              thus  use --clobber to enforce the clobbering, even if -J, --re-
              mote-header-name is specified.

              Providing --no-clobber multiple times has no extra effect.  Dis-
              able it again with --clobber.

              Example:
               curl --no-clobber --output local/dir/file https://example.com

              See also -o, --output and -O, --remote-name. Added in 7.83.0.

       --no-keepalive
              Disables  the  use  of keepalive messages on the TCP connection.
              curl otherwise enables them by default.

              Note that this is the negated option name  documented.  You  can
              thus use --keepalive to enforce keepalive.

              Providing  --no-keepalive  multiple  times  has no extra effect.
              Disable it again with --keepalive.

              Example:
               curl --no-keepalive https://example.com

              See also --keepalive-time.

       --no-npn
              (HTTPS) In curl 7.86.0 and later, curl never uses NPN.

              Disable the NPN TLS extension. NPN  is  enabled  by  default  if
              libcurl  was built with an SSL library that supports NPN. NPN is
              used by a libcurl that supports HTTP/2 to negotiate HTTP/2  sup-
              port with the server during https sessions.

              Providing  --no-npn multiple times has no extra effect.  Disable
              it again with --npn.

              Example:
               curl --no-npn https://example.com

              See also --no-alpn and --http2. --no-npn requires that  the  un-
              derlying libcurl was built to support TLS. Added in 7.36.0.

       --no-progress-meter
              Option to switch off the progress meter output without muting or
              otherwise affecting warning and informational messages like  -s,
              --silent does.

              Note  that  this  is the negated option name documented. You can
              thus use --progress-meter to enable the progress meter again.

              Providing --no-progress-meter multiple times has  no  extra  ef-
              fect.  Disable it again with --progress-meter.

              Example:
               curl --no-progress-meter -o store https://example.com

              See also -v, --verbose and -s, --silent. Added in 7.67.0.

       --no-sessionid
              (TLS)  Disable  curl's use of SSL session-ID caching. By default
              all transfers are done using the cache. Note that while  nothing
              should  ever  get  hurt  by attempting to reuse SSL session-IDs,
              there seem to be broken SSL implementations in the wild that may
              require you to disable this in order for you to succeed.

              Note  that  this  is the negated option name documented. You can
              thus use --sessionid to enforce session-ID caching.

              Providing --no-sessionid multiple times  has  no  extra  effect.
              Disable it again with --sessionid.

              Example:
               curl --no-sessionid https://example.com

              See also -k, --insecure.

       --noproxy <no-proxy-list>
              Comma-separated  list  of hosts for which not to use a proxy, if
              one is specified. The only wildcard is  a  single  *  character,
              which  matches  all  hosts,  and effectively disables the proxy.
              Each name in this list is matched as either a domain which  con-
              tains  the  hostname,  or  the hostname itself. For example, lo-
              cal.com would match local.com, local.com:80, and  www.local.com,
              but not www.notlocal.com.

              Since  7.53.0,  This  option overrides the environment variables
              that disable the proxy ('no_proxy' and 'NO_PROXY').  If  there's
              an  environment  variable disabling a proxy, you can set the no-
              proxy list to "" to override it.

              Since 7.86.0, IP addresses specified to this option can be  pro-
              vided  using  CIDR notation: an appended slash and number speci-
              fies the number of "network bits" out of the address to  use  in
              the comparison. For example "192.168.0.0/16" would match all ad-
              dresses starting with "192.168".

              If --noproxy is provided several times, the last set value  will
              be used.

              Example:
               curl --noproxy "www.example" https://example.com

              See also -x, --proxy.

       --ntlm-wb
              (HTTP) Enables NTLM much in the style --ntlm does, but hand over
              the authentication to the separate binary  ntlmauth  application
              that is executed when needed.

              Providing --ntlm-wb multiple times has no extra effect.

              Example:
               curl --ntlm-wb -u user:password https://example.com

              See also --ntlm and --proxy-ntlm.

       --ntlm (HTTP)  Enables  NTLM  authentication.  The  NTLM authentication
              method was designed by Microsoft and is used by IIS web servers.
              It  is a proprietary protocol, reverse-engineered by clever peo-
              ple and implemented in curl based on their efforts. This kind of
              behavior  should  not be endorsed, you should encourage everyone
              who uses NTLM to switch to a public and  documented  authentica-
              tion method instead, such as Digest.

              If  you  want to enable NTLM for your proxy authentication, then
              use --proxy-ntlm.

              If this option is used several times,  only  the  first  one  is
              used.

              Providing --ntlm multiple times has no extra effect.

              Example:
               curl --ntlm -u user:password https://example.com

              See  also  --proxy-ntlm.  --ntlm  requires  that  the underlying
              libcurl was built to support TLS. This option is mutually exclu-
              sive to --basic and --negotiate and --digest and --anyauth.

       --oauth2-bearer <token>
              (IMAP  LDAP  POP3  SMTP HTTP) Specify the Bearer Token for OAUTH
              2.0 server authentication. The Bearer Token is used in  conjunc-
              tion  with  the  user name which can be specified as part of the
              --url or -u, --user options.

              The Bearer Token and user name are formatted  according  to  RFC
              6750.

              If --oauth2-bearer is provided several times, the last set value
              will be used.

              Example:
               curl --oauth2-bearer "mF_9.B5f-4.1JqM" https://example.com

              See also --basic, --ntlm and --digest. Added in 7.33.0.

       --output-dir <dir>
              This option specifies the directory in  which  files  should  be
              stored, when -O, --remote-name or -o, --output are used.

              The  given  output directory is used for all URLs and output op-
              tions on the command line, up until the first -:, --next.

              If the specified target directory does not exist, the  operation
              will fail unless --create-dirs is also used.

              If  --output-dir  is  provided several times, the last set value
              will be used.

              Example:
               curl --output-dir "tmp" -O https://example.com

              See also -O, --remote-name and -J,  --remote-header-name.  Added
              in 7.73.0.

       -o, --output <file>
              Write output to <file> instead of stdout. If you are using {} or
              [] to fetch multiple documents, you should quote the URL and you
              can  use  '#' followed by a number in the <file> specifier. That
              variable will be replaced with the current string  for  the  URL
              being fetched. Like in:

               curl "http://{one,two}.example.com" -o "file_#1.txt"

              or use several variables like:

               curl "http://{site,host}.host[1-5].com" -o "#1_#2"

              You  may use this option as many times as the number of URLs you
              have. For example, if you specify two URLs on the  same  command
              line, you can use it like this:

                curl -o aa example.com -o bb example.net

              and  the  order  of the -o options and the URLs does not matter,
              just that the first -o is for the first URL and so  on,  so  the
              above command line can also be written as

                curl example.com example.net -o aa -o bb

              See  also  the --create-dirs option to create the local directo-
              ries dynamically. Specifying the output as '-' (a  single  dash)
              will force the output to be done to stdout.

              To   suppress  response  bodies,  you  can  redirect  output  to
              /dev/null:

                curl example.com -o /dev/null

              Or for Windows use nul:

                curl example.com -o nul

              -o, --output can be used several times in a command line

              Examples:
               curl -o file https://example.com
               curl "http://{one,two}.example.com" -o "file_#1.txt"
               curl "http://{site,host}.host[1-5].com" -o "#1_#2"
               curl -o file https://example.com -o file2 https://example.net

              See also -O, --remote-name, --remote-name-all and -J,  --remote-
              header-name.

       --parallel-immediate
              When  doing  parallel  transfers, this option will instruct curl
              that it should rather prefer opening up more connections in par-
              allel at once rather than waiting to see if new transfers can be
              added as multiplexed streams on another connection.

              This option is global and does not need to be specified for each
              use of -:, --next.

              Providing  --parallel-immediate  multiple times has no extra ef-
              fect.  Disable it again with --no-parallel-immediate.

              Example:
               curl --parallel-immediate -Z https://example.com -o file1 https://example.com -o file2

              See also -Z, --parallel and --parallel-max. Added in 7.68.0.

       --parallel-max <num>
              When asked to do parallel transfers, using -Z, --parallel,  this
              option controls the maximum amount of transfers to do simultane-
              ously.

              This option is global and does not need to be specified for each
              use of -:, --next.

              The default is 50.

              If  --parallel-max is provided several times, the last set value
              will be used.

              Example:
               curl --parallel-max 100 -Z https://example.com ftp://example.com/

              See also -Z, --parallel. Added in 7.66.0.

       -Z, --parallel
              Makes curl perform its transfers in parallel as compared to  the
              regular serial manner.

              This option is global and does not need to be specified for each
              use of -:, --next.

              Providing -Z, --parallel multiple times  has  no  extra  effect.
              Disable it again with --no-parallel.

              Example:
               curl --parallel https://example.com -o file1 https://example.com -o file2

              See also -:, --next and -v, --verbose. Added in 7.66.0.

       --pass <phrase>
              (SSH TLS) Passphrase for the private key.

              If  --pass is provided several times, the last set value will be
              used.

              Example:
               curl --pass secret --key file https://example.com

              See also --key and -u, --user.

       --path-as-is
              Tell curl to not handle sequences of /../ or /./  in  the  given
              URL  path.  Normally curl will squash or merge them according to
              standards but with this option set you tell it not to do that.

              Providing --path-as-is multiple times has no extra effect.  Dis-
              able it again with --no-path-as-is.

              Example:
               curl --path-as-is https://example.com/../../etc/passwd

              See also --request-target. Added in 7.42.0.

       --pinnedpubkey <hashes>
              (TLS)  Tells  curl  to  use  the  specified  public key file (or
              hashes) to verify the peer. This can be a path to a  file  which
              contains a single public key in PEM or DER format, or any number
              of base64 encoded sha256 hashes preceded by 'sha256//' and sepa-
              rated by ';'.

              When  negotiating  a  TLS  or SSL connection, the server sends a
              certificate indicating its identity. A public key  is  extracted
              from  this certificate and if it does not exactly match the pub-
              lic key provided to this option, curl will abort the  connection
              before sending or receiving any data.

              PEM/DER support:

              7.39.0: OpenSSL, GnuTLS and GSKit

              7.43.0: NSS and wolfSSL

              7.47.0: mbedtls

              sha256 support:

              7.44.0: OpenSSL, GnuTLS, NSS and wolfSSL

              7.47.0: mbedtls

              Other SSL backends not supported.

              If  --pinnedpubkey is provided several times, the last set value
              will be used.

              Examples:
               curl --pinnedpubkey keyfile https://example.com
               curl --pinnedpubkey 'sha256//ce118b51897f4452dc' https://example.com

              See also --hostpubsha256. Added in 7.39.0.

       --post301
              (HTTP) Tells curl to respect RFC 7231/6.4.2 and not convert POST
              requests into GET requests when following a 301 redirection. The
              non-RFC behavior is ubiquitous in web browsers, so curl does the
              conversion by default to maintain consistency. However, a server
              may require a POST to remain a POST after  such  a  redirection.
              This option is meaningful only when using -L, --location.

              Providing --post301 multiple times has no extra effect.  Disable
              it again with --no-post301.

              Example:
               curl --post301 --location -d "data" https://example.com

              See also --post302, --post303 and -L, --location.

       --post302
              (HTTP) Tells curl to respect RFC 7231/6.4.3 and not convert POST
              requests into GET requests when following a 302 redirection. The
              non-RFC behavior is ubiquitous in web browsers, so curl does the
              conversion by default to maintain consistency. However, a server
              may require a POST to remain a POST after  such  a  redirection.
              This option is meaningful only when using -L, --location.

              Providing --post302 multiple times has no extra effect.  Disable
              it again with --no-post302.

              Example:
               curl --post302 --location -d "data" https://example.com

              See also --post301, --post303 and -L, --location.

       --post303
              (HTTP) Tells curl to violate RFC 7231/6.4.4 and not convert POST
              requests  into  GET  requests when following 303 redirections. A
              server may require a POST to remain a POST after a 303 redirect-
              ion. This option is meaningful only when using -L, --location.

              Providing --post303 multiple times has no extra effect.  Disable
              it again with --no-post303.

              Example:
               curl --post303 --location -d "data" https://example.com

              See also --post302, --post301 and -L, --location.

       --preproxy [protocol://]host[:port]
              Use the specified SOCKS proxy before connecting to  an  HTTP  or
              HTTPS  -x,  --proxy.  In  such a case curl first connects to the
              SOCKS proxy and then connects (through SOCKS)  to  the  HTTP  or
              HTTPS proxy. Hence pre proxy.

              The pre proxy string should be specified with a protocol:// pre-
              fix to  specify  alternative  proxy  protocols.  Use  socks4://,
              socks4a://,  socks5://  or  socks5h://  to  request the specific
              SOCKS version to be used. No protocol specified will  make  curl
              default to SOCKS4.

              If  the  port number is not specified in the proxy string, it is
              assumed to be 1080.

              User and password that might be provided in the proxy string are
              URL  decoded by curl. This allows you to pass in special charac-
              ters such as @ by using %40 or pass in a colon with %3a.

              If --preproxy is provided several times, the last set value will
              be used.

              Example:
               curl --preproxy socks5://proxy.example -x http://http.example https://example.com

              See also -x, --proxy and --socks5. Added in 7.52.0.

       -#, --progress-bar
              Make curl display transfer progress as a simple progress bar in-
              stead of the standard, more informational, meter.

              This progress bar draws a single line of '#'  characters  across
              the screen and shows a percentage if the transfer size is known.
              For transfers without a known size, there  will  be  space  ship
              (-=o=-)  that  moves back and forth but only while data is being
              transferred, with a set of flying hash sign symbols on top.

              This option is global and does not need to be specified for each
              use of -:, --next.

              Providing -#, --progress-bar multiple times has no extra effect.
              Disable it again with --no-progress-bar.

              Example:
               curl -# -O https://example.com

              See also --styled-output.

       --proto-default <protocol>
              Tells curl to use protocol for any URL missing a scheme name.

              An unknown or unsupported  protocol  causes  error  CURLE_UNSUP-
              PORTED_PROTOCOL (1).

              This option does not change the default proxy protocol (http).

              Without this option set, curl guesses protocol based on the host
              name, see --url for details.

              If --proto-default is provided several times, the last set value
              will be used.

              Example:
               curl --proto-default https ftp.example.com

              See also --proto and --proto-redir. Added in 7.45.0.

       --proto-redir <protocols>
              Tells  curl to limit what protocols it may use on redirect. Pro-
              tocols denied by --proto are not overridden by this option.  See
              --proto for how protocols are represented.

              Example, allow only HTTP and HTTPS on redirect:

               curl --proto-redir -all,http,https http://example.com

              By default curl will only allow HTTP, HTTPS, FTP and FTPS on re-
              direct (since 7.65.2). Specifying all or +all enables all proto-
              cols on redirects, which is not good for security.

              If  --proto-redir  is provided several times, the last set value
              will be used.

              Example:
               curl --proto-redir =http,https https://example.com

              See also --proto.

       --proto <protocols>
              Tells curl to limit what protocols it  may  use  for  transfers.
              Protocols  are evaluated left to right, are comma separated, and
              are each a protocol name or 'all', optionally prefixed  by  zero
              or more modifiers. Available modifiers are:

              +  Permit this protocol in addition to protocols already permit-
                 ted (this is the default if no modifier is used).

              -  Deny this protocol, removing it from the  list  of  protocols
                 already permitted.

              =  Permit  only this protocol (ignoring the list already permit-
                 ted), though subject to later modification by subsequent  en-
                 tries in the comma separated list.

              For example:

              --proto -ftps  uses the default protocols, but disables ftps

              --proto -all,https,+http
                             only enables http and https

              --proto =http,https
                             also only enables http and https

              Unknown  and  disabled  protocols produce a warning. This allows
              scripts to safely rely on being able to disable potentially dan-
              gerous protocols, without relying upon support for that protocol
              being built into curl to avoid an error.

              This option can be used multiple times, in which case the effect
              is  the same as concatenating the protocols into one instance of
              the option.

              If --proto is provided several times, the last set value will be
              used.

              Example:
               curl --proto =http,https,sftp https://example.com

              See also --proto-redir and --proto-default.

       --proxy-anyauth
              Tells  curl to pick a suitable authentication method when commu-
              nicating with the given HTTP proxy. This might  cause  an  extra
              request/response round-trip.

              Providing --proxy-anyauth multiple times has no extra effect.

              Example:
               curl --proxy-anyauth --proxy-user user:passwd -x proxy https://example.com

              See also -x, --proxy, --proxy-basic and --proxy-digest.

       --proxy-basic
              Tells  curl  to use HTTP Basic authentication when communicating
              with the given proxy. Use --basic for enabling HTTP Basic with a
              remote  host.  Basic  is  the default authentication method curl
              uses with proxies.

              Providing --proxy-basic multiple times has no extra effect.

              Example:
               curl --proxy-basic --proxy-user user:passwd -x proxy https://example.com

              See also -x, --proxy, --proxy-anyauth and --proxy-digest.

       --proxy-cacert <file>
              Same as --cacert but used in HTTPS proxy context.

              If --proxy-cacert is provided several times, the last set  value
              will be used.

              Example:
               curl --proxy-cacert CA-file.txt -x https://proxy https://example.com

              See  also  --proxy-capath,  --cacert,  --capath and -x, --proxy.
              Added in 7.52.0.

       --proxy-capath <dir>
              Same as --capath but used in HTTPS proxy context.

              If --proxy-capath is provided several times, the last set  value
              will be used.

              Example:
               curl --proxy-capath /local/directory -x https://proxy https://example.com

              See  also  --proxy-cacert,  -x,  --proxy  and --capath. Added in
              7.52.0.

       --proxy-cert-type <type>
              Same as --cert-type but used in HTTPS proxy context.

              If --proxy-cert-type is provided several  times,  the  last  set
              value will be used.

              Example:
               curl --proxy-cert-type PEM --proxy-cert file -x https://proxy https://example.com

              See also --proxy-cert. Added in 7.52.0.

       --proxy-cert <cert[:passwd]>
              Same as -E, --cert but used in HTTPS proxy context.

              If  --proxy-cert  is  provided several times, the last set value
              will be used.

              Example:
               curl --proxy-cert file -x https://proxy https://example.com

              See also --proxy-cert-type. Added in 7.52.0.

       --proxy-ciphers <list>
              Same as --ciphers but used in HTTPS proxy context.

              If --proxy-ciphers is provided several times, the last set value
              will be used.

              Example:
               curl --proxy-ciphers ECDHE-ECDSA-AES256-CCM8 -x https://proxy https://example.com

              See also --ciphers, --curves and -x, --proxy. Added in 7.52.0.

       --proxy-crlfile <file>
              Same as --crlfile but used in HTTPS proxy context.

              If --proxy-crlfile is provided several times, the last set value
              will be used.

              Example:
               curl --proxy-crlfile rejects.txt -x https://proxy https://example.com

              See also --crlfile and -x, --proxy. Added in 7.52.0.

       --proxy-digest
              Tells curl to use HTTP Digest authentication when  communicating
              with the given proxy. Use --digest for enabling HTTP Digest with
              a remote host.

              Providing --proxy-digest multiple times has no extra effect.

              Example:
               curl --proxy-digest --proxy-user user:passwd -x proxy https://example.com

              See also -x, --proxy, --proxy-anyauth and --proxy-basic.

       --proxy-header <header/@file>
              (HTTP) Extra header to include in the request when sending  HTTP
              to a proxy. You may specify any number of extra headers. This is
              the equivalent option to -H, --header but is for proxy  communi-
              cation  only  like  in CONNECT requests when you want a separate
              header sent to the proxy to what is sent to  the  actual  remote
              host.

              curl  will  make  sure  that each header you add/replace is sent
              with the proper end-of-line marker, you should thus not add that
              as a part of the header content: do not add newlines or carriage
              returns, they will only mess things up for you.

              Headers specified with this option will not be included  in  re-
              quests that curl knows will not be sent to a proxy.

              Starting  in  7.55.0, this option can take an argument in @file-
              name style, which then adds a header for each line in the  input
              file. Using @- will make curl read the header file from stdin.

              This  option  can  be  used multiple times to add/replace/remove
              multiple headers.

              --proxy-header can be used several times in a command line

              Examples:
               curl --proxy-header "X-First-Name: Joe" -x http://proxy https://example.com
               curl --proxy-header "User-Agent: surprise" -x http://proxy https://example.com
               curl --proxy-header "Host:" -x http://proxy https://example.com

              See also -x, --proxy. Added in 7.37.0.

       --proxy-insecure
              Same as -k, --insecure but used in HTTPS proxy context.

              Providing --proxy-insecure multiple times has no  extra  effect.
              Disable it again with --no-proxy-insecure.

              Example:
               curl --proxy-insecure -x https://proxy https://example.com

              See also -x, --proxy and -k, --insecure. Added in 7.52.0.

       --proxy-key-type <type>
              Same as --key-type but used in HTTPS proxy context.

              If  --proxy-key-type  is  provided  several  times, the last set
              value will be used.

              Example:
               curl --proxy-key-type DER --proxy-key here -x https://proxy https://example.com

              See also --proxy-key and -x, --proxy. Added in 7.52.0.

       --proxy-key <key>
              Same as --key but used in HTTPS proxy context.

              If --proxy-key is provided several times,  the  last  set  value
              will be used.

              Example:
               curl --proxy-key here -x https://proxy https://example.com

              See also --proxy-key-type and -x, --proxy. Added in 7.52.0.

       --proxy-negotiate
              Tells  curl  to  use HTTP Negotiate (SPNEGO) authentication when
              communicating with the given proxy. Use --negotiate for enabling
              HTTP Negotiate (SPNEGO) with a remote host.

              Providing --proxy-negotiate multiple times has no extra effect.

              Example:
               curl --proxy-negotiate --proxy-user user:passwd -x proxy https://example.com

              See also --proxy-anyauth and --proxy-basic.

       --proxy-ntlm
              Tells  curl  to  use HTTP NTLM authentication when communicating
              with the given proxy. Use --ntlm for enabling NTLM with a remote
              host.

              Providing --proxy-ntlm multiple times has no extra effect.

              Example:
               curl --proxy-ntlm --proxy-user user:passwd -x http://proxy https://example.com

              See also --proxy-negotiate and --proxy-anyauth.

       --proxy-pass <phrase>
              Same as --pass but used in HTTPS proxy context.

              If  --proxy-pass  is  provided several times, the last set value
              will be used.

              Example:
               curl --proxy-pass secret --proxy-key here -x https://proxy https://example.com

              See also -x, --proxy and --proxy-key. Added in 7.52.0.

       --proxy-pinnedpubkey <hashes>
              (TLS) Tells curl to  use  the  specified  public  key  file  (or
              hashes)  to verify the proxy. This can be a path to a file which
              contains a single public key in PEM or DER format, or any number
              of base64 encoded sha256 hashes preceded by 'sha256//' and sepa-
              rated by ';'.

              When negotiating a TLS or SSL connection,  the  server  sends  a
              certificate  indicating  its identity. A public key is extracted
              from this certificate and if it does not exactly match the  pub-
              lic  key provided to this option, curl will abort the connection
              before sending or receiving any data.

              If --proxy-pinnedpubkey is provided several times, the last  set
              value will be used.

              Examples:
               curl --proxy-pinnedpubkey keyfile https://example.com
               curl --proxy-pinnedpubkey 'sha256//ce118b51897f4452dc' https://example.com

              See also --pinnedpubkey and -x, --proxy. Added in 7.59.0.

       --proxy-service-name <name>
              This  option allows you to change the service name for proxy ne-
              gotiation.

              If --proxy-service-name is provided several times, the last  set
              value will be used.

              Example:
               curl --proxy-service-name "shrubbery" -x proxy https://example.com

              See also --service-name and -x, --proxy. Added in 7.43.0.

       --proxy-ssl-allow-beast
              Same as --ssl-allow-beast but used in HTTPS proxy context.

              Providing  --proxy-ssl-allow-beast  multiple  times has no extra
              effect.  Disable it again with --no-proxy-ssl-allow-beast.

              Example:
               curl --proxy-ssl-allow-beast -x https://proxy https://example.com

              See also --ssl-allow-beast and -x, --proxy. Added in 7.52.0.

       --proxy-ssl-auto-client-cert
              Same as --ssl-auto-client-cert but used in HTTPS proxy context.

              Providing --proxy-ssl-auto-client-cert multiple times has no ex-
              tra  effect.   Disable it again with --no-proxy-ssl-auto-client-
              cert.

              Example:
               curl --proxy-ssl-auto-client-cert -x https://proxy https://example.com

              See  also  --ssl-auto-client-cert  and  -x,  --proxy.  Added  in
              7.77.0.

       --proxy-tls13-ciphers <ciphersuite list>
              (TLS)  Specifies which cipher suites to use in the connection to
              your HTTPS proxy when it negotiates TLS 1.3. The list of ciphers
              suites  must  specify  valid  ciphers. Read up on TLS 1.3 cipher
              suite details on this URL:

               https://curl.se/docs/ssl-ciphers.html

              This option is currently used only when curl  is  built  to  use
              OpenSSL 1.1.1 or later. If you are using a different SSL backend
              you can try setting TLS 1.3 cipher suites by using the  --proxy-
              ciphers option.

              If --proxy-tls13-ciphers is provided several times, the last set
              value will be used.

              Example:
               curl --proxy-tls13-ciphers TLS_AES_128_GCM_SHA256 -x proxy https://example.com

              See also --tls13-ciphers and --curves. Added in 7.61.0.

       --proxy-tlsauthtype <type>
              Same as --tlsauthtype but used in HTTPS proxy context.

              If --proxy-tlsauthtype is provided several times, the  last  set
              value will be used.

              Example:
               curl --proxy-tlsauthtype SRP -x https://proxy https://example.com

              See also -x, --proxy and --proxy-tlsuser. Added in 7.52.0.

       --proxy-tlspassword <string>
              Same as --tlspassword but used in HTTPS proxy context.

              If  --proxy-tlspassword  is provided several times, the last set
              value will be used.

              Example:
               curl --proxy-tlspassword passwd -x https://proxy https://example.com

              See also -x, --proxy and --proxy-tlsuser. Added in 7.52.0.

       --proxy-tlsuser <name>
              Same as --tlsuser but used in HTTPS proxy context.

              If --proxy-tlsuser is provided several times, the last set value
              will be used.

              Example:
               curl --proxy-tlsuser smith -x https://proxy https://example.com

              See also -x, --proxy and --proxy-tlspassword. Added in 7.52.0.

       --proxy-tlsv1
              Same as -1, --tlsv1 but used in HTTPS proxy context.

              Providing --proxy-tlsv1 multiple times has no extra effect.

              Example:
               curl --proxy-tlsv1 -x https://proxy https://example.com

              See also -x, --proxy. Added in 7.52.0.

       -U, --proxy-user <user:password>
              Specify  the user name and password to use for proxy authentica-
              tion.

              If you use a Windows SSPI-enabled curl binary and do either  Ne-
              gotiate  or NTLM authentication then you can tell curl to select
              the user name and password from your environment by specifying a
              single colon with this option: "-U :".

              On systems where it works, curl will hide the given option argu-
              ment from process listings. This is not enough to  protect  cre-
              dentials  from  possibly getting seen by other users on the same
              system as they  will  still  be  visible  for  a  moment  before
              cleared. Such sensitive data should be retrieved from a file in-
              stead or similar and never used in clear text in a command line.

              If -U, --proxy-user is provided  several  times,  the  last  set
              value will be used.

              Example:
               curl --proxy-user name:pwd -x proxy https://example.com

              See also --proxy-pass.

       -x, --proxy [protocol://]host[:port]
              Use the specified proxy.

              The  proxy string can be specified with a protocol:// prefix. No
              protocol specified or http:// will be treated as HTTP proxy. Use
              socks4://, socks4a://, socks5:// or socks5h:// to request a spe-
              cific SOCKS version to be used.

              Unix domain sockets are supported for socks proxy. Set localhost
              for the host part. e.g. socks5h://localhost/path/to/socket.sock

              HTTPS  proxy  support  via https:// protocol prefix was added in
              7.52.0 for OpenSSL, GnuTLS and NSS.

              Unrecognized and unsupported  proxy  protocols  cause  an  error
              since  7.52.0.   Prior  versions may ignore the protocol and use
              http:// instead.

              If the port number is not specified in the proxy string,  it  is
              assumed to be 1080.

              This  option  overrides  existing environment variables that set
              the proxy to use. If there's an environment variable  setting  a
              proxy, you can set proxy to "" to override it.

              All operations that are performed over an HTTP proxy will trans-
              parently be converted to HTTP. It means  that  certain  protocol
              specific operations might not be available. This is not the case
              if you can tunnel through the proxy, as one with the -p, --prox-
              ytunnel option.

              User and password that might be provided in the proxy string are
              URL decoded by curl. This allows you to pass in special  charac-
              ters such as @ by using %40 or pass in a colon with %3a.

              The  proxy host can be specified the same way as the proxy envi-
              ronment variables, including the protocol prefix  (http://)  and
              the embedded user + password.

              When a proxy is used, the active FTP mode as set with -P, --ftp-
              port, cannot be used.

              If -x, --proxy is provided several times,  the  last  set  value
              will be used.

              Example:
               curl --proxy http://proxy.example https://example.com

              See also --socks5 and --proxy-basic.

       --proxy1.0 <host[:port]>
              Use  the  specified  HTTP  1.0  proxy. If the port number is not
              specified, it is assumed at port 1080.

              The only difference between this and the HTTP proxy  option  -x,
              --proxy,  is that attempts to use CONNECT through the proxy will
              specify an HTTP 1.0 protocol instead of the default HTTP 1.1.

              Providing --proxy1.0 multiple times has no extra effect.

              Example:
               curl --proxy1.0 -x http://proxy https://example.com

              See also -x, --proxy, --socks5 and --preproxy.

       -p, --proxytunnel
              When an HTTP proxy is used -x, --proxy, this  option  will  make
              curl  tunnel through the proxy. The tunnel approach is made with
              the HTTP proxy CONNECT request and requires that the  proxy  al-
              lows direct connect to the remote port number curl wants to tun-
              nel through to.

              To suppress proxy CONNECT response headers when curl is  set  to
              output headers use --suppress-connect-headers.

              Providing  -p, --proxytunnel multiple times has no extra effect.
              Disable it again with --no-proxytunnel.

              Example:
               curl --proxytunnel -x http://proxy https://example.com

              See also -x, --proxy.

       --pubkey <key>
              (SFTP SCP) Public key file name. Allows you to provide your pub-
              lic key in this separate file.

              (As of 7.39.0, curl attempts to automatically extract the public
              key from the private key file, so passing this option is  gener-
              ally not required. Note that this public key extraction requires
              libcurl to be linked against a copy of libssh2 1.2.8  or  higher
              that is itself linked against OpenSSL.)

              If  --pubkey  is provided several times, the last set value will
              be used.

              Example:
               curl --pubkey file.pub sftp://example.com/

              See also --pass.

       -Q, --quote <command>
              (FTP SFTP) Send an arbitrary command to the remote FTP  or  SFTP
              server.  Quote commands are sent BEFORE the transfer takes place
              (just after the initial PWD command in an FTP  transfer,  to  be
              exact). To make commands take place after a successful transfer,
              prefix them with a dash '-'.

              (FTP only) To make commands be sent after curl has  changed  the
              working  directory,  just  before  the file transfer command(s),
              prefix the command with a '+'. This is not performed when a  di-
              rectory listing is performed.

              You may specify any number of commands.

              By  default  curl  will stop at first failure. To make curl con-
              tinue even if the command fails, prefix the command with an  as-
              terisk  (*). Otherwise, if the server returns failure for one of
              the commands, the entire operation will be aborted.

              You must send syntactically correct FTP commands as RFC 959  de-
              fines  to  FTP  servers,  or one of the commands listed below to
              SFTP servers.

              This option can be used multiple times.

              SFTP is a binary protocol. Unlike for FTP, curl interprets  SFTP
              quote  commands  itself  before sending them to the server. File
              names may be quoted shell-style to embed spaces or special char-
              acters.  Following  is the list of all supported SFTP quote com-
              mands:

              atime date file
                     The atime command sets the last access time of  the  file
                     named  by  the file operand. The <date expression> can be
                     all sorts of date strings, see  the  curl_getdate(3)  man
                     page for date expression details. (Added in 7.73.0)

              chgrp group file
                     The  chgrp command sets the group ID of the file named by
                     the file operand to the group ID specified by  the  group
                     operand. The group operand is a decimal integer group ID.

              chmod mode file
                     The  chmod  command  modifies  the  file mode bits of the
                     specified file. The mode operand is an octal integer mode
                     number.

              chown user file
                     The chown command sets the owner of the file named by the
                     file operand to the user ID specified by the  user  oper-
                     and. The user operand is a decimal integer user ID.

              ln source_file target_file
                     The ln and symlink commands create a symbolic link at the
                     target_file location pointing to  the  source_file  loca-
                     tion.

              mkdir directory_name
                     The  mkdir command creates the directory named by the di-
                     rectory_name operand.

              mtime date file
                     The mtime command sets the last modification time of  the
                     file named by the file operand. The <date expression> can
                     be all sorts of date strings, see the curl_getdate(3) man
                     page for date expression details. (Added in 7.73.0)

              pwd    The pwd command returns the absolute pathname of the cur-
                     rent working directory.

              rename source target
                     The rename command renames the file or directory named by
                     the  source  operand to the destination path named by the
                     target operand.

              rm file
                     The rm command removes the file specified by the file op-
                     erand.

              rmdir directory
                     The  rmdir  command removes the directory entry specified
                     by the directory operand, provided it is empty.

              symlink source_file target_file
                     See ln.

       -Q, --quote can be used several times in a command line

       Example:
        curl --quote "DELE file" ftp://example.com/foo

       See also -X, --request.

       --random-file <file>
              Deprecated option. This option is ignored by curl since  7.84.0.
              Prior  to that it only had an effect on curl if built to use old
              versions of OpenSSL.

              Specify the path name to file containing what will be considered
              as  random  data. The data may be used to seed the random engine
              for SSL connections.

              If --random-file is provided several times, the last  set  value
              will be used.

              Example:
               curl --random-file rubbish https://example.com

              See also --egd-file.

       -r, --range <range>
              (HTTP FTP SFTP FILE) Retrieve a byte range (i.e. a partial docu-
              ment) from an HTTP/1.1, FTP or SFTP  server  or  a  local  FILE.
              Ranges can be specified in a number of ways.

              0-499     specifies the first 500 bytes

              500-999   specifies the second 500 bytes

              -500      specifies the last 500 bytes

              9500-     specifies the bytes from offset 9500 and forward

              0-0,-1    specifies the first and last byte only(*)(HTTP)

              100-199,500-599
                        specifies two separate 100-byte ranges(*) (HTTP)

              (*)  = NOTE that this will cause the server to reply with a mul-
              tipart response, which will be returned as-is by  curl!  Parsing
              or otherwise transforming this response is the responsibility of
              the caller.

              Only digit characters (0-9) are valid in the 'start' and  'stop'
              fields  of the 'start-stop' range syntax. If a non-digit charac-
              ter is given in the range, the server's response will be unspec-
              ified, depending on the server's configuration.

              You  should also be aware that many HTTP/1.1 servers do not have
              this feature enabled, so that when you attempt to get  a  range,
              you will instead get the whole document.

              FTP  and  SFTP  range  downloads only support the simple 'start-
              stop' syntax (optionally with one of the numbers  omitted).  FTP
              use depends on the extended FTP command SIZE.

              If  -r,  --range  is  provided several times, the last set value
              will be used.

              Example:
               curl --range 22-44 https://example.com

              See also -C, --continue-at and -a, --append.

       --rate <max request rate>
              Specify the maximum transfer frequency you allow curl to  use  -
              in number of transfer starts per time unit (sometimes called re-
              quest rate). Without this  option,  curl  will  start  the  next
              transfer as fast as possible.

              If  given  several URLs and a transfer completes faster than the
              allowed rate, curl will wait until the next transfer is  started
              to  maintain  the requested rate. This option has no effect when
              -Z, --parallel is used.

              The request rate is provided as "N/U" where N is an integer num-
              ber  and U is a time unit. Supported units are 's' (second), 'm'
              (minute), 'h' (hour) and 'd' /(day, as in a 24 hour  unit).  The
              default  time  unit, if no "/U" is provided, is number of trans-
              fers per hour.

              If curl is told to allow 10 requests per  minute,  it  will  not
              start  the  next  request until 6 seconds have elapsed since the
              previous transfer was started.

              This function uses millisecond resolution. If the  allowed  fre-
              quency is set more than 1000 per second, it will instead run un-
              restricted.

              When retrying transfers,  enabled  with  --retry,  the  separate
              retry delay logic is used and not this setting.

              If  --rate is provided several times, the last set value will be
              used.

              Examples:
               curl --rate 2/s https://example.com
               curl --rate 3/h https://example.com
               curl --rate 14/m https://example.com

              See also --limit-rate and --retry-delay. Added in 7.84.0.

       --raw  (HTTP) When used, it disables all internal HTTP decoding of con-
              tent  or transfer encodings and instead makes them passed on un-
              altered, raw.

              Providing --raw multiple times has no extra effect.  Disable  it
              again with --no-raw.

              Example:
               curl --raw https://example.com

              See also --tr-encoding.

       -e, --referer <URL>
              (HTTP) Sends the "Referrer Page" information to the HTTP server.
              This can also be set with the -H, --header flag of course.  When
              used  with  -L,  --location  you  can  append ";auto" to the -e,
              --referer URL to make curl automatically set  the  previous  URL
              when  it  follows  a Location: header. The ";auto" string can be
              used alone, even if you do not set an initial -e, --referer.

              If -e, --referer is provided several times, the last  set  value
              will be used.

              Examples:
               curl --referer "https://fake.example" https://example.com
               curl --referer "https://fake.example;auto" -L https://example.com
               curl --referer ";auto" -L https://example.com

              See also -A, --user-agent and -H, --header.

       -J, --remote-header-name
              (HTTP) This option tells the -O, --remote-name option to use the
              server-specified Content-Disposition  filename  instead  of  ex-
              tracting  a  filename  from the URL. If the server-provided file
              name contains a path, that will be stripped off before the  file
              name is used.

              The  file is saved in the current directory, or in the directory
              specified with --output-dir.

              If the server specifies a file name and a file  with  that  name
              already  exists  in  the  destination  directory, it will not be
              overwritten and an error will occur - unless you allow it by us-
              ing  the --clobber option. If the server does not specify a file
              name then this option has no effect.

              There's no attempt to decode %-sequences (yet) in  the  provided
              file name, so this option may provide you with rather unexpected
              file names.

              This feature uses the name from the "filename"  field,  it  does
              not  yet  support the "filename*" field (filenames with explicit
              character sets).

              WARNING: Exercise judicious use of this  option,  especially  on
              Windows.  A  rogue  server  could  send you the name of a DLL or
              other file that could be loaded automatically by Windows or some
              third party software.

              Providing  -J,  --remote-header-name multiple times has no extra
              effect.  Disable it again with --no-remote-header-name.

              Example:
               curl -OJ https://example.com/file

              See also -O, --remote-name.

       --remote-name-all
              This option changes the default action for all given URLs to  be
              dealt with as if -O, --remote-name were used for each one. So if
              you want to disable that for a specific URL after --remote-name-
              all has been used, you must use "-o -" or --no-remote-name.

              Providing  --remote-name-all multiple times has no extra effect.
              Disable it again with --no-remote-name-all.

              Example:
               curl --remote-name-all ftp://example.com/file1 ftp://example.com/file2

              See also -O, --remote-name.

       -O, --remote-name
              Write output to a local file named like the remote file we  get.
              (Only  the file part of the remote file is used, the path is cut
              off.)

              The file will be saved in the current working directory. If  you
              want  the  file  saved  in  a different directory, make sure you
              change the current working directory before invoking  curl  with
              this option or use --output-dir.

              The  remote  file  name  to use for saving is extracted from the
              given URL, nothing else, and if it already  exists  it  will  be
              overwritten.  If  you  want  the server to be able to choose the
              file name refer to -J, --remote-header-name which can be used in
              addition  to  this option. If the server chooses a file name and
              that name already exists it will not be overwritten.

              There is no URL decoding done on the file name. If it has %20 or
              other  URL  encoded parts of the name, they will end up as-is as
              file name.

              You may use this option as many times as the number of URLs  you
              have.

              -O, --remote-name can be used several times in a command line

              Example:
               curl -O https://example.com/filename

              See  also  --remote-name-all,  --output-dir  and  -J,  --remote-
              header-name.

       -R, --remote-time
              When used, this will make curl attempt to figure out  the  time-
              stamp  of the remote file, and if that is available make the lo-
              cal file get that same timestamp.

              Providing -R, --remote-time multiple times has no extra  effect.
              Disable it again with --no-remote-time.

              Example:
               curl --remote-time -o foo https://example.com

              See also -O, --remote-name and -z, --time-cond.

       --remove-on-error
              When  curl  returns an error when told to save output in a local
              file, this option removes that saved file before  exiting.  This
              prevents  curl from leaving a partial file in the case of an er-
              ror during transfer.

              If the output is not a file, this option has no effect.

              Providing --remove-on-error multiple times has no extra  effect.
              Disable it again with --no-remove-on-error.

              Example:
               curl --remove-on-error -o output https://example.com

              See also -f, --fail. Added in 7.83.0.

       --request-target <path>
              (HTTP)  Tells curl to use an alternative "target" (path) instead
              of using the path as provided in the  URL.  Particularly  useful
              when  wanting  to  issue  HTTP requests without leading slash or
              other data that does not follow the regular  URL  pattern,  like
              "OPTIONS *".

              If  --request-target  is  provided  several  times, the last set
              value will be used.

              Example:
               curl --request-target "*" -X OPTIONS https://example.com

              See also -X, --request. Added in 7.55.0.

       -X, --request <method>
              (HTTP) Specifies a custom request method to use when communicat-
              ing  with  the HTTP server. The specified request method will be
              used instead of the method otherwise  used  (which  defaults  to
              GET).  Read  the HTTP 1.1 specification for details and explana-
              tions. Common additional HTTP requests include PUT  and  DELETE,
              but related technologies like WebDAV offers PROPFIND, COPY, MOVE
              and more.

              Normally you do not need this option. All sorts  of  GET,  HEAD,
              POST and PUT requests are rather invoked by using dedicated com-
              mand line options.

              This option only changes the actual word used in  the  HTTP  re-
              quest, it does not alter the way curl behaves. So for example if
              you want to make a proper HEAD request, using -X HEAD  will  not
              suffice. You need to use the -I, --head option.

              The  method  string  you set with -X, --request will be used for
              all requests, which if you for example use  -L,  --location  may
              cause  unintended side-effects when curl does not change request
              method according to the HTTP 30x response codes - and similar.

              (FTP) Specifies a custom FTP command to use instead of LIST when
              doing file lists with FTP.

              (POP3) Specifies a custom POP3 command to use instead of LIST or
              RETR.

              (IMAP) Specifies a custom IMAP command to use instead  of  LIST.
              (Added in 7.30.0)

              (SMTP) Specifies a custom SMTP command to use instead of HELP or
              VRFY. (Added in 7.34.0)

              If -X, --request is provided several times, the last  set  value
              will be used.

              Examples:
               curl -X "DELETE" https://example.com
               curl -X NLST ftp://example.com/

              See also --request-target.

       --resolve <[+]host:port:addr[,addr]...>
              Provide  a custom address for a specific host and port pair. Us-
              ing this, you can make the curl requests(s) use a specified  ad-
              dress  and prevent the otherwise normally resolved address to be
              used. Consider it a sort of /etc/hosts alternative  provided  on
              the  command line. The port number should be the number used for
              the specific protocol the host will be used for.  It  means  you
              need several entries if you want to provide address for the same
              host but different ports.

              By specifying '*' as host you can tell curl to resolve any  host
              and specific port pair to the specified address. Wildcard is re-
              solved last so any --resolve with a specific host and port  will
              be used first.

              The provided address set by this option will be used even if -4,
              --ipv4 or -6, --ipv6 is set to make curl use another IP version.

              By prefixing the host with a '+' you can make the entry time out
              after  curl's  default  timeout  (1 minute). Note that this will
              only make sense for long running parallel transfers with  a  lot
              of files. In such cases, if this option is used curl will try to
              resolve the host as it normally would once the timeout  has  ex-
              pired.

              Support for providing the IP address within [brackets] was added
              in 7.57.0.

              Support for providing multiple IP addresses per entry was  added
              in 7.59.0.

              Support for resolving with wildcard was added in 7.64.0.

              Support for the '+' prefix was was added in 7.75.0.

              This option can be used many times to add many host names to re-
              solve.

              --resolve can be used several times in a command line

              Example:
               curl --resolve example.com:443:127.0.0.1 https://example.com

              See also --connect-to and --alt-svc.

       --retry-all-errors
              Retry on any error. This option is used together with --retry.

              This option is the "sledgehammer" of retrying. Do not  use  this
              option by default (eg in curlrc), there may be unintended conse-
              quences such as sending or receiving duplicate data. Do not  use
              with  redirected  input or output. You'd be much better off han-
              dling your unique problems in shell script. Please read the  ex-
              ample below.

              WARNING:  For server compatibility curl attempts to retry failed
              flaky transfers as close as possible to how they  were  started,
              but  this  is  not possible with redirected input or output. For
              example, before retrying it removes output data  from  a  failed
              partial  transfer  that  was  written to an output file. However
              this is not true of data redirected to a | pipe or > file, which
              are  not  reset.  We strongly suggest you do not parse or record
              output via redirect in combination with this option,  since  you
              may receive duplicate data.

              By default curl will not error on an HTTP response code that in-
              dicates an HTTP error, if the transfer was successful. For exam-
              ple,  if  a  server replies 404 Not Found and the reply is fully
              received then that is not an error. When --retry  is  used  then
              curl  will retry on some HTTP response codes that indicate tran-
              sient HTTP errors, but that does not include most  4xx  response
              codes  such  as  404. If you want to retry on all response codes
              that indicate HTTP errors (4xx and 5xx) then  combine  with  -f,
              --fail.

              Providing --retry-all-errors multiple times has no extra effect.
              Disable it again with --no-retry-all-errors.

              Example:
               curl --retry 5 --retry-all-errors https://example.com

              See also --retry. Added in 7.71.0.

       --retry-connrefused
              In addition to the other conditions, consider ECONNREFUSED as  a
              transient  error  too  for --retry. This option is used together
              with --retry.

              Providing --retry-connrefused multiple times has  no  extra  ef-
              fect.  Disable it again with --no-retry-connrefused.

              Example:
               curl --retry-connrefused --retry 7 https://example.com

              See also --retry and --retry-all-errors. Added in 7.52.0.

       --retry-delay <seconds>
              Make  curl  sleep  this  amount of time before each retry when a
              transfer has failed with a transient error (it changes  the  de-
              fault  backoff  time  algorithm between retries). This option is
              only interesting if --retry is also used. Setting this delay  to
              zero will make curl use the default backoff time.

              If  --retry-delay  is provided several times, the last set value
              will be used.

              Example:
               curl --retry-delay 5 --retry 7 https://example.com

              See also --retry.

       --retry-max-time <seconds>
              The retry timer is reset before the first transfer attempt.  Re-
              tries  will  be done as usual (see --retry) as long as the timer
              has not reached this given limit. Notice that if the  timer  has
              not  reached  the limit, the request will be made and while per-
              forming, it may take longer than  this  given  time  period.  To
              limit  a  single request's maximum time, use -m, --max-time. Set
              this option to zero to not timeout retries.

              If --retry-max-time is provided  several  times,  the  last  set
              value will be used.

              Example:
               curl --retry-max-time 30 --retry 10 https://example.com

              See also --retry.

       --retry <num>
              If  a  transient  error is returned when curl tries to perform a
              transfer, it will retry this number of times before  giving  up.
              Setting  the  number to 0 makes curl do no retries (which is the
              default). Transient error means either: a timeout,  an  FTP  4xx
              response code or an HTTP 408, 429, 500, 502, 503 or 504 response
              code.

              When curl is about to retry a transfer, it will first  wait  one
              second  and  then for all forthcoming retries it will double the
              waiting time until it reaches 10 minutes which then will be  the
              delay  between  the  rest of the retries. By using --retry-delay
              you  disable  this  exponential  backoff  algorithm.  See   also
              --retry-max-time to limit the total time allowed for retries.

              Since  curl  7.66.0,  curl will comply with the Retry-After: re-
              sponse header if one was present to know when to issue the  next
              retry.

              If --retry is provided several times, the last set value will be
              used.

              Example:
               curl --retry 7 https://example.com

              See also --retry-max-time.

       --sasl-authzid <identity>
              Use this authorization identity (authzid), during SASL PLAIN au-
              thentication,  in addition to the authentication identity (auth-
              cid) as specified by -u, --user.

              If the option is not specified, the server will derive  the  au-
              thzid  from  the authcid, but if specified, and depending on the
              server implementation, it may be used to access  another  user's
              inbox,  that  the  user  has been granted access to, or a shared
              mailbox for example.

              If --sasl-authzid is provided several times, the last set  value
              will be used.

              Example:
               curl --sasl-authzid zid imap://example.com/

              See also --login-options. Added in 7.66.0.

       --sasl-ir
              Enable initial response in SASL authentication.

              Providing --sasl-ir multiple times has no extra effect.  Disable
              it again with --no-sasl-ir.

              Example:
               curl --sasl-ir imap://example.com/

              See also --sasl-authzid. Added in 7.31.0.

       --service-name <name>
              This option allows you to change the service name for SPNEGO.

              Examples:   --negotiate   --service-name   sockd    would    use
              sockd/server-name.

              If  --service-name is provided several times, the last set value
              will be used.

              Example:
               curl --service-name sockd/server https://example.com

              See also --negotiate and --proxy-service-name. Added in 7.43.0.

       -S, --show-error
              When used with -s, --silent, it makes curl show an error message
              if it fails.

              This option is global and does not need to be specified for each
              use of -:, --next.

              Providing -S, --show-error multiple times has no  extra  effect.
              Disable it again with --no-show-error.

              Example:
               curl --show-error --silent https://example.com

              See also --no-progress-meter.

       -s, --silent
              Silent  or  quiet mode. Do not show progress meter or error mes-
              sages. Makes Curl mute. It will still output the  data  you  ask
              for, potentially even to the terminal/stdout unless you redirect
              it.

              Use -S, --show-error in  addition  to  this  option  to  disable
              progress meter but still show error messages.

              Providing -s, --silent multiple times has no extra effect.  Dis-
              able it again with --no-silent.

              Example:
               curl -s https://example.com

              See also -v, --verbose, --stderr and --no-progress-meter.

       --socks4 <host[:port]>
              Use the specified SOCKS4 proxy. If the port number is not speci-
              fied,  it  is  assumed at port 1080. Using this socket type make
              curl resolve the host name and passing the  address  on  to  the
              proxy.

              To  specify  proxy  on  a  unix domain socket, use localhost for
              host, e.g.  socks4://localhost/path/to/socket.sock

              This option overrides any previous use of -x, --proxy,  as  they
              are mutually exclusive.

              This  option is superfluous since you can specify a socks4 proxy
              with -x, --proxy using a socks4:// protocol prefix.

              Since 7.52.0, --preproxy can be used to specify a SOCKS proxy at
              the  same  time -x, --proxy is used with an HTTP/HTTPS proxy. In
              such a case curl first connects to the SOCKS proxy and then con-
              nects (through SOCKS) to the HTTP or HTTPS proxy.

              If  --socks4  is provided several times, the last set value will
              be used.

              Example:
               curl --socks4 hostname:4096 https://example.com

              See also --socks4a, --socks5 and --socks5-hostname.

       --socks4a <host[:port]>
              Use the specified SOCKS4a proxy. If the port number is not spec-
              ified,  it  is  assumed at port 1080. This asks the proxy to re-
              solve the host name.

              To specify proxy on a unix  domain  socket,  use  localhost  for
              host, e.g.  socks4a://localhost/path/to/socket.sock

              This  option  overrides any previous use of -x, --proxy, as they
              are mutually exclusive.

              This option is superfluous since you can specify a socks4a proxy
              with -x, --proxy using a socks4a:// protocol prefix.

              Since 7.52.0, --preproxy can be used to specify a SOCKS proxy at
              the same time -x, --proxy is used with an HTTP/HTTPS  proxy.  In
              such a case curl first connects to the SOCKS proxy and then con-
              nects (through SOCKS) to the HTTP or HTTPS proxy.

              If --socks4a is provided several times, the last set value  will
              be used.

              Example:
               curl --socks4a hostname:4096 https://example.com

              See also --socks4, --socks5 and --socks5-hostname.

       --socks5-basic
              Tells curl to use username/password authentication when connect-
              ing to a SOCKS5 proxy.  The username/password authentication  is
              enabled  by  default.   Use --socks5-gssapi to force GSS-API au-
              thentication to SOCKS5 proxies.

              Providing --socks5-basic multiple times has no extra effect.

              Example:
               curl --socks5-basic --socks5 hostname:4096 https://example.com

              See also --socks5. Added in 7.55.0.

       --socks5-gssapi-nec
              As part of the GSS-API negotiation a protection mode is  negoti-
              ated.  RFC  1961 says in section 4.3/4.4 it should be protected,
              but the  NEC  reference  implementation  does  not.  The  option
              --socks5-gssapi-nec  allows the unprotected exchange of the pro-
              tection mode negotiation.

              Providing --socks5-gssapi-nec multiple times has  no  extra  ef-
              fect.  Disable it again with --no-socks5-gssapi-nec.

              Example:
               curl --socks5-gssapi-nec --socks5 hostname:4096 https://example.com

              See also --socks5.

       --socks5-gssapi-service <name>
              The default service name for a socks server is rcmd/server-fqdn.
              This option allows you to change it.

              Examples:  --socks5  proxy-name  --socks5-gssapi-service   sockd
              would  use sockd/proxy-name --socks5 proxy-name --socks5-gssapi-
              service sockd/real-name  would  use  sockd/real-name  for  cases
              where the proxy-name does not match the principal name.

              If  --socks5-gssapi-service  is provided several times, the last
              set value will be used.

              Example:
               curl --socks5-gssapi-service sockd --socks5 hostname:4096 https://example.com

              See also --socks5.

       --socks5-gssapi
              Tells curl to use GSS-API authentication when  connecting  to  a
              SOCKS5  proxy.  The GSS-API authentication is enabled by default
              (if curl is compiled with GSS-API support).  Use  --socks5-basic
              to force username/password authentication to SOCKS5 proxies.

              Providing  --socks5-gssapi  multiple  times has no extra effect.
              Disable it again with --no-socks5-gssapi.

              Example:
               curl --socks5-gssapi --socks5 hostname:4096 https://example.com

              See also --socks5. Added in 7.55.0.

       --socks5-hostname <host[:port]>
              Use the specified SOCKS5 proxy (and let the  proxy  resolve  the
              host  name).  If the port number is not specified, it is assumed
              at port 1080.

              To specify proxy on a unix  domain  socket,  use  localhost  for
              host, e.g.  socks5h://localhost/path/to/socket.sock

              This  option  overrides any previous use of -x, --proxy, as they
              are mutually exclusive.

              This option is superfluous since you can specify a socks5  host-
              name proxy with -x, --proxy using a socks5h:// protocol prefix.

              Since 7.52.0, --preproxy can be used to specify a SOCKS proxy at
              the same time -x, --proxy is used with an HTTP/HTTPS  proxy.  In
              such a case curl first connects to the SOCKS proxy and then con-
              nects (through SOCKS) to the HTTP or HTTPS proxy.

              If --socks5-hostname is provided several  times,  the  last  set
              value will be used.

              Example:
               curl --socks5-hostname proxy.example:7000 https://example.com

              See also --socks5 and --socks4a.

       --socks5 <host[:port]>
              Use  the  specified SOCKS5 proxy - but resolve the host name lo-
              cally. If the port number is not specified,  it  is  assumed  at
              port 1080.

              To  specify  proxy  on  a  unix domain socket, use localhost for
              host, e.g.  socks5://localhost/path/to/socket.sock

              This option overrides any previous use of -x, --proxy,  as  they
              are mutually exclusive.

              This  option is superfluous since you can specify a socks5 proxy
              with -x, --proxy using a socks5:// protocol prefix.

              Since 7.52.0, --preproxy can be used to specify a SOCKS proxy at
              the  same  time -x, --proxy is used with an HTTP/HTTPS proxy. In
              such a case curl first connects to the SOCKS proxy and then con-
              nects (through SOCKS) to the HTTP or HTTPS proxy.

              This  option (as well as --socks4) does not work with IPV6, FTPS
              or LDAP.

              If --socks5 is provided several times, the last set  value  will
              be used.

              Example:
               curl --socks5 proxy.example:7000 https://example.com

              See also --socks5-hostname and --socks4a.

       -Y, --speed-limit <speed>
              If a transfer is slower than this given speed (in bytes per sec-
              ond) for speed-time seconds it gets aborted. speed-time  is  set
              with -y, --speed-time and is 30 if not set.

              If  -Y,  --speed-limit  is  provided several times, the last set
              value will be used.

              Example:
               curl --speed-limit 300 --speed-time 10 https://example.com

              See also -y, --speed-time, --limit-rate and -m, --max-time.

       -y, --speed-time <seconds>
              If a transfer runs slower than speed-limit bytes per second dur-
              ing  a speed-time period, the transfer is aborted. If speed-time
              is used, the default speed-limit will be 1 unless set  with  -Y,
              --speed-limit.

              This option controls transfers (in both directions) but will not
              affect slow connects etc. If this is a concern for you, try  the
              --connect-timeout option.

              If  -y,  --speed-time  is  provided  several times, the last set
              value will be used.

              Example:
               curl --speed-limit 300 --speed-time 10 https://example.com

              See also -Y, --speed-limit and --limit-rate.

       --ssl-allow-beast
              This option tells curl to not work around a security flaw in the
              SSL3 and TLS1.0 protocols known as BEAST.  If this option is not
              used, the SSL layer may use workarounds known to cause  interop-
              erability problems with some older SSL implementations.

              WARNING: this option loosens the SSL security, and by using this
              flag you ask for exactly that.

              Providing --ssl-allow-beast multiple times has no extra  effect.
              Disable it again with --no-ssl-allow-beast.

              Example:
               curl --ssl-allow-beast https://example.com

              See also --proxy-ssl-allow-beast and -k, --insecure.

       --ssl-auto-client-cert
              Tell  libcurl  to automatically locate and use a client certifi-
              cate for authentication, when requested by the server. This  op-
              tion  is only supported for Schannel (the native Windows SSL li-
              brary). Prior to 7.77.0 this was the default behavior in libcurl
              with Schannel. Since the server can request any certificate that
              supports client authentication in the OS  certificate  store  it
              could be a privacy violation and unexpected.

              Providing --ssl-auto-client-cert multiple times has no extra ef-
              fect.  Disable it again with --no-ssl-auto-client-cert.

              Example:
               curl --ssl-auto-client-cert https://example.com

              See also --proxy-ssl-auto-client-cert. Added in 7.77.0.

       --ssl-no-revoke
              (Schannel) This option tells curl to disable certificate revoca-
              tion checks.  WARNING: this option loosens the SSL security, and
              by using this flag you ask for exactly that.

              Providing --ssl-no-revoke multiple times has  no  extra  effect.
              Disable it again with --no-ssl-no-revoke.

              Example:
               curl --ssl-no-revoke https://example.com

              See also --crlfile. Added in 7.44.0.

       --ssl-reqd
              (FTP  IMAP  POP3  SMTP LDAP) Require SSL/TLS for the connection.
              Terminates the connection if the transfer cannot be upgraded  to
              use SSL/TLS.

              This option is handled in LDAP since version 7.81.0. It is fully
              supported by the OpenLDAP backend and rejected  by  the  generic
              ldap backend if explicit TLS is required.

              This  option  is unnecessary if you use a URL scheme that in it-
              self implies immediate and implicit use of TLS, like  for  FTPS,
              IMAPS,  POP3S,  SMTPS and LDAPS. Such transfers will always fail
              if the TLS handshake does not work.

              This option was formerly known as --ftp-ssl-reqd.

              Providing --ssl-reqd multiple times has no extra  effect.   Dis-
              able it again with --no-ssl-reqd.

              Example:
               curl --ssl-reqd ftp://example.com

              See also --ssl and -k, --insecure.

       --ssl-revoke-best-effort
              (Schannel)  This option tells curl to ignore certificate revoca-
              tion checks when they failed due to missing/offline distribution
              points for the revocation check lists.

              Providing  --ssl-revoke-best-effort  multiple times has no extra
              effect.  Disable it again with --no-ssl-revoke-best-effort.

              Example:
               curl --ssl-revoke-best-effort https://example.com

              See also --crlfile and -k, --insecure. Added in 7.70.0.

       --ssl  (FTP IMAP POP3 SMTP LDAP) Warning: this is considered  an  inse-
              cure  option.  Consider using --ssl-reqd instead to be sure curl
              upgrades to a secure connection.

              Try to use SSL/TLS for the connection. Reverts to  a  non-secure
              connection  if  the  server  does  not support SSL/TLS. See also
              --ftp-ssl-control and --ssl-reqd for different levels of encryp-
              tion required.

              This option is handled in LDAP since version 7.81.0. It is fully
              supported by the OpenLDAP backend and  ignored  by  the  generic
              ldap backend.

              Please  note that a server may close the connection if the nego-
              tiation does not succeed.

              This option was formerly known as --ftp-ssl.  That  option  name
              can still be used but will be removed in a future version.

              Providing  --ssl multiple times has no extra effect.  Disable it
              again with --no-ssl.

              Example:
               curl --ssl pop3://example.com/

              See also --ssl-reqd, -k, --insecure and --ciphers.

       -2, --sslv2
              (SSL) This option previously asked curl to use SSLv2, but start-
              ing  in curl 7.77.0 this instruction is ignored. SSLv2 is widely
              considered insecure (see RFC 6176).

              Providing -2, --sslv2 multiple times has no extra effect.

              Example:
               curl --sslv2 https://example.com

              See also --http1.1 and --http2. -2, --sslv2  requires  that  the
              underlying  libcurl was built to support TLS. This option is mu-
              tually exclusive to -3, --sslv3 and -1,  --tlsv1  and  --tlsv1.1
              and --tlsv1.2.

       -3, --sslv3
              (SSL) This option previously asked curl to use SSLv3, but start-
              ing in curl 7.77.0 this instruction is ignored. SSLv3 is  widely
              considered insecure (see RFC 7568).

              Providing -3, --sslv3 multiple times has no extra effect.

              Example:
               curl --sslv3 https://example.com

              See  also  --http1.1  and --http2. -3, --sslv3 requires that the
              underlying libcurl was built to support TLS. This option is  mu-
              tually  exclusive  to  -2, --sslv2 and -1, --tlsv1 and --tlsv1.1
              and --tlsv1.2.

       --stderr <file>
              Redirect all writes to stderr to the specified file instead.  If
              the file name is a plain '-', it is instead written to stdout.

              This option is global and does not need to be specified for each
              use of -:, --next.

              If --stderr is provided several times, the last set  value  will
              be used.

              Example:
               curl --stderr output.txt https://example.com

              See also -v, --verbose and -s, --silent.

       --styled-output
              Enables  the automatic use of bold font styles when writing HTTP
              headers to the terminal. Use --no-styled-output to  switch  them
              off.

              Styled output requires a terminal that supports bold fonts. This
              feature is not present on curl for Windows due to lack  of  this
              capability.

              This option is global and does not need to be specified for each
              use of -:, --next.

              Providing --styled-output multiple times has  no  extra  effect.
              Disable it again with --no-styled-output.

              Example:
               curl --styled-output -I https://example.com

              See also -I, --head and -v, --verbose. Added in 7.61.0.

       --suppress-connect-headers
              When  -p, --proxytunnel is used and a CONNECT request is made do
              not output proxy CONNECT response headers. This option is  meant
              to  be  used  with  -D, --dump-header or -i, --include which are
              used to show protocol headers in the output. It has no effect on
              debug  options  such as -v, --verbose or --trace, or any statis-
              tics.

              Providing --suppress-connect-headers multiple times has no extra
              effect.  Disable it again with --no-suppress-connect-headers.

              Example:
               curl --suppress-connect-headers --include -x proxy https://example.com

              See also -D, --dump-header, -i, --include and -p, --proxytunnel.
              Added in 7.54.0.

       --tcp-fastopen
              Enable use of TCP Fast Open (RFC7413).

              Providing --tcp-fastopen multiple times  has  no  extra  effect.
              Disable it again with --no-tcp-fastopen.

              Example:
               curl --tcp-fastopen https://example.com

              See also --false-start. Added in 7.49.0.

       --tcp-nodelay
              Turn  on the TCP_NODELAY option. See the curl_easy_setopt(3) man
              page for details about this option.

              Since 7.50.2, curl sets this option by default and you  need  to
              explicitly switch it off if you do not want it on.

              Providing  --tcp-nodelay  multiple  times  has  no extra effect.
              Disable it again with --no-tcp-nodelay.

              Example:
               curl --tcp-nodelay https://example.com

              See also -N, --no-buffer.

       -t, --telnet-option <opt=val>
              Pass options to the telnet protocol. Supported options are:

              TTYPE=<term> Sets the terminal type.

              XDISPLOC=<X display> Sets the X display location.

              NEW_ENV=<var,val> Sets an environment variable.

              -t, --telnet-option can be used several times in a command line

              Example:
               curl -t TTYPE=vt100 telnet://example.com/

              See also -K, --config.

       --tftp-blksize <value>
              (TFTP) Set TFTP BLKSIZE option (must be >512). This is the block
              size that curl will try to use when transferring data to or from
              a TFTP server. By default 512 bytes will be used.

              If --tftp-blksize is provided several times, the last set  value
              will be used.

              Example:
               curl --tftp-blksize 1024 tftp://example.com/file

              See also --tftp-no-options.

       --tftp-no-options
              (TFTP) Tells curl not to send TFTP options requests.

              This  option  improves  interop with some legacy servers that do
              not acknowledge or properly implement TFTP  options.  When  this
              option is used --tftp-blksize is ignored.

              Providing  --tftp-no-options multiple times has no extra effect.
              Disable it again with --no-tftp-no-options.

              Example:
               curl --tftp-no-options tftp://192.168.0.1/

              See also --tftp-blksize. Added in 7.48.0.

       -z, --time-cond <time>
              (HTTP FTP) Request a file that has been modified later than  the
              given  time  and date, or one that has been modified before that
              time. The <date expression> can be all sorts of date strings  or
              if  it  does not match any internal ones, it is taken as a file-
              name and tries to get the modification date (mtime) from  <file>
              instead.  See  the curl_getdate(3) man pages for date expression
              details.

              Start the date expression with a dash (-) to make it request for
              a  document that is older than the given date/time, default is a
              document that is newer than the specified date/time.

              If -z, --time-cond is provided several times, the last set value
              will be used.

              Examples:
               curl -z "Wed 01 Sep 2021 12:18:00" https://example.com
               curl -z "-Wed 01 Sep 2021 12:18:00" https://example.com
               curl -z file https://example.com

              See also --etag-compare and -R, --remote-time.

       --tls-max <VERSION>
              (SSL) VERSION defines maximum supported TLS version. The minimum
              acceptable version  is  set  by  tlsv1.0,  tlsv1.1,  tlsv1.2  or
              tlsv1.3.

              If  the  connection  is done without TLS, this option has no ef-
              fect. This includes QUIC-using (HTTP/3) transfers.

              default
                     Use up to recommended TLS version.

              1.0    Use up to TLSv1.0.

              1.1    Use up to TLSv1.1.

              1.2    Use up to TLSv1.2.

              1.3    Use up to TLSv1.3.

       If --tls-max is provided several times, the  last  set  value  will  be
       used.

       Examples:
        curl --tls-max 1.2 https://example.com
        curl --tls-max 1.3 --tlsv1.2 https://example.com

       See  also  --tlsv1.0, --tlsv1.1, --tlsv1.2 and --tlsv1.3. --tls-max re-
       quires that the underlying libcurl was built to support TLS.  Added  in
       7.54.0.

       --tls13-ciphers <ciphersuite list>
              (TLS)  Specifies which cipher suites to use in the connection if
              it negotiates TLS 1.3. The list of ciphers suites  must  specify
              valid  ciphers.  Read up on TLS 1.3 cipher suite details on this
              URL:

               https://curl.se/docs/ssl-ciphers.html

              This option is currently used only when curl  is  built  to  use
              OpenSSL 1.1.1 or later. If you are using a different SSL backend
              you can try setting TLS 1.3 cipher suites by using the --ciphers
              option.

              If --tls13-ciphers is provided several times, the last set value
              will be used.

              Example:
               curl --tls13-ciphers TLS_AES_128_GCM_SHA256 https://example.com

              See also --ciphers and --curves. Added in 7.61.0.

       --tlsauthtype <type>
              Set TLS authentication type. Currently, the only  supported  op-
              tion  is  "SRP",  for  TLS-SRP  (RFC  5054).  If  --tlsuser  and
              --tlspassword are specified but --tlsauthtype is not, then  this
              option defaults to "SRP". This option works only if the underly-
              ing libcurl  is  built  with  TLS-SRP  support,  which  requires
              OpenSSL or GnuTLS with TLS-SRP support.

              If  --tlsauthtype  is provided several times, the last set value
              will be used.

              Example:
               curl --tlsauthtype SRP https://example.com

              See also --tlsuser.

       --tlspassword <string>
              Set password for use with the TLS authentication  method  speci-
              fied with --tlsauthtype. Requires that --tlsuser also be set.

              This option does not work with TLS 1.3.

              If  --tlspassword  is provided several times, the last set value
              will be used.

              Example:
               curl --tlspassword pwd --tlsuser user https://example.com

              See also --tlsuser.

       --tlsuser <name>
              Set username for use with the TLS authentication  method  speci-
              fied  with  --tlsauthtype.  Requires  that --tlspassword also is
              set.

              This option does not work with TLS 1.3.

              If --tlsuser is provided several times, the last set value  will
              be used.

              Example:
               curl --tlspassword pwd --tlsuser user https://example.com

              See also --tlspassword.

       --tlsv1.0
              (TLS)  Forces curl to use TLS version 1.0 or later when connect-
              ing to a remote TLS server.

              In old versions of curl this  option  was  documented  to  allow
              _only_ TLS 1.0.  That behavior was inconsistent depending on the
              TLS library. Use --tls-max if you want to set a maximum TLS ver-
              sion.

              Providing --tlsv1.0 multiple times has no extra effect.

              Example:
               curl --tlsv1.0 https://example.com

              See also --tlsv1.3. Added in 7.34.0.

       --tlsv1.1
              (TLS)  Forces curl to use TLS version 1.1 or later when connect-
              ing to a remote TLS server.

              In old versions of curl this  option  was  documented  to  allow
              _only_ TLS 1.1.  That behavior was inconsistent depending on the
              TLS library. Use --tls-max if you want to set a maximum TLS ver-
              sion.

              Providing --tlsv1.1 multiple times has no extra effect.

              Example:
               curl --tlsv1.1 https://example.com

              See also --tlsv1.3 and --tls-max. Added in 7.34.0.

       --tlsv1.2
              (TLS)  Forces curl to use TLS version 1.2 or later when connect-
              ing to a remote TLS server.

              In old versions of curl this  option  was  documented  to  allow
              _only_ TLS 1.2.  That behavior was inconsistent depending on the
              TLS library. Use --tls-max if you want to set a maximum TLS ver-
              sion.

              Providing --tlsv1.2 multiple times has no extra effect.

              Example:
               curl --tlsv1.2 https://example.com

              See also --tlsv1.3 and --tls-max. Added in 7.34.0.

       --tlsv1.3
              (TLS)  Forces curl to use TLS version 1.3 or later when connect-
              ing to a remote TLS server.

              If the connection is done without TLS, this option  has  no  ef-
              fect. This includes QUIC-using (HTTP/3) transfers.

              Note that TLS 1.3 is not supported by all TLS backends.

              Providing --tlsv1.3 multiple times has no extra effect.

              Example:
               curl --tlsv1.3 https://example.com

              See also --tlsv1.2 and --tls-max. Added in 7.52.0.

       -1, --tlsv1
              (SSL)  Tells curl to use at least TLS version 1.x when negotiat-
              ing with a remote TLS server. That  means  TLS  version  1.0  or
              higher

              Providing -1, --tlsv1 multiple times has no extra effect.

              Example:
               curl --tlsv1 https://example.com

              See  also  --http1.1  and --http2. -1, --tlsv1 requires that the
              underlying libcurl was built to support TLS. This option is  mu-
              tually exclusive to --tlsv1.1 and --tlsv1.2 and --tlsv1.3.

       --tr-encoding
              (HTTP) Request a compressed Transfer-Encoding response using one
              of the algorithms curl supports, and uncompress the  data  while
              receiving it.

              Providing  --tr-encoding  multiple  times  has  no extra effect.
              Disable it again with --no-tr-encoding.

              Example:
               curl --tr-encoding https://example.com

              See also --compressed.

       --trace-ascii <file>
              Enables a full trace dump of all incoming and outgoing data, in-
              cluding  descriptive  information, to the given output file. Use
              "-" as filename to have the output sent to stdout.

              This is similar to --trace, but leaves out the hex part and only
              shows  the  ASCII part of the dump. It makes smaller output that
              might be easier to read for untrained humans.

              This option is global and does not need to be specified for each
              use of -:, --next.

              If  --trace-ascii  is provided several times, the last set value
              will be used.

              Example:
               curl --trace-ascii log.txt https://example.com

              See also -v, --verbose and --trace. This option is mutually  ex-
              clusive to --trace and -v, --verbose.

       --trace-time
              Prepends  a  time  stamp to each trace or verbose line that curl
              displays.

              This option is global and does not need to be specified for each
              use of -:, --next.

              Providing --trace-time multiple times has no extra effect.  Dis-
              able it again with --no-trace-time.

              Example:
               curl --trace-time --trace-ascii output https://example.com

              See also --trace and -v, --verbose.

       --trace <file>
              Enables a full trace dump of all incoming and outgoing data, in-
              cluding  descriptive  information, to the given output file. Use
              "-" as filename to have the output sent to stdout.  Use  "%"  as
              filename to have the output sent to stderr.

              This option is global and does not need to be specified for each
              use of -:, --next.

              If --trace is provided several times, the last set value will be
              used.

              Example:
               curl --trace log.txt https://example.com

              See also --trace-ascii and --trace-time. This option is mutually
              exclusive to -v, --verbose and --trace-ascii.

       --unix-socket <path>
              (HTTP) Connect through this Unix domain socket, instead of using
              the network.

              If  --unix-socket  is provided several times, the last set value
              will be used.

              Example:
               curl --unix-socket socket-path https://example.com

              See also --abstract-unix-socket. Added in 7.40.0.

       -T, --upload-file <file>
              This transfers the specified local file to the  remote  URL.  If
              there is no file part in the specified URL, curl will append the
              local file name. NOTE that you must use a trailing / on the last
              directory  to really prove to Curl that there is no file name or
              curl will think that your last directory name is the remote file
              name to use. That will most likely cause the upload operation to
              fail. If this is used on an HTTP(S) server, the PUT command will
              be used.

              Use  the file name "-" (a single dash) to use stdin instead of a
              given file.  Alternately, the file name "."  (a  single  period)
              may  be  specified  instead  of "-" to use stdin in non-blocking
              mode to allow reading server output while  stdin  is  being  up-
              loaded.

              You  can  specify one -T, --upload-file for each URL on the com-
              mand line. Each -T, --upload-file + URL pair specifies  what  to
              upload  and  to  where. curl also supports "globbing" of the -T,
              --upload-file argument, meaning that  you  can  upload  multiple
              files  to a single URL by using the same URL globbing style sup-
              ported in the URL.

              When uploading to an SMTP server: the uploaded data  is  assumed
              to be RFC 5322 formatted. It has to feature the necessary set of
              headers and mail body formatted correctly by the  user  as  curl
              will not transcode nor encode it further in any way.

              -T, --upload-file can be used several times in a command line

              Examples:
               curl -T file https://example.com
               curl -T "img[1-1000].png" ftp://ftp.example.com/
               curl --upload-file "{file1,file2}" https://example.com

              See also -G, --get and -I, --head.

       --url-query <data>
              (all)  This  option adds a piece of data, usually a name + value
              pair, to the end of the URL query part. The syntax is  identical
              to that used for --data-urlencode with one extension:

              If the argument starts with a '+' (plus), the rest of the string
              is provided as-is unencoded.

              The query part of a URL is the one following the  question  mark
              on the right end.

              --url-query can be used several times in a command line

              Examples:
               curl --url-query name=val https://example.com
               curl --url-query =encodethis http://example.net/foo
               curl --url-query name@file https://example.com
               curl --url-query @fileonly https://example.com
               curl --url-query "+name=%20foo" https://example.com

              See also --data-urlencode and -G, --get. Added in 7.87.0.

       --url <url>
              Specify  a  URL  to  fetch. This option is mostly handy when you
              want to specify URL(s) in a config file.

              If the given URL is missing a scheme name (such as "http://"  or
              "ftp://"  etc) then curl will make a guess based on the host. If
              the outermost sub-domain name matches  DICT,  FTP,  IMAP,  LDAP,
              POP3  or  SMTP  then  that protocol will be used, otherwise HTTP
              will be used. Since 7.45.0 guessing can be disabled by setting a
              default protocol, see --proto-default for details.

              To  control  where  this URL is written, use the -o, --output or
              the -O, --remote-name options.

              WARNING: On Windows, particular file://  accesses  can  be  con-
              verted to network accesses by the operating system. Beware!

              --url can be used several times in a command line

              Example:
               curl --url https://example.com

              See also -:, --next and -K, --config.

       -B, --use-ascii
              (FTP  LDAP) Enable ASCII transfer. For FTP, this can also be en-
              forced by using a URL that  ends  with  ";type=A".  This  option
              causes data sent to stdout to be in text mode for win32 systems.

              Providing  -B,  --use-ascii  multiple times has no extra effect.
              Disable it again with --no-use-ascii.

              Example:
               curl -B ftp://example.com/README

              See also --crlf and --data-ascii.

       -A, --user-agent <name>
              (HTTP) Specify the User-Agent string to send to the HTTP server.
              To  encode blanks in the string, surround the string with single
              quote marks. This header can also be set with the  -H,  --header
              or the --proxy-header options.

              If  you give an empty argument to -A, --user-agent (""), it will
              remove the header completely from the request. If you  prefer  a
              blank header, you can set it to a single space (" ").

              If  -A,  --user-agent  is  provided  several times, the last set
              value will be used.

              Example:
               curl -A "Agent 007" https://example.com

              See also -H, --header and --proxy-header.

       -u, --user <user:password>
              Specify the user name and password to use for server authentica-
              tion. Overrides -n, --netrc and --netrc-optional.

              If  you  simply  specify  the  user name, curl will prompt for a
              password.

              The user name and passwords are split up  on  the  first  colon,
              which  makes  it impossible to use a colon in the user name with
              this option. The password can, still.

              On systems where it works, curl will hide the given option argu-
              ment  from  process listings. This is not enough to protect cre-
              dentials from possibly getting seen by other users on  the  same
              system  as  they  will  still  be  visible  for  a moment before
              cleared. Such sensitive data should be retrieved from a file in-
              stead or similar and never used in clear text in a command line.

              When  using  Kerberos  V5 with a Windows based server you should
              include the Windows domain name in the user name, in  order  for
              the  server  to successfully obtain a Kerberos Ticket. If you do
              not, then the initial authentication handshake may fail.

              When using NTLM, the user name can be specified  simply  as  the
              user  name,  without the domain, if there is a single domain and
              forest in your setup for example.

              To specify the domain name use either Down-Level Logon  Name  or
              UPN (User Principal Name) formats. For example, EXAMPLE\user and
              user@example.com respectively.

              If you use a Windows SSPI-enabled curl binary and  perform  Ker-
              beros  V5, Negotiate, NTLM or Digest authentication then you can
              tell curl to select the user name and password from  your  envi-
              ronment by specifying a single colon with this option: "-u :".

              If -u, --user is provided several times, the last set value will
              be used.

              Example:
               curl -u user:secret https://example.com

              See also -n, --netrc and -K, --config.

       -v, --verbose
              Makes curl verbose during the operation.  Useful  for  debugging
              and  seeing  what's  going  on "under the hood". A line starting
              with '>' means "header data" sent by  curl,  '<'  means  "header
              data"  received  by  curl  that is hidden in normal cases, and a
              line starting with '*' means additional info provided by curl.

              If you only want HTTP headers in the output, -i, --include might
              be the option you are looking for.

              If you think this option still does not give you enough details,
              consider using --trace or --trace-ascii instead.

              This option is global and does not need to be specified for each
              use of -:, --next.

              Use -s, --silent to make curl really quiet.

              Providing  -v,  --verbose  multiple  times  has no extra effect.
              Disable it again with --no-verbose.

              Example:
               curl --verbose https://example.com

              See also -i, --include. This option  is  mutually  exclusive  to
              --trace and --trace-ascii.

       -V, --version
              Displays information about curl and the libcurl version it uses.

              The  first  line  includes the full version of curl, libcurl and
              other 3rd party libraries linked with the executable.

              The second line (starts with "Protocols:") shows  all  protocols
              that libcurl reports to support.

              The third line (starts with "Features:") shows specific features
              libcurl reports to offer. Available features include:

              alt-svc
                     Support for the Alt-Svc: header is provided.

              AsynchDNS
                     This curl uses asynchronous name  resolves.  Asynchronous
                     name  resolves can be done using either the c-ares or the
                     threaded resolver backends.

              brotli Support for automatic brotli compression over HTTP(S).

              CharConv
                     curl was built with support for character set conversions
                     (like EBCDIC)

              Debug  This  curl  uses a libcurl built with Debug. This enables
                     more error-tracking and memory debugging etc.  For  curl-
                     developers only!

              gsasl  The  built-in  SASL authentication includes extensions to
                     support SCRAM because libcurl was built with libgsasl.

              GSS-API
                     GSS-API is supported.

              HSTS   HSTS support is present.

              HTTP2  HTTP/2 support has been built-in.

              HTTP3  HTTP/3 support has been built-in.

              HTTPS-proxy
                     This curl is built to support HTTPS proxy.

              IDN    This curl supports IDN - international domain names.

              IPv6   You can use IPv6 with this.

              Kerberos
                     Kerberos V5 authentication is supported.

              Largefile
                     This curl supports transfers of large files, files larger
                     than 2GB.

              libz   Automatic decompression (via gzip, deflate) of compressed
                     files over HTTP is supported.

              MultiSSL
                     This curl supports multiple TLS backends.

              NTLM   NTLM authentication is supported.

              NTLM_WB
                     NTLM delegation to winbind helper is supported.

              PSL    PSL is short for Public Suffix List and means  that  this
                     curl  has  been  built  with knowledge about "public suf-
                     fixes".

              SPNEGO SPNEGO authentication is supported.

              SSL    SSL versions of various protocols are supported, such  as
                     HTTPS, FTPS, POP3S and so on.

              SSPI   SSPI is supported.

              TLS-SRP
                     SRP  (Secure Remote Password) authentication is supported
                     for TLS.

              TrackMemory
                     Debug memory tracking is supported.

              Unicode
                     Unicode support on Windows.

              UnixSockets
                     Unix sockets support is provided.

              zstd   Automatic decompression (via zstd)  of  compressed  files
                     over HTTP is supported.

       Example:
        curl --version

       See also -h, --help and -M, --manual.

       -w, --write-out <format>
              Make curl display information on stdout after a completed trans-
              fer. The format is a string that may contain  plain  text  mixed
              with  any  number of variables. The format can be specified as a
              literal "string", or you can have curl read the  format  from  a
              file  with  "@filename" and to tell curl to read the format from
              stdin you write "@-".

              The variables present in the output format will  be  substituted
              by  the  value or text that curl thinks fit, as described below.
              All variables are specified as %{variable_name} and to output  a
              normal  % you just write them as %%. You can output a newline by
              using \n, a carriage return with \r and a tab space with \t.

              The output will be written to standard output, but this  can  be
              switched to standard error by using %{stderr}.

              Output  HTTP  headers  from  the  most  recent  request by using
              %header{name} where name is the case  insensitive  name  of  the
              header (without the trailing colon). The header contents are ex-
              actly as sent over the network, with leading and trailing white-
              space trimmed. Added in curl 7.84.0.

              NOTE: In Windows the %-symbol is a special symbol used to expand
              environment variables. In batch files all occurrences of %  must
              be  doubled  when  using this option to properly escape. If this
              option is used at the command prompt then the %  cannot  be  es-
              caped and unintended expansion is possible.

              The variables available are:

              certs          Output  the  certificate chain with details. Sup-
                             ported only by  the  OpenSSL,  GnuTLS,  Schannel,
                             NSS,  GSKit  and Secure Transport backends (Added
                             in 7.88.0)

              content_type   The Content-Type of the  requested  document,  if
                             there was any.

              errormsg       The error message. (Added in 7.75.0)

              exitcode       The numerical exitcode of the transfer. (Added in
                             7.75.0)

              filename_effective
                             The ultimate filename that curl  writes  out  to.
                             This  is only meaningful if curl is told to write
                             to a file  with  the  -O,  --remote-name  or  -o,
                             --output  option. It's most useful in combination
                             with the -J, --remote-header-name option.

              ftp_entry_path The initial path curl ended up in when logging on
                             to the remote FTP server.

              header_json    A JSON object with all HTTP response headers from
                             the recent transfer. Values are provided  as  ar-
                             rays, since in the case of multiple headers there
                             can be multiple values. (Added in 7.83.0)

                             The header names provided in lowercase, listed in
                             order of appearance over the wire. Except for du-
                             plicated headers. They are grouped on  the  first
                             occurrence  of  that  header,  each value is pre-
                             sented in the JSON array.

              http_code      The numerical response code that was found in the
                             last retrieved HTTP(S) or FTP(s) transfer.

              http_connect   The numerical code that was found in the last re-
                             sponse (from a proxy) to a curl CONNECT request.

              http_version   The  http  version  that  was  effectively  used.
                             (Added in 7.50.0)

              json           A JSON object with all available keys.

              local_ip       The  IP  address of the local end of the most re-
                             cently done connection - can be  either  IPv4  or
                             IPv6.

              local_port     The  local  port number of the most recently done
                             connection.

              method         The http method used in the most recent HTTP  re-
                             quest. (Added in 7.72.0)

              num_certs      Number of server certificates received in the TLS
                             handshake. Supported only by the OpenSSL, GnuTLS,
                             Schannel,  NSS,  GSKit and Secure Transport back-
                             ends (Added in 7.88.0)

              num_connects   Number of new connects made in the recent  trans-
                             fer.

              num_headers    The number of response headers in the most recent
                             request (restarted at each redirect).  Note  that
                             the  status  line  IS  NOT  a  header.  (Added in
                             7.73.0)

              num_redirects  Number of redirects that were followed in the re-
                             quest.

              onerror        The  rest  of  the  output  is  only shown if the
                             transfer returned  a  non-zero  error  (Added  in
                             7.75.0)

              proxy_ssl_verify_result
                             The result of the HTTPS proxy's SSL peer certifi-
                             cate verification that was requested. 0 means the
                             verification was successful. (Added in 7.52.0)

              redirect_url   When an HTTP request was made without -L, --loca-
                             tion to follow redirects (or when --max-redirs is
                             met),  this  variable  will show the actual URL a
                             redirect would have gone to.

              referer        The Referer: header, if there was any. (Added  in
                             7.76.0)

              remote_ip      The  remote  IP address of the most recently done
                             connection - can be either IPv4 or IPv6.

              remote_port    The remote port number of the most recently  done
                             connection.

              response_code  The numerical response code that was found in the
                             last transfer (formerly known as "http_code").

              scheme         The URL scheme (sometimes called  protocol)  that
                             was effectively used. (Added in 7.52.0)

              size_download  The  total  amount of bytes that were downloaded.
                             This is the size of the body/data that was trans-
                             ferred, excluding headers.

              size_header    The total amount of bytes of the downloaded head-
                             ers.

              size_request   The total amount of bytes that were sent  in  the
                             HTTP request.

              size_upload    The  total  amount  of  bytes that were uploaded.
                             This is the size of the body/data that was trans-
                             ferred, excluding headers.

              speed_download The average download speed that curl measured for
                             the complete download. Bytes per second.

              speed_upload   The average upload speed that curl  measured  for
                             the complete upload. Bytes per second.

              ssl_verify_result
                             The  result of the SSL peer certificate verifica-
                             tion that was requested. 0 means the verification
                             was successful.

              stderr         From  this  point  on, the -w, --write-out output
                             will be written  to  standard  error.  (Added  in
                             7.63.0)

              stdout         From  this  point  on, the -w, --write-out output
                             will be written to standard output.  This is  the
                             default,  but  can  be  used to switch back after
                             switching to stderr.  (Added in 7.63.0)

              time_appconnect
                             The time, in seconds, it took from the start  un-
                             til  the SSL/SSH/etc connect/handshake to the re-
                             mote host was completed.

              time_connect   The time, in seconds, it took from the start  un-
                             til the TCP connect to the remote host (or proxy)
                             was completed.

              time_namelookup
                             The time, in seconds, it took from the start  un-
                             til the name resolving was completed.

              time_pretransfer
                             The  time, in seconds, it took from the start un-
                             til the file transfer was just  about  to  begin.
                             This includes all pre-transfer commands and nego-
                             tiations that are specific to the particular pro-
                             tocol(s) involved.

              time_redirect  The time, in seconds, it took for all redirection
                             steps including name lookup, connect, pretransfer
                             and  transfer  before  the  final transaction was
                             started. time_redirect shows the complete  execu-
                             tion time for multiple redirections.

              time_starttransfer
                             The  time, in seconds, it took from the start un-
                             til the first byte was just about  to  be  trans-
                             ferred.  This  includes time_pretransfer and also
                             the time the server needed to calculate  the  re-
                             sult.

              time_total     The  total time, in seconds, that the full opera-
                             tion lasted.

              url            The URL that was fetched. (Added in 7.75.0)

              urlnum         The URL index number of this transfer, 0-indexed.
                             De-globbed  URLs  share  the same index number as
                             the origin globbed URL. (Added in 7.75.0)

              url_effective  The URL that was fetched last. This is most mean-
                             ingful  if you have told curl to follow location:
                             headers.

              If -w, --write-out is provided several times, the last set value
              will be used.

              Example:
               curl -w '%{http_code}\n' https://example.com

              See also -v, --verbose and -I, --head.

       --xattr
              When  saving  output  to a file, this option tells curl to store
              certain file metadata in extended  file  attributes.  Currently,
              the URL is stored in the xdg.origin.url attribute and, for HTTP,
              the content type is stored in the mime_type  attribute.  If  the
              file  system  does not support extended attributes, a warning is
              issued.

              Providing --xattr multiple times has no extra  effect.   Disable
              it again with --no-xattr.

              Example:
               curl --xattr -o storage https://example.com

              See also -R, --remote-time, -w, --write-out and -v, --verbose.

EXECUTION EXAMPLE:
COMMAND INPUT:
curl --version

COMMAND OUTPUT:
curl 7.88.1 (x86_64-pc-linux-gnu) libcurl/7.88.1 OpenSSL/3.0.15 zlib/1.2.13 brotli/1.0.9 zstd/1.5.4 libidn2/2.3.3 libpsl/0.21.2 (+libidn2/2.3.3) libssh2/1.10.0 nghttp2/1.52.0 librtmp/2.3 OpenLDAP/2.5.13
Release-Date: 2023-02-20, security patched: 7.88.1-10+deb12u8
Protocols: dict file ftp ftps gopher gophers http https imap imaps ldap ldaps mqtt pop3 pop3s rtmp rtsp scp sftp smb smbs smtp smtps telnet tftp
Features: alt-svc AsynchDNS brotli GSS-API HSTS HTTP2 HTTPS-proxy IDN IPv6 Kerberos Largefile libz NTLM NTLM_WB PSL SPNEGO SSL threadsafe TLS-SRP UnixSockets zstd

===

COMMAND: nc

DESCRIPTION: nc -- arbitrary TCP and UDP connections and listens

USAGE: nc [-46bCDdFhklNnrStUuvZz] [-I length] [-i interval] [-M ttl] [-m minttl]
        [-O length] [-P proxy_username] [-p source_port] [-q seconds]
        [-s sourceaddr] [-T keyword] [-V rtable] [-W recvlimit] [-w timeout]
        [-X proxy_protocol] [-x proxy_address[:port]] [destination] [port]

EXECUTION EXAMPLE:
COMMAND INPUT:
nc -h

COMMAND OUTPUT:
OpenBSD netcat (Debian patchlevel 1.219-1)
usage: nc [-46CDdFhklNnrStUuvZz] [-I length] [-i interval] [-M ttl]
	  [-m minttl] [-O length] [-P proxy_username] [-p source_port]
	  [-q seconds] [-s sourceaddr] [-T keyword] [-V rtable] [-W recvlimit]
	  [-w timeout] [-X proxy_protocol] [-x proxy_address[:port]]
	  [destination] [port]
	Command Summary:
		-4		Use IPv4
		-6		Use IPv6
		-b		Allow broadcast
		-C		Send CRLF as line-ending
		-D		Enable the debug socket option
		-d		Detach from stdin
		-F		Pass socket fd
		-h		This help text
		-I length	TCP receive buffer length
		-i interval	Delay interval for lines sent, ports scanned
		-k		Keep inbound sockets open for multiple connects
		-l		Listen mode, for inbound connects
		-M ttl		Outgoing TTL / Hop Limit
		-m minttl	Minimum incoming TTL / Hop Limit
		-N		Shutdown the network socket after EOF on stdin
		-n		Suppress name/port resolutions
		-O length	TCP send buffer length
		-P proxyuser	Username for proxy authentication
		-p port		Specify local port for remote connects
		-q secs		quit after EOF on stdin and delay of secs
		-r		Randomize remote ports
		-S		Enable the TCP MD5 signature option
		-s sourceaddr	Local source address
		-T keyword	TOS value
		-t		Answer TELNET negotiation
		-U		Use UNIX domain socket
		-u		UDP mode
		-V rtable	Specify alternate routing table
		-v		Verbose
		-W recvlimit	Terminate after receiving a number of packets
		-w timeout	Timeout for connects and final net reads
		-X proto	Proxy protocol: "4", "5" (SOCKS) or "connect"
		-x addr[:port]	Specify proxy address and port
		-Z		DCCP mode
		-z		Zero-I/O mode [used for scanning]
	Port numbers can be individual or ranges: lo-hi [inclusive]

===

COMMAND: ssh

DESCRIPTION: ssh -- OpenSSH remote login client

USAGE: ssh [-46AaCfGgKkMNnqsTtVvXxYy] [-B bind_interface] [-b bind_address]
         [-c cipher_spec] [-D [bind_address:]port] [-E log_file]
         [-e escape_char] [-F configfile] [-I pkcs11] [-i identity_file]
         [-J destination] [-L address] [-l login_name] [-m mac_spec]
         [-O ctl_cmd] [-o option] [-p port] [-Q query_option] [-R address]
         [-S ctl_path] [-W host:port] [-w local_tun[:remote_tun]] destination
         [command [argument ...]]

EXECUTION EXAMPLE:
COMMAND INPUT:
ssh -V

COMMAND OUTPUT:
OpenSSH_9.2p1 Debian-2+deb12u4, OpenSSL 3.0.15 3 Sep 2024

===

COMMAND: scp

DESCRIPTION: scp -- OpenSSH secure file copy

USAGE: scp [-346ABCOpqRrsTv] [-c cipher] [-D sftp_server_path] [-F ssh_config]
         [-i identity_file] [-J destination] [-l limit] [-o ssh_option]
         [-P port] [-S program] [-X sftp_option] source ... target

EXECUTION EXAMPLE:
COMMAND INPUT:
scp -V

COMMAND OUTPUT:
scp: unknown option -- V
usage: scp [-346ABCOpqRrsTv] [-c cipher] [-D sftp_server_path] [-F ssh_config]
           [-i identity_file] [-J destination] [-l limit] [-o ssh_option]
           [-P port] [-S program] [-X sftp_option] source ... target

===

COMMAND: sftp

DESCRIPTION: sftp -- OpenSSH secure file transfer

USAGE: sftp [-46AaCfNpqrv] [-B buffer_size] [-b batchfile] [-c cipher]
          [-D sftp_server_command] [-F ssh_config] [-i identity_file]
          [-J destination] [-l limit] [-o ssh_option] [-P port]
          [-R num_requests] [-S program] [-s subsystem | sftp_server]
          [-X sftp_option] destination

EXECUTION EXAMPLE:
COMMAND INPUT:
sftp -V

COMMAND OUTPUT:
unknown option -- V
usage: sftp [-46AaCfNpqrv] [-B buffer_size] [-b batchfile] [-c cipher]
          [-D sftp_server_command] [-F ssh_config] [-i identity_file]
          [-J destination] [-l limit] [-o ssh_option] [-P port]
          [-R num_requests] [-S program] [-s subsystem | sftp_server]
          [-X sftp_option] destination

===

COMMAND: nmap

DESCRIPTION: nmap - Network exploration tool and security / port scanner

USAGE: nmap [Scan Type...] [Options] {target specification}

OPTIONS:
This section describes some important (and not-so-important) options
       that don't really fit anywhere else.

       -6 (Enable IPv6 scanning)
           Nmap has IPv6 support for its most popular features. Ping scanning,
           port scanning, version detection, and the Nmap Scripting Engine all
           support IPv6. The command syntax is the same as usual except that
           you also add the -6 option. Of course, you must use IPv6 syntax if
           you specify an address rather than a hostname. An address might
           look like 3ffe:7501:4819:2000:210:f3ff:fe03:14d0, so hostnames are
           recommended. The output looks the same as usual, with the IPv6
           address on the "interesting ports" line being the only IPv6
           giveaway.

           While IPv6 hasn't exactly taken the world by storm, it gets
           significant use in some (usually Asian) countries and most modern
           operating systems support it. To use Nmap with IPv6, both the
           source and target of your scan must be configured for IPv6. If your
           ISP (like most of them) does not allocate IPv6 addresses to you,
           free tunnel brokers are widely available and work fine with Nmap. I
           use the free IPv6 tunnel broker service at
           http://www.tunnelbroker.net. Other tunnel brokers are listed at
           Wikipedia[17]. 6to4 tunnels are another popular, free approach.

           On Windows, raw-socket IPv6 scans are supported only on ethernet
           devices (not tunnels), and only on Windows Vista and later. Use the
           --unprivileged option in other situations.

       -A (Aggressive scan options)
           This option enables additional advanced and aggressive options.
           Presently this enables OS detection (-O), version scanning (-sV),
           script scanning (-sC) and traceroute (--traceroute).  More features
           may be added in the future. The point is to enable a comprehensive
           set of scan options without people having to remember a large set
           of flags. However, because script scanning with the default set is
           considered intrusive, you should not use -A against target networks
           without permission. This option only enables features, and not
           timing options (such as -T4) or verbosity options (-v) that you
           might want as well. Options which require privileges (e.g. root
           access) such as OS detection and traceroute will only be enabled if
           those privileges are available.

       --datadir directoryname (Specify custom Nmap data file location)
           Nmap obtains some special data at runtime in files named
           nmap-service-probes, nmap-services, nmap-protocols, nmap-rpc,
           nmap-mac-prefixes, and nmap-os-db. If the location of any of these
           files has been specified (using the --servicedb or --versiondb
           options), that location is used for that file. After that, Nmap
           searches these files in the directory specified with the --datadir
           option (if any). Any files not found there, are searched for in the
           directory specified by the NMAPDIR environment variable. Next comes
           ~/.nmap for real and effective UIDs; or on Windows,
           HOME\AppData\Roaming\nmap (where HOME is the user's home directory,
           like C:\Users\user). This is followed by the location of the nmap
           executable and the same location with ../share/nmap appended. Then
           a compiled-in location such as /usr/local/share/nmap or
           /usr/share/nmap.

       --servicedb services file (Specify custom services file)
           Asks Nmap to use the specified services file rather than the
           nmap-services data file that comes with Nmap. Using this option
           also causes a fast scan (-F) to be used. See the description for
           --datadir for more information on Nmap's data files.

       --versiondb service probes file (Specify custom service probes file)
           Asks Nmap to use the specified service probes file rather than the
           nmap-service-probes data file that comes with Nmap. See the
           description for --datadir for more information on Nmap's data
           files.

       --send-eth (Use raw ethernet sending)
           Asks Nmap to send packets at the raw ethernet (data link) layer
           rather than the higher IP (network) layer. By default, Nmap chooses
           the one which is generally best for the platform it is running on.
           Raw sockets (IP layer) are generally most efficient for Unix
           machines, while ethernet frames are required for Windows operation
           since Microsoft disabled raw socket support. Nmap still uses raw IP
           packets on Unix despite this option when there is no other choice
           (such as non-ethernet connections).

       --send-ip (Send at raw IP level)
           Asks Nmap to send packets via raw IP sockets rather than sending
           lower level ethernet frames. It is the complement to the --send-eth
           option discussed previously.

       --privileged (Assume that the user is fully privileged)
           Tells Nmap to simply assume that it is privileged enough to perform
           raw socket sends, packet sniffing, and similar operations that
           usually require root privileges on Unix systems. By default Nmap
           quits if such operations are requested but geteuid is not zero.
           --privileged is useful with Linux kernel capabilities and similar
           systems that may be configured to allow unprivileged users to
           perform raw-packet scans. Be sure to provide this option flag
           before any flags for options that require privileges (SYN scan, OS
           detection, etc.). The NMAP_PRIVILEGED environment variable may be
           set as an equivalent alternative to --privileged.

       --unprivileged (Assume that the user lacks raw socket privileges)
           This option is the opposite of --privileged. It tells Nmap to treat
           the user as lacking network raw socket and sniffing privileges.
           This is useful for testing, debugging, or when the raw network
           functionality of your operating system is somehow broken. The
           NMAP_UNPRIVILEGED environment variable may be set as an equivalent
           alternative to --unprivileged.

       --release-memory (Release memory before quitting)
           This option is only useful for memory-leak debugging. It causes
           Nmap to release allocated memory just before it quits so that
           actual memory leaks are easier to spot. Normally Nmap skips this as
           the OS does this anyway upon process termination.

       -V; --version (Print version number)
           Prints the Nmap version number and exits.

       -h; --help (Print help summary page)
           Prints a short help screen with the most common command flags.
           Running Nmap without any arguments does the same thing.

EXECUTION EXAMPLE:
COMMAND INPUT:
nmap --version

COMMAND OUTPUT:
Nmap version 7.93 ( https://nmap.org )
Platform: x86_64-pc-linux-gnu
Compiled with: liblua-5.3.6 openssl-3.0.15 libssh2-1.10.0 libz-1.2.13 libpcre-8.39 libpcap-1.10.3 nmap-libdnet-1.12 ipv6
Compiled without:
Available nsock engines: epoll poll select

===

COMMAND: dig

DESCRIPTION: dig - DNS lookup utility

USAGE: dig  [@server] [-b address] [-c class] [-f filename] [-k filename] [-m]
       [-p port#] [-q name] [-t type] [-v] [-x addr]  [-y  [hmac:]name:key]  [
       [-4] | [-6] ] [name] [type] [class] [queryopt...]

       dig [-h]

       dig [global-queryopt...] [query...]

OPTIONS:
-4     This option indicates that only IPv4 should be used.

       -6     This option indicates that only IPv6 should be used.

       -b address[#port]
              This option sets the source IP address of the query. The address
              must be a valid address on one of the host's network interfaces,
              or  "0.0.0.0"  or "::". An optional port may be specified by ap-
              pending #port.

       -c class
              This option sets the query class. The default class is IN; other
              classes are HS for Hesiod records or CH for Chaosnet records.

       -f file
              This option sets batch mode, in which dig reads a list of lookup
              requests to process from the given file. Each line in  the  file
              should  be  organized in the same way it would be presented as a
              query to dig using the command-line interface.

       -h     Print a usage summary.

       -k keyfile
              This option tells dig to sign queries using TSIG or SIG(0) using
              a key read from the given file. Key files can be generated using
              tsig-keygen. When using TSIG authentication with dig,  the  name
              server  that is queried needs to know the key and algorithm that
              is being used. In BIND, this is done  by  providing  appropriate
              key  and server statements in named.conf for TSIG and by looking
              up the KEY record in zone data for SIG(0).

       -m     This option enables memory usage debugging.

       -p port
              This option sends the  query  to  a  non-standard  port  on  the
              server,  instead  of the default port 53. This option is used to
              test a name server  that  has  been  configured  to  listen  for
              queries on a non-standard port number.

       -q name
              This  option  specifies the domain name to query. This is useful
              to distinguish the name from other arguments.

       -r     This option indicates that options  from  ${HOME}/.digrc  should
              not  be  read.  This is useful for scripts that need predictable
              behavior.

       -t type
              This option indicates the resource record type to  query,  which
              can  be  any  valid  query type. If it is a resource record type
              supported in BIND 9, it can be given by the type mnemonic  (such
              as  NS  or AAAA). The default query type is A, unless the -x op-
              tion is supplied to indicate a reverse lookup. A  zone  transfer
              can be requested by specifying a type of AXFR. When an incremen-
              tal zone transfer (IXFR) is required, set the  type  to  ixfr=N.
              The  incremental  zone transfer contains all changes made to the
              zone since the serial number in the zone's SOA record was N.

              All resource record types can be expressed as TYPEnn,  where  nn
              is  the  number  of the type. If the resource record type is not
              supported in BIND 9, the result is displayed as described in RFC
              3597.

       -u     This  option indicates that print query times should be provided
              in microseconds instead of milliseconds.

       -v     This option prints the version number and exits.

       -x addr
              This option sets simplified reverse  lookups,  for  mapping  ad-
              dresses  to names. The addr is an IPv4 address in dotted-decimal
              notation, or a colon-delimited IPv6 address. When the -x  option
              is  used,  there is no need to provide the name, class, and type
              arguments.  dig automatically performs a lookup for a name  like
              94.2.0.192.in-addr.arpa and sets the query type and class to PTR
              and IN respectively. IPv6 addresses are looked up  using  nibble
              format under the IP6.ARPA domain.

       -y [hmac:]keyname:secret
              This  option signs queries using TSIG with the given authentica-
              tion key.  keyname is the name of the key,  and  secret  is  the
              base64-encoded  shared secret. hmac is the name of the key algo-
              rithm;  valid  choices  are  hmac-md5,  hmac-sha1,  hmac-sha224,
              hmac-sha256,  hmac-sha384, or hmac-sha512. If hmac is not speci-
              fied, the default is hmac-md5; if MD5 was disabled, the  default
              is hmac-sha256.

       NOTE:
          Only  the  -k  option should be used, rather than the -y option, be-
          cause with -y the shared secret is supplied as a command-line  argu-
          ment in clear text. This may be visible in the output from ps1 or in
          a history file maintained by the user's shell.

EXECUTION EXAMPLE:
COMMAND INPUT:
dig google.com

COMMAND OUTPUT:
; <<>> DiG 9.18.33-1~deb12u2-Debian <<>> google.com
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 51610
;; flags: qr rd ra; QUERY: 1, ANSWER: 6, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 65494
;; QUESTION SECTION:
;google.com.			IN	A

;; ANSWER SECTION:
google.com.		57	IN	A	209.85.145.138
google.com.		57	IN	A	209.85.145.102
google.com.		57	IN	A	209.85.145.100
google.com.		57	IN	A	209.85.145.101
google.com.		57	IN	A	209.85.145.139
google.com.		57	IN	A	209.85.145.113

;; Query time: 0 msec
;; SERVER: 127.0.0.53#53(127.0.0.53) (UDP)
;; WHEN: Mon Mar 03 23:02:34 UTC 2025
;; MSG SIZE  rcvd: 135

===

COMMAND: nslookup

DESCRIPTION: nslookup - query Internet name servers interactively

USAGE: nslookup [-option] [name | -] [server]

EXECUTION EXAMPLE:
COMMAND INPUT:
nslookup google.com

COMMAND OUTPUT:
Server:		127.0.0.53
Address:	127.0.0.53#53

Non-authoritative answer:
Name:	google.com
Address: 209.85.145.102
Name:	google.com
Address: 209.85.145.138
Name:	google.com
Address: 209.85.145.113
Name:	google.com
Address: 209.85.145.101
Name:	google.com
Address: 209.85.145.139
Name:	google.com
Address: 209.85.145.100
Name:	google.com
Address: 2607:f8b0:4001:c1d::64
Name:	google.com
Address: 2607:f8b0:4001:c1d::65
Name:	google.com
Address: 2607:f8b0:4001:c1d::71
Name:	google.com
Address: 2607:f8b0:4001:c1d::66

===

COMMAND: host

DESCRIPTION: host - DNS lookup utility

USAGE: host  [-aACdlnrsTUwv]  [-c  class] [-N ndots] [-p port] [-R number] [-t
       type] [-W wait] [-m flag] [ [-4] | [-6] ] [-v] [-V] {name} [server]

OPTIONS:
-4     This option specifies that only IPv4 should be  used  for  query
              transport. See also the -6 option.

       -6     This  option  specifies  that only IPv6 should be used for query
              transport. See also the -4 option.

       -a     The -a ("all") option is normally equivalent to -v  -t  ANY.  It
              also affects the behavior of the -l list zone option.

       -A     The  -A  ("almost  all") option is equivalent to -a, except that
              RRSIG, NSEC, and NSEC3 records are omitted from the output.

       -c class
              This option specifies the query class,  which  can  be  used  to
              lookup  HS (Hesiod) or CH (Chaosnet) class resource records. The
              default class is IN (Internet).

       -C     This option indicates that named should check consistency, mean-
              ing that host queries the SOA records for zone name from all the
              listed authoritative name servers for that  zone.  The  list  of
              name servers is defined by the NS records that are found for the
              zone.

       -d     This option prints debugging traces, and is equivalent to the -v
              verbose option.

       -l     This  option tells named to list the zone, meaning the host com-
              mand performs a zone transfer of zone name and  prints  out  the
              NS, PTR, and address records (A/AAAA).

              Together, the -l -a options print all records in the zone.

       -N ndots
              This option specifies the number of dots (ndots) that have to be
              in name for it to be considered absolute. The default  value  is
              that defined using the ndots statement in /etc/resolv.conf, or 1
              if no ndots statement is present. Names with fewer dots are  in-
              terpreted as relative names, and are searched for in the domains
              listed in the search or domain directive in /etc/resolv.conf.

       -p port
              This option specifies the port to query on the server.  The  de-
              fault is 53.

       -r     This option specifies a non-recursive query; setting this option
              clears the RD (recursion desired) bit in the query.  This  means
              that the name server receiving the query does not attempt to re-
              solve name. The -r option enables host to mimic the behavior  of
              a  name server by making non-recursive queries, and expecting to
              receive answers to those queries that can be referrals to  other
              name servers.

       -R number
              This  option specifies the number of retries for UDP queries. If
              number is negative or zero, the number of  retries  is  silently
              set  to  1. The default value is 1, or the value of the attempts
              option in /etc/resolv.conf, if set.

       -s     This option tells named not to send the query to the next  name-
              server if any server responds with a SERVFAIL response, which is
              the reverse of normal stub resolver behavior.

       -t type
              This option specifies the query type. The type argument  can  be
              any  recognized  query  type: CNAME, NS, SOA, TXT, DNSKEY, AXFR,
              etc.

              When no query type is specified, host automatically  selects  an
              appropriate query type. By default, it looks for A, AAAA, and MX
              records. If the -C option is given, queries  are  made  for  SOA
              records.  If  name is a dotted-decimal IPv4 address or colon-de-
              limited IPv6 address, host queries for PTR records.

              If a query type of IXFR is chosen, the  starting  serial  number
              can  be  specified  by appending an equals sign (=), followed by
              the starting serial number, e.g., -t IXFR=12345678.

       -T, -U This option specifies TCP or UDP. By default, host uses UDP when
              making queries; the -T option makes it use a TCP connection when
              querying the name server.  TCP  is  automatically  selected  for
              queries  that require it, such as zone transfer (AXFR) requests.
              Type ANY queries default to TCP, but can be forced  to  use  UDP
              initially via -U.

       -m flag
              This option sets memory usage debugging: the flag can be record,
              usage, or trace. The -m option can be specified more  than  once
              to set multiple flags.

       -v     This option sets verbose output, and is equivalent to the -d de-
              bug option. Verbose output can also be enabled  by  setting  the
              debug option in /etc/resolv.conf.

       -V     This option prints the version number and exits.

       -w     This option sets "wait forever": the query timeout is set to the
              maximum possible. See also the -W option.

       -W wait
              This options sets the length of  the  wait  timeout,  indicating
              that  named  should  wait for up to wait seconds for a reply. If
              wait is less than 1, the wait interval is set to 1 second.

              By default, host waits for 5 seconds for UDP  responses  and  10
              seconds for TCP connections. These defaults can be overridden by
              the timeout option in /etc/resolv.conf.

              See also the -w option.

EXECUTION EXAMPLE:
COMMAND INPUT:
host google.com

COMMAND OUTPUT:
google.com has address 209.85.145.102
google.com has address 209.85.145.113
google.com has address 209.85.145.101
google.com has address 209.85.145.100
google.com has address 209.85.145.139
google.com has address 209.85.145.138
google.com has IPv6 address 2607:f8b0:4001:c1d::65
google.com has IPv6 address 2607:f8b0:4001:c1d::71
google.com has IPv6 address 2607:f8b0:4001:c1d::66
google.com has IPv6 address 2607:f8b0:4001:c1d::64
google.com mail is handled by 10 smtp.google.com.

===

COMMAND: traceroute

DESCRIPTION: traceroute - print the route packets trace to network host

USAGE: traceroute [-46dFITUnreAV] [-f first_ttl] [-g gate,...]
               [-i device] [-m max_ttl] [-p port] [-s src_addr]
               [-q nqueries] [-N squeries] [-t tos]
               [-l flow_label] [-w waittimes] [-z sendwait] [-UL] [-D]
               [-P proto] [--sport=port] [-M method] [-O mod_options]
               [--mtu] [--back]
               host [packet_len]
       traceroute6  [options]
       tcptraceroute  [options]
       lft  [options]

OPTIONS:
--help Print help info and exit.

       -4, -6 Explicitly force IPv4 or IPv6 tracerouting. By default, the pro-
              gram  will  try to resolve the name given, and choose the appro-
              priate protocol automatically. If resolving a host name  returns
              both IPv4 and IPv6 addresses, traceroute will use IPv4.

       -I, --icmp
              Use ICMP ECHO for probes

       -T, --tcp
              Use TCP SYN for probes

       -d, --debug
              Enable  socket  level  debugging (when the Linux kernel supports
              it)

       -F, --dont-fragment
              Do not fragment probe packets. (For IPv4 it also  sets  DF  bit,
              which  tells  intermediate  routers  not to fragment remotely as
              well).

              Varying the size of the probing packet by the packet_len command
              line  parameter,  you  can manually obtain information about the
              MTU of individual network hops. The  --mtu  option  (see  below)
              tries to do this automatically.

              Note, that non-fragmented features (like -F or --mtu) work prop-
              erly since the Linux kernel 2.6.22 only.  Before  that  version,
              IPv6  was always fragmented, IPv4 could use the once the discov-
              ered final mtu only (from the route cache), which  can  be  less
              than the actual mtu of a device.

       -f first_ttl, --first=first_ttl
              Specifies with what TTL to start. Defaults to 1.

       -g gateway, --gateway=gateway
              Tells  traceroute to add an IP source routing option to the out-
              going packet that tells the network to route the packet  through
              the specified gateway (most routers have disabled source routing
              for security reasons).  In general, several gateway's is allowed
              (comma  separated).  For  IPv6, the form of num,addr,addr...  is
              allowed, where num is a route header type (default is  type  2).
              Note the type 0 route header is now deprecated (rfc5095).

       -i interface, --interface=interface
              Specifies  the  interface  through  which traceroute should send
              packets. By default, the interface is selected according to  the
              routing table.

       -m max_ttl, --max-hops=max_ttl
              Specifies  the  maximum  number of hops (max time-to-live value)
              traceroute will probe. The default is 30.

       -N squeries, --sim-queries=squeries
              Specifies the number of probe packets sent  out  simultaneously.
              Sending several probes concurrently can speed up traceroute con-
              siderably. The default value is 16.
              Note that some routers and hosts can use ICMP  rate  throttling.
              In such a situation specifying too large number can lead to loss
              of some responses.

       -n     Do not try to map IP addresses to  host  names  when  displaying
              them.

       -p port, --port=port
              For  UDP tracing, specifies the destination port base traceroute
              will use (the destination port number  will  be  incremented  by
              each probe).
              For ICMP tracing, specifies the initial ICMP sequence value (in-
              cremented by each probe too).
              For TCP and others specifies  just  the  (constant)  destination
              port to connect. When using the tcptraceroute wrapper, -p speci-
              fies the source port.

       -t tos, --tos=tos
              For IPv4, set the Type of Service (TOS)  and  Precedence  value.
              Useful  values  are 16 (low delay) and 8 (high throughput). Note
              that in order to use some TOS precedence values, you have to  be
              super user.
              For IPv6, set the Traffic Control value.

       -l flow_label, --flowlabel=flow_label
              Use specified flow_label for IPv6 packets.

       -w max[,here,near], --wait=max[,here,near]
              Determines how long to wait for a response to a probe.

              There  are  three (in general) float values separated by a comma
              (or a slash).  Max specifies the maximum time (in  seconds,  de-
              fault 5.0) to wait, in any case.

              Traditional  traceroute  implementation  always waited whole max
              seconds for any probe. But if we already have some replies  from
              the  same  hop, or even from some next hop, we can use the round
              trip time of such a reply as a hint to determine the actual rea-
              sonable amount of time to wait.

              The  optional  here (default 3.0) specifies a factor to multiply
              the round trip time of an already  received  response  from  the
              same  hop.  The  resulting  value  is  used as a timeout for the
              probe, instead of (but no more than)  max.   The  optional  near
              (default  10.0)  specifies  a similar factor for a response from
              some next hop.  (The time of the first found result is  used  in
              both cases).

              First,  we  look  for  the  same hop (of the probe which will be
              printed first from now).  If nothing found, then look  for  some
              next  hop.  If nothing found, use max.  If here and/or near have
              zero values, the corresponding computation is skipped.
              Here and near are always set to zero if only  max  is  specified
              (for compatibility with previous versions).

       -q nqueries, --queries=nqueries
              Sets the number of probe packets per hop. The default is 3.

       -r     Bypass  the normal routing tables and send directly to a host on
              an attached network.  If the host is not on a  directly-attached
              network,  an error is returned.  This option can be used to ping
              a local host through an interface that has no route through it.

       -s source_addr, --source=source_addr
              Chooses an alternative source address. Note that you must select
              the  address  of one of the interfaces.  By default, the address
              of the outgoing interface is used.

       -z sendwait, --sendwait=sendwait
              Minimal time interval between probes (default 0).  If the  value
              is  more  than  10,  then it specifies a number in milliseconds,
              else it is a number of seconds (float point values allowed too).
              Useful when some routers use rate-limit for ICMP messages.

       -e, --extensions
              Show  ICMP extensions (rfc4884). The general form is CLASS/TYPE:
              followed by a hexadecimal dump.  The  MPLS  (rfc4950)  is  shown
              parsed,  in  a form: MPLS:L=label,E=exp_use,S=stack_bottom,T=TTL
              (more objects separated by / ).

       -A, --as-path-lookups
              Perform AS path lookups in routing registries and print  results
              directly after the corresponding addresses.

       -V, --version
              Print the version and exit.

       There  are  additional options intended for advanced usage (such as al-
       ternate trace methods etc.):

       --sport=port
              Chooses the source port to use. Implies  -N 1 -w 5  .   Normally
              source ports (if applicable) are chosen by the system.

       --fwmark=mark
              Set the firewall mark for outgoing packets (since the Linux ker-
              nel 2.6.25).

       -M method, --module=name
              Use specified method for traceroute operations.  Default  tradi-
              tional  udp method has name default, icmp (-I) and tcp (-T) have
              names icmp and tcp respectively.
              Method-specific options can be passed by -O .  Most methods have
              their simple shortcuts, (-I means -M icmp, etc).

       -O option, --options=options
              Specifies some method-specific option. Several options are sepa-
              rated by comma (or use several -O on cmdline).  Each method  may
              have its own specific options, or many not have them at all.  To
              print information about available options, use -O help.

       -U, --udp
              Use UDP to particular destination port for tracerouting (instead
              of  increasing  the  port  per  each  probe). Default port is 53
              (dns).

       -UL    Use UDPLITE for tracerouting (default port is 53).

       -D, --dccp
              Use DCCP Requests for probes.

       -P protocol, --protocol=protocol
              Use raw packet of specified protocol for  tracerouting.  Default
              protocol is 253 (rfc3692).

       --mtu  Discover  MTU along the path being traced. Implies -F -N 1.  New
              mtu is printed once in a form of F=NUM at the first probe  of  a
              hop which requires such mtu to be reached. (Actually, the corre-
              spond "frag needed" icmp message normally is sent by the  previ-
              ous hop).

              Note, that some routers might cache once the seen information on
              a fragmentation. Thus you can  receive  the  final  mtu  from  a
              closer hop.  Try to specify an unusual tos by -t , this can help
              for one attempt (then it can be cached there as well).
              See -F option for more info.

       --back Print the number of backward hops when it seems  different  with
              the forward direction. This number is guessed in assumption that
              remote hops send reply packets with initial ttl  set  to  either
              64, or 128 or 255 (which seems a common practice). It is printed
              as a negate value in a form of '-NUM' .

EXECUTION EXAMPLE:
COMMAND INPUT:
traceroute -m 5 google.com

COMMAND OUTPUT:
traceroute to google.com (209.85.145.138), 5 hops max, 60 byte packets
 1  * * *
 2  216.239.63.166 (216.239.63.166)  8.155 ms 72.14.239.198 (72.14.239.198)  2.838 ms 216.239.54.198 (216.239.54.198)  2.694 ms
 3  142.251.236.135 (142.251.236.135)  2.849 ms 216.239.41.124 (216.239.41.124)  2.938 ms 216.239.42.64 (216.239.42.64)  3.647 ms
 4  216.239.58.88 (216.239.58.88)  3.511 ms 209.85.253.209 (209.85.253.209)  2.592 ms 216.239.41.99 (216.239.41.99)  2.757 ms
 5  142.251.60.149 (142.251.60.149)  2.350 ms 142.251.60.151 (142.251.60.151)  2.341 ms 142.251.61.57 (142.251.61.57)  2.268 ms

===

COMMAND: ip

DESCRIPTION: ip - show / manipulate routing, network devices, interfaces and tunnels

USAGE: ip [ OPTIONS ] OBJECT { COMMAND | help }

       ip [ -force ] -batch filename

       OBJECT := { link | address | addrlabel | route | rule | neigh | ntable
               | tunnel | tuntap | maddress | mroute | mrule | monitor | xfrm
               | netns | l2tp | tcp_metrics | token | macsec | vrf | mptcp |
               ioam | stats }

       OPTIONS := { -V[ersion] | -h[uman-readable] | -s[tatistics] |
               -d[etails] | -r[esolve] | -iec | -f[amily] { inet | inet6 |
               link } | -4 | -6 | -B | -0 | -l[oops] { maximum-addr-flush-at-
               tempts } | -o[neline] | -rc[vbuf] [size] | -t[imestamp] |
               -ts[hort] | -n[etns] name | -N[umeric] | -a[ll] | -c[olor] |
               -br[ief] | -j[son] | -p[retty] }

OPTIONS:
-V, -Version
              Print the version of the ip utility and exit.

       -h, -human, -human-readable
              output statistics with human readable values followed by suffix.

       -b, -batch <FILENAME>
              Read commands from provided file or standard input and invoke
              them.  First failure will cause termination of ip.

       -force Don't terminate ip on errors in batch mode.  If there were any
              errors during execution of the commands, the application return
              code will be non zero.

       -s, -stats, -statistics
              Output more information. If the option appears twice or more,
              the amount of information increases.  As a rule, the information
              is statistics or some time values.

       -d, -details
              Output more detailed information.

       -l, -loops <COUNT>
              Specify maximum number of loops the 'ip address flush' logic
              will attempt before giving up. The default is 10.  Zero (0)
              means loop until all addresses are removed.

       -f, -family <FAMILY>
              Specifies the protocol family to use. The protocol family iden-
              tifier can be one of inet, inet6, bridge, mpls or link.  If this
              option is not present, the protocol family is guessed from other
              arguments. If the rest of the command line does not give enough
              information to guess the family, ip falls back to the default
              one, usually inet or any.  link is a special family identifier
              meaning that no networking protocol is involved.

       -4     shortcut for -family inet.

       -6     shortcut for -family inet6.

       -B     shortcut for -family bridge.

       -M     shortcut for -family mpls.

       -0     shortcut for -family link.

       -o, -oneline
              output each record on a single line, replacing line feeds with
              the '\' character. This is convenient when you want to count
              records with wc(1) or to grep(1) the output.

       -r, -resolve
              use the system's name resolver to print DNS names instead of
              host addresses.

       -n, -netns <NETNS>
              switches ip to the specified network namespace NETNS.  Actually
              it just simplifies executing of:

              ip netns exec NETNS ip [ OPTIONS ] OBJECT { COMMAND | help }

              to

              ip -n[etns] NETNS [ OPTIONS ] OBJECT { COMMAND | help }

       -N, -Numeric
              Print the number of protocol, scope, dsfield, etc directly in-
              stead of converting it to human readable name.

       -a, -all
              executes specified command over all objects, it depends if com-
              mand supports this option.

       -c[color][={always|auto|never}
              Configure color output. If parameter is omitted or always, color
              output is enabled regardless of stdout state. If parameter is
              auto, stdout is checked to be a terminal before enabling color
              output. If parameter is never, color output is disabled. If
              specified multiple times, the last one takes precedence. This
              flag is ignored if -json is also given.

              Used color palette can be influenced by COLORFGBG environment
              variable (see ENVIRONMENT).

       -t, -timestamp
              display current time when using monitor option.

       -ts, -tshort
              Like -timestamp, but use shorter format.

       -rc, -rcvbuf<SIZE>
              Set the netlink socket receive buffer size, defaults to 1MB.

       -iec   print human readable rates in IEC units (e.g. 1Ki = 1024).

       -br, -brief
              Print only basic information in a tabular format for better
              readability. This option is currently only supported by ip addr
              show , ip link show & ip neigh show commands.

       -j, -json
              Output results in JavaScript Object Notation (JSON).

       -p, -pretty
              The default JSON format is compact and more efficient to parse
              but hard for most users to read.  This flag adds indentation for
              readability.

       -echo  Request the kernel to send the applied configuration back.

EXECUTION EXAMPLE:
COMMAND INPUT:
ip route

COMMAND OUTPUT:
default via 10.128.0.1 dev ens4 proto dhcp src 10.128.0.2 metric 100 
10.128.0.1 dev ens4 proto dhcp scope link src 10.128.0.2 metric 100 
169.254.169.254 via 10.128.0.1 dev ens4 proto dhcp src 10.128.0.2 metric 100 
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown

===

COMMAND: lsof

DESCRIPTION: lsof - list open files

USAGE: lsof  [  -?abChlnNOPQRtUvVX  ]  [ -A A ] [ -c c ] [ +c c ] [ +|-d d ] [
       +|-D D ] [ +|-e s ] [ +|-E ] [ +|-f [cfgGn] ] [ -F [f] ] [ -g [s]  ]  [
       -i  [i] ] [ -k k ] [ -K k ] [ +|-L [l] ] [ +|-m m ] [ +|-M ] [ -o [o] ]
       [ -p s ] [ +|-r [t[m<fmt>]] ] [ -s [p:s] ] [ -S [t] ] [ -T [t] ] [ -u s
       ] [ +|-w ] [ -x [fl] ] [ -z [z] ] [ -Z [Z] ] [ -- ] [names]

OPTIONS:
In the absence of any options, lsof lists all open files  belonging  to
       all active processes.

       If  any  list  request option is specified, other list requests must be
       specifically requested - e.g., if -U is specified for  the  listing  of
       UNIX  socket  files, NFS files won't be listed unless -N is also speci-
       fied; or if a user list is specified with the -u  option,  UNIX  domain
       socket  files,  belonging to users not in the list, won't be listed un-
       less the -U option is also specified.

       Normally, list options that are specifically stated are  ORed  -  i.e.,
       specifying  the  -i option without an address and the -ufoo option pro-
       duces a listing of all network files OR files  belonging  to  processes
       owned by user ``foo''.  The exceptions are:

       1) the `^' (negated) login name or user ID (UID), specified with the -u
          option;

       2) the `^' (negated) process ID (PID), specified with the -p option;

       3) the `^' (negated) process group ID (PGID), specified with the -g op-
          tion;

       4) the `^' (negated) command, specified with the -c option;

       5) the  (`^')  negated  TCP or UDP protocol state names, specified with
          the -s [p:s] option.

       Since they represent exclusions, they are applied without ORing or AND-
       ing and take effect before any other selection criteria are applied.

       The -a option may be used to AND the selections.  For example, specify-
       ing -a, -U, and -ufoo produces a listing of only UNIX socket files that
       belong to processes owned by user ``foo''.

       Caution:  the  -a option causes all list selection options to be ANDed;
       it can't be used to cause ANDing of selected pairs of selection options
       by  placing it between them, even though its placement there is accept-
       able.  Wherever -a is placed, it causes the ANDing of all selection op-
       tions.

       Items of the same selection set - command names, file descriptors, net-
       work addresses, process identifiers, user identifiers, zone names,  se-
       curity  contexts  -  are joined in a single ORed set and applied before
       the result participates  in  ANDing.   Thus,  for  example,  specifying
       -i@aaa.bbb,  -i@ccc.ddd,  -a,  and -ufff,ggg will select the listing of
       files that belong to either login ``fff'' OR ``ggg'' AND  have  network
       connections to either host aaa.bbb OR ccc.ddd.

       Options  may be grouped together following a single prefix -- e.g., the
       option set ``-a -b -C'' may be stated as -abC.  However,  since  values
       are optional following +|-f, -F, -g, -i, +|-L, -o, +|-r, -s, -S, -T, -x
       and -z.  when you have no values for them be careful that the following
       character isn't ambiguous.  For example, -Fn might represent the -F and
       -n options, or it might represent the n field identifier character fol-
       lowing  the  -F option.  When ambiguity is possible, start a new option
       with a `-' character - e.g., ``-F -n''.  If the next option is  a  file
       name,  follow the possibly ambiguous option with ``--'' - e.g., ``-F --
       name''.

       Either the `+' or the `-' prefix may be applied to a group of  options.
       Options that don't take on separate meanings for each prefix - e.g., -i
       - may be grouped under either prefix.  Thus, for example, ``+M -i'' may
       be  stated  as ``+Mi'' and the group means the same as the separate op-
       tions.  Be careful of prefix grouping when one or more options  in  the
       group  does  take on separate meanings under different prefixes - e.g.,
       +|-M; ``-iM'' is not the same request as ``-i +M''.  When in doubt, use
       separate options with appropriate prefixes.

       -? -h    These  two  equivalent  options  select  a usage (help) output
                list.  Lsof displays a shortened form of this output  when  it
                detects  an  error in the options supplied to it, after it has
                displayed messages explaining each  error.   (Escape  the  `?'
                character as your shell requires.)

       -a       causes list selection options to be ANDed, as described above.

       -A A     is  available  on  systems configured for AFS whose AFS kernel
                code is implemented via dynamic modules.  It allows  the  lsof
                user  to  specify  A  as an alternate name list file where the
                kernel addresses of the dynamic modules might be  found.   See
                the  lsof  FAQ (The FAQ section gives its location.)  for more
                information about dynamic modules, their symbols, and how they
                affect lsof.

       -b       causes  lsof  to  avoid  kernel  functions  that might block -
                lstat(2), readlink(2), and stat(2).

                See the BLOCKS AND TIMEOUTS and AVOIDING  KERNEL  BLOCKS  sec-
                tions for information on using this option.

       -c c     selects  the listing of files for processes executing the com-
                mand that begins with the characters of c.  Multiple  commands
                may  be specified, using multiple -c options.  They are joined
                in a single ORed set before participating in AND option selec-
                tion.

                If  c begins with a `^', then the following characters specify
                a command name whose processes are to be ignored (excluded.)

                If c begins and ends with a slash ('/'),  the  characters  be-
                tween  the  slashes  are  interpreted as a regular expression.
                Shell meta-characters in the regular expression must be quoted
                to  prevent  their  interpretation  by the shell.  The closing
                slash may be followed by these modifiers:

                     b    the regular expression is a basic one.
                     i    ignore the case of letters.
                     x    the regular expression is an extended one
                          (default).

                See the lsof FAQ (The FAQ section gives  its  location.)   for
                more information on basic and extended regular expressions.

                The  simple  command  specification  is tested first.  If that
                test fails, the command regular expression is applied.  If the
                simple  command  test succeeds, the command regular expression
                test isn't made.  This may result in ``no  command  found  for
                regex:'' messages when lsof's -V option is specified.

       +c w     defines  the maximum number of initial characters of the name,
                supplied by the UNIX dialect, of the UNIX  command  associated
                with a process to be printed in the COMMAND column.  (The lsof
                default is nine.)

                Note that many UNIX dialects do not supply  all  command  name
                characters to lsof in the files and structures from which lsof
                obtains command name.  Often  dialects  limit  the  number  of
                characters  supplied  in  those  sources.   For example, Linux
                2.4.27 and Solaris 9 both limit  command  name  length  to  16
                characters.

                If w is zero ('0'), all command characters supplied to lsof by
                the UNIX dialect will be printed.

                If w is less than the length of the column title, ``COMMAND'',
                it will be raised to that length.

       -C       disables  the  reporting  of any path name components from the
                kernel's name cache.  See the KERNEL NAME  CACHE  section  for
                more information.

       +d s     causes  lsof  to  search for all open instances of directory s
                and the files and directories it contains at  its  top  level.
                +d does NOT descend the directory tree, rooted at s.  The +D D
                option may be used to request a  full-descent  directory  tree
                search, rooted at directory D.

                Processing  of  the  +d  option does not follow symbolic links
                within s unless the -x or -x  l option is also specified.  Nor
                does  it  search for open files on file system mount points on
                subdirectories of s unless the -x or  -x   f  option  is  also
                specified.

                Note:  the  authority  of the user of this option limits it to
                searching for files that the user has  permission  to  examine
                with the system stat(2) function.

       -d s     specifies  a list of file descriptors (FDs) to exclude from or
                include in the output listing.  The file descriptors are spec-
                ified  in  the  comma-separated  set  s  -  e.g., ``cwd,1,3'',
                ``^6,^2''.  (There should be no spaces in the set.)

                The list is an exclusion list if all entries of the set  begin
                with  `^'.   It  is  an inclusion list if no entry begins with
                `^'.  Mixed lists are not permitted.

                A file descriptor number range may be in the set  as  long  as
                neither  member  is  empty,  both members are numbers, and the
                ending member is larger than the starting one - e.g.,  ``0-7''
                or  ``3-10''.   Ranges  may be specified for exclusion if they
                have the `^' prefix - e.g., ``^0-7''  excludes  all  file  de-
                scriptors 0 through 7.

                Multiple  file  descriptor numbers are joined in a single ORed
                set before participating in AND option selection.

                When there are exclusion and inclusion  members  in  the  set,
                lsof  reports  them as errors and exits with a non-zero return
                code.

                See the description of File Descriptor (FD) output  values  in
                the  OUTPUT  section  for  more information on file descriptor
                names.

                fd is a pseudo file descriptor name for specifying  the  whole
                range of possible file descriptor numbers.  fd does not appear
                in FD column of output.

       +D D     causes lsof to search for all open instances  of  directory  D
                and  all the files and directories it contains to its complete
                depth.

                Processing of the +D option does  not  follow  symbolic  links
                within D unless the -x or -x  l option is also specified.  Nor
                does it search for open files on file system mount  points  on
                subdirectories  of  D  unless  the  -x or -x  f option is also
                specified.

                Note: the authority of the user of this option  limits  it  to
                searching  for  files  that the user has permission to examine
                with the system stat(2) function.

                Further note: lsof may process this option slowly and  require
                a large amount of dynamic memory to do it.  This is because it
                must descend the entire directory tree, rooted at  D,  calling
                stat(2)  for  each  file and directory, building a list of all
                the files it finds, and searching that list for a  match  with
                every  open  file.  When directory D is large, these steps can
                take a long time, so use this option prudently.

       -D D     directs lsof's use of the device cache file.  The use of  this
                option  is  sometimes  restricted.   See the DEVICE CACHE FILE
                section and the sections that follow it for  more  information
                on this option.

                -D  must be followed by a function letter; the function letter
                may optionally be followed by a path  name.   Lsof  recognizes
                these function letters:

                     ? - report device cache file paths
                     b - build the device cache file
                     i - ignore the device cache file
                     r - read the device cache file
                     u - read and update the device cache file

                The  b,  r,  and  u functions, accompanied by a path name, are
                sometimes restricted.  When these  functions  are  restricted,
                they  will not appear in the description of the -D option that
                accompanies -h or -?  option output.   See  the  DEVICE  CACHE
                FILE section and the sections that follow it for more informa-
                tion on these functions and when they're restricted.

                The ?  function reports the read-only  and  write  paths  that
                lsof can use for the device cache file, the names of any envi-
                ronment variables whose values lsof will examine when  forming
                the  device  cache  file path, and the format for the personal
                device cache file path.  (Escape the  `?'  character  as  your
                shell requires.)

                When  available,  the b, r, and u functions may be followed by
                the  device  cache  file's  path.   The  standard  default  is
                .lsof_hostname  in the home directory of the real user ID that
                executes lsof, but this could have been changed when lsof  was
                configured  and  compiled.   (The output of the -h and -?  op-
                tions show the current default prefix - e.g., ``.lsof''.)  The
                suffix,  hostname,  is  the first component of the host's name
                returned by gethostname(2).

                When available, the b function directs lsof to build a new de-
                vice cache file at the default or specified path.

                The i function directs lsof to ignore the default device cache
                file and obtain its information about devices via direct calls
                to the kernel.

                The  r  function  directs lsof to read the device cache at the
                default or specified path, but prevents it from creating a new
                device  cache file when none exists or the existing one is im-
                properly structured.  The r function, when specified without a
                path  name,  prevents  lsof from updating an incorrect or out-
                dated device cache file, or creating a new one in  its  place.
                The  r function is always available when it is specified with-
                out a path name argument; it may be restricted by the  permis-
                sions of the lsof process.

                When available, the u function directs lsof to read the device
                cache file at the default or specified path, if possible,  and
                to rebuild it, if necessary.  This is the default device cache
                file function when no -D option has been specified.

       +|-e s   exempts the file system whose path name is s from  being  sub-
                jected  to kernel function calls that might block.  The +e op-
                tion exempts stat(2), lstat(2)  and  most  readlink(2)  kernel
                function  calls.   The  -e  option  exempts  only  stat(2) and
                lstat(2) kernel function calls.  Multiple file systems may  be
                specified  with separate +|-e specifications and each may have
                readlink(2) calls exempted or not.

                This option is currently implemented only for Linux.

                CAUTION: this option can easily be mis-applied to  other  than
                the  file system of interest, because it uses path name rather
                than the more reliable device and inode numbers.  (Device  and
                inode  numbers  are  acquired  via  the  potentially  blocking
                stat(2) kernel call and are thus not available,  but  see  the
                +|-m  m  option as a possible alternative way to supply device
                numbers.)  Use this option with great care and  fully  specify
                the path name of the file system to be exempted.

                When  open files on exempted file systems are reported, it may
                not be possible to obtain all their  information.   Therefore,
                some   information  columns  will  be  blank,  the  characters
                ``UNKN'' preface the values in the TYPE column, and the appli-
                cable  exemption  option is added in parentheses to the end of
                the NAME column.  (Some device  number  information  might  be
                made available via the +|-m m option.)

       +|-E     +E specifies that Linux pipe, Linux UNIX socket, Linux INET(6)
                socket closed in a local  host,  Linux  pseudoterminal  files,
                POSIX  Message  Queueue  implementation  in  Linux,  and Linux
                eventfd should be displayed with endpoint information and  the
                files of the endpoints should also be displayed.

                Note  1:  UNIX socket file endpoint information is only avail-
                able when the compile flags line of -v output contains  HASUX-
                SOCKEPT, and psudoterminal endpoint information is only avail-
                able when the compile flags line contains HASPTYEPT.

                Note 2: POSIX Message Queue file endpoint information is  only
                available when mqueue file system is mounted.

                Pipe  endpoint  information is displayed in the NAME column in
                the form ``PID,cmd,FDmode'', where PID is the endpoint process
                ID;  cmd  is  the endpoint process command; FD is the endpoint
                file's descriptor; and mode  is  the  endpoint  file's  access
                mode.

                Pseudoterminal  endpoint  information is displayed in the NAME
                column as  ``->/dev/ptsmin PID,cmd,FDmode''  or  ``PID,cmd,FD-
                mode''.   The  first  form is for a master device; the second,
                for a slave device.  min is a slave device's minor device num-
                ber;  and PID, cmd, FD and mode are the same as with pipe end-
                point information.  Note: psudoterminal  endpoint  information
                is  only  available  when  the compile flags line of -V output
                contains HASPTYEPT. In addition, this feature works  on  Linux
                kernels above 4.13.0.

                UNIX socket file endpoint information is displayed in the NAME
                column in the form
                ``type=TYPE ->INO=INODE PID,cmd,FDmode'', where  TYPE  is  the
                socket  type;  INODE  is  the  i-node  number of the connected
                socket; and PID, cmd, FD and mode are the same  as  with  pipe
                endpoint  information.  Note: UNIX socket file endpoint infor-
                mation is available only when the compile  flags  line  of  -v
                output contains HASUXSOCKEPT.

                INET socket file endpoint information is inserted to the value
                at the NAME column in th form
                PID, cmd, FD and mode are the same as with pipe  endpoint  in-
                formation.  The  endpoint information is available only if the
                socket is used for local IPC; both endpoints bind to the  same
                local IPv4 or IPv6 address.

                POSIX  Message Queue file endpoint information is displayed in
                the NAME column in the same form as that of pipe.

                eventfd endpoint information is displayed in the  NAME  column
                in  the same form as that of pipe. This feature works on Linux
                kernels above 5.2.0.

                Multiple occurrences of  this  information  can  appear  in  a
                file's NAME column.

                -E specifies that endpoint supported files should be displayed
                with endpoint information, but not the files of the endpoints.

       +|-f [cfgGn]
                f by itself clarifies how path name arguments are to be inter-
                preted.   When followed by c, f, g, G, or n in any combination
                it specifies that the listing of kernel file structure  infor-
                mation is to be enabled (`+') or inhibited (`-').

                Normally  a  path  name  argument is taken to be a file system
                name if it matches a mounted-on  directory  name  reported  by
                mount(8),  or  if  it  represents a block device, named in the
                mount output and associated with  a  mounted  directory  name.
                When +f is specified, all path name arguments will be taken to
                be file system names, and lsof will complain if any  are  not.
                This  can  be  useful,  for example, when the file system name
                (mounted-on device) isn't a block device.   This  happens  for
                some CD-ROM file systems.

                When  -f  is specified by itself, all path name arguments will
                be taken to be simple files.  Thus, for example,  the  ``-f --
                /''  arguments direct lsof to search for open files with a `/'
                path name, not all open files in the `/' (root) file system.

                Be careful to make sure +f and -f are properly terminated  and
                aren't followed by a character (e.g., of the file or file sys-
                tem name) that might be taken as a  parameter.   For  example,
                use ``--'' after +f and -f as in these examples.

                     $ lsof +f -- /file/system/name
                     $ lsof -f -- /file/name

                The  listing  of  information from kernel file structures, re-
                quested with the +f [cfgGn] option form,  is  normally  inhib-
                ited,  and is not available in whole or part for some dialects
                - e.g., /proc-based Linux kernels below 2.6.22.  When the pre-
                fix  to  f is a plus sign (`+'), these characters request file
                structure information:

                     c    file structure use count (not Linux)
                     f    file structure address (not Linux)
                     g    file flag abbreviations (Linux 2.6.22 and up)

                          Abbrev.   Flag in C code (see open(2))

                          W         O_WRONLY
                          RW        O_RDWR
                          CR        O_CREAT
                          EXCL      O_EXCL
                          NTTY      O_NOCTTY
                          TR        O_TRUNC
                          AP        O_APPEND
                          ND        O_NDELAY
                          SYN       O_SYNC
                          ASYN      O_ASYNC
                          DIR       O_DIRECT
                          DTY       O_DIRECTORY
                          NFLK      O_NOFOLLOW
                          NATM      O_NOATIME
                          DSYN      O_DSYNC
                          RSYN      O_RSYNC
                          LG        O_LARGEFILE
                          CX        O_CLOEXEC
                          TMPF      O_TMPFILE

                     G    file flags in hexadecimal (Linux 2.6.22 and up)
                     n    file structure node address (not Linux)

                When the prefix is minus (`-') the same characters disable the
                listing of the indicated values.

                File  structure  addresses,  use  counts,  flags, and node ad-
                dresses may be used to detect more readily identical files in-
                herited  by child processes and identical files in use by dif-
                ferent processes.  Lsof column output can be sorted by  output
                columns  holding  the  values and listed to identify identical
                file use, or lsof field output can be parsed by an AWK or Perl
                post-filter script, or by a C program.

       -F f     specifies  a  character list, f, that selects the fields to be
                output for processing by another program,  and  the  character
                that terminates each output field.  Each field to be output is
                specified with a single character in f.  The field  terminator
                defaults to NL, but may be changed to NUL (000).  See the OUT-
                PUT FOR OTHER PROGRAMS section for a description of the  field
                identification characters and the field output process.

                When the field selection character list is empty, all standard
                fields are selected (except the  raw  device  field,  security
                context  and  zone field for compatibility reasons) and the NL
                field terminator is used.

                When the field selection character list contains only  a  zero
                (`0'),  all  fields  are selected (except the raw device field
                for compatibility reasons) and the NUL terminator character is
                used.

                Other combinations of fields and their associated field termi-
                nator character must be set with explicit entries in f, as de-
                scribed in the OUTPUT FOR OTHER PROGRAMS section.

                When  a field selection character identifies an item lsof does
                not normally list - e.g., PPID, selected with -R -  specifica-
                tion of the field character - e.g., ``-FR'' - also selects the
                listing of the item.

                When the field selection character list  contains  the  single
                character  `?',  lsof  will  display  a help list of the field
                identification characters.  (Escape the `?' character as  your
                shell requires.)

       -g [s]   excludes  or  selects  the  listing of files for the processes
                whose optional process group IDentification (PGID) numbers are
                in  the comma-separated set s - e.g., ``123'' or ``123,^456''.
                (There should be no spaces in the set.)

                PGID numbers that begin with `^' (negation)  represent  exclu-
                sions.

                Multiple  PGID  numbers are joined in a single ORed set before
                participating in AND option selection.  However,  PGID  exclu-
                sions  are applied without ORing or ANDing and take effect be-
                fore other selection criteria are applied.

                The -g option also enables the output display of PGID numbers.
                When specified without a PGID set that's all it does.

       -i [i]   selects  the  listing  of  files any of whose Internet address
                matches the address specified in i.  If no address  is  speci-
                fied, this option selects the listing of all Internet and x.25
                (HP-UX) network files.

                If -i4 or -i6 is specified with  no  following  address,  only
                files  of  the  indicated  IP  version, IPv4 or IPv6, are dis-
                played.  (An IPv6 specification may be used only  if  the  di-
                alects supports IPv6, as indicated by ``[46]'' and ``IPv[46]''
                in lsof's -h or -?   output.)   Sequentially  specifying  -i4,
                followed  by -i6 is the same as specifying -i, and vice-versa.
                Specifying -i4, or -i6 after -i is the same as specifying  -i4
                or -i6 by itself.

                Multiple  addresses  (up  to  a limit of 100) may be specified
                with multiple -i options.  (A  port  number  or  service  name
                range is counted as one address.)  They are joined in a single
                ORed set before participating in AND option selection.

                An Internet address is specified in the form (Items in  square
                brackets are optional.):

                [46][protocol][@hostname|hostaddr][:service|port]

                where:
                     46 specifies the IP version, IPv4 or IPv6
                          that applies to the following address.
                          '6' may be be specified only if the UNIX
                          dialect supports IPv6.  If neither '4' nor
                          '6' is specified, the following address
                          applies to all IP versions.
                     protocol is a protocol name - TCP, UDP
                     hostname is an Internet host name.  Unless a
                          specific IP version is specified, open
                          network files associated with host names
                          of all versions will be selected.
                     hostaddr is a numeric Internet IPv4 address in
                          dot form; or an IPv6 numeric address in
                          colon form, enclosed in brackets, if the
                          UNIX dialect supports IPv6.  When an IP
                          version is selected, only its numeric
                          addresses may be specified.
                     service is an /etc/services name - e.g., smtp -
                          or a list of them.
                     port is a port number, or a list of them.

                IPv6  options  may  be  used only if the UNIX dialect supports
                IPv6.  To see if the dialect supports IPv6, run lsof and spec-
                ify the -h or -?  (help) option.  If the displayed description
                of the -i option contains ``[46]'' and  ``IPv[46]'',  IPv6  is
                supported.

                IPv4  host names and addresses may not be specified if network
                file selection is limited to IPv6 with -i 6.  IPv6 host  names
                and  addresses  may not be specified if network file selection
                is limited to IPv4 with -i  4.   When  an  open  IPv4  network
                file's  address  is mapped in an IPv6 address, the open file's
                type will be IPv6, not IPv4, and its display will be  selected
                by '6', not '4'.

                At  least  one  address  component - 4, 6, protocol, hostname,
                hostaddr, or service - must be supplied.  The  `@'  character,
                leading  the host specification, is always required; as is the
                `:', leading the port specification.  Specify either  hostname
                or  hostaddr.  Specify either service name list or port number
                list.  If a service name list is specified, the  protocol  may
                also  need  to  be  specified if the TCP, UDP and UDPLITE port
                numbers for the service name are different.  Use  any  case  -
                lower or upper - for protocol.

                Service names and port numbers may be combined in a list whose
                entries are separated by commas and whose  numeric  range  en-
                tries  are separated by minus signs.  There may be no embedded
                spaces, and all service names must  belong  to  the  specified
                protocol.   Since  service  names  may  contain embedded minus
                signs, the starting entry of a range can't be a service  name;
                it can be a port number, however.

                Here are some sample addresses:

                     -i6 - IPv6 only
                     TCP:25 - TCP and port 25
                     @1.2.3.4 - Internet IPv4 host address 1.2.3.4
                     @[3ffe:1ebc::1]:1234 - Internet IPv6 host address
                          3ffe:1ebc::1, port 1234
                     UDP:who - UDP who service port
                     TCP@lsof.itap:513 - TCP, port 513 and host name lsof.itap
                     tcp@foo:1-10,smtp,99 - TCP, ports 1 through 10,
                          service name smtp, port 99, host name foo
                     tcp@bar:1-smtp - TCP, ports 1 through smtp, host bar
                     :time - either TCP, UDP or UDPLITE time service port

       -K k     selects  the  listing  of tasks (threads) of processes, on di-
                alects where task (thread) reporting is supported.   (If  help
                output  -  i.e.,  the  output of the -h or -?  options - shows
                this option, then task (thread) reporting is supported by  the
                dialect.)

                If  -K  is  followed  by  a  value, k, it must be ``i''.  That
                causes lsof to ignore  tasks,  particularly  in  the  default,
                list-everything case when no other options are specified.

                When -K and -a are both specified on Linux, and the tasks of a
                main process are selected by other options, the  main  process
                will  also  be  listed as though it were a task, but without a
                task ID.  (See the description of the TID column in the OUTPUT
                section.)

                Where  the  FreeBSD version supports threads, all threads will
                be listed with their IDs.

                In general threads and tasks inherit the files of the  caller,
                but may close some and open others, so lsof always reports all
                the open files of threads and tasks.

       -k k     specifies a kernel name list file, k,  in  place  of  /vmunix,
                /mach,  etc.   -k  is  not  available  under  AIX  on  the IBM
                RISC/System 6000.

       -l       inhibits the conversion of user ID numbers to login names.  It
                is also useful when login name lookup is working improperly or
                slowly.

       +|-L [l] enables (`+') or disables  (`-')  the  listing  of  file  link
                counts, where they are available - e.g., they aren't available
                for sockets, or most FIFOs and pipes.

                When +L is specified without  a  following  number,  all  link
                counts will be listed.  When -L is specified (the default), no
                link counts will be listed.

                When +L is followed by a number,  only  files  having  a  link
                count  less  than  that number will be listed.  (No number may
                follow -L.)  A specification of the form ``+L1''  will  select
                open  files  that  have been unlinked.  A specification of the
                form ``+aL1 <file_system>'' will select unlinked open files on
                the specified file system.

                For  other link count comparisons, use field output (-F) and a
                post-processing script or program.

       +|-m m   specifies an alternate kernel memory file or  activates  mount
                table supplement processing.

                The  option  form  -m  m specifies a kernel memory file, m, in
                place of /dev/kmem or /dev/mem - e.g., a crash dump file.

                The option form +m requests that a mount  supplement  file  be
                written  to  the  standard output file.  All other options are
                silently ignored.

                There will be a line in the mount  supplement  file  for  each
                mounted file system, containing the mounted file system direc-
                tory, followed by a single space, followed by the device  num-
                ber in hexadecimal "0x" format - e.g.,

                     / 0x801

                Lsof  can  use the mount supplement file to get device numbers
                for file systems  when  it  can't  get  them  via  stat(2)  or
                lstat(2).

                The option form +m m identifies m as a mount supplement file.

                Note:  the  +m and +m m options are not available for all sup-
                ported dialects.  Check the output of lsof's -h or -?  options
                to see if the +m and +m m options are available.

       +|-M     Enables (+) or disables (-) the reporting of portmapper regis-
                trations for local TCP, UDP and UDPLITE ports, where port map-
                ping is supported.  (See the last paragraph of this option de-
                scription for information about where portmapper  registration
                reporting is supported.)

                The default reporting mode is set by the lsof builder with the
                HASPMAPENABLED #define in the dialect's machine.h header file;
                lsof  is  distributed  with the HASPMAPENABLED #define deacti-
                vated, so portmapper reporting is disabled by default and must
                be requested with +M.  Specifying lsof's -h or -?  option will
                report the default mode.   Disabling  portmapper  registration
                when  it  is  already disabled or enabling it when already en-
                abled is acceptable.  When portmapper  registration  reporting
                is enabled, lsof displays the portmapper registration (if any)
                for local TCP, UDP or UDPLITE ports in square brackets immedi-
                ately  following  the  port  numbers  or service names - e.g.,
                ``:1234[name]'' or ``:name[100083]''.  The registration infor-
                mation  may  be a name or number, depending on what the regis-
                tering program supplied to the portmapper when  it  registered
                the port.

                When  portmapper  registration  reporting is enabled, lsof may
                run a little more slowly or even become blocked when access to
                the  portmapper becomes congested or stopped.  Reverse the re-
                porting mode to determine if portmapper registration reporting
                is slowing or blocking lsof.

                For purposes of portmapper registration reporting lsof consid-
                ers a TCP, UDP or UDPLITE port local if: it is  found  in  the
                local part of its containing kernel structure; or if it is lo-
                cated in the foreign part of its containing  kernel  structure
                and  the local and foreign Internet addresses are the same; or
                if it is located in the foreign part of its containing  kernel
                structure  and the foreign Internet address is INADDR_LOOPBACK
                (127.0.0.1).  This rule may  make  lsof  ignore  some  foreign
                ports  on  machines  with multiple interfaces when the foreign
                Internet address is on a different interface  from  the  local
                one.

                See  the  lsof  FAQ (The FAQ section gives its location.)  for
                further discussion of portmapper  registration  reporting  is-
                sues.

                Portmapper  registration  reporting  is  supported only on di-
                alects that have RPC header files.  (Some Linux  distributions
                with  GlibC 2.14 do not have them.)  When portmapper registra-
                tion reporting is supported, the -h or -?   help  output  will
                show the +|-M option.

       -n       inhibits  the  conversion of network numbers to host names for
                network  files.   Inhibiting  conversion  may  make  lsof  run
                faster.   It is also useful when host name lookup is not work-
                ing properly.

       -N       selects the listing of NFS files.

       -o       directs lsof to display file offset at all times.   It  causes
                the  SIZE/OFF  output  column  title  to be changed to OFFSET.
                Note: on some UNIX dialects lsof can't obtain accurate or con-
                sistent  file offset information from its kernel data sources,
                sometimes just for particular kinds  of  files  (e.g.,  socket
                files.)  Consult the lsof FAQ (The FAQ section gives its loca-
                tion.)  for more information.

                The -o and -s options are mutually exclusive; they can't  both
                be  specified.  When neither is specified, lsof displays what-
                ever value - size or offset - is appropriate and available for
                the type of the file.

       -o o     defines  the  number of decimal digits (o) to be printed after
                the ``0t'' for a file offset before the form  is  switched  to
                ``0x...''.  An o value of zero (unlimited) directs lsof to use
                the ``0t'' form for all offset output.

                This option does NOT direct lsof  to  display  offset  at  all
                times;  specify -o (without a trailing number) to do that.  -o
                o only specifies the number of digits after ``0t''  in  either
                mixed  size and offset or offset-only output.  Thus, for exam-
                ple, to direct lsof to display offset at all times with a dec-
                imal digit count of 10, use:

                     -o -o 10
                or
                     -oo10

                The  default number of digits allowed after ``0t'' is normally
                8, but may have been changed by the lsof builder.  Consult the
                description  of  the -o o option in the output of the -h or -?
                option to determine the default that is in effect.

       -O       directs lsof to bypass the strategy it  uses  to  avoid  being
                blocked by some kernel operations - i.e., doing them in forked
                child processes.  See the BLOCKS  AND  TIMEOUTS  and  AVOIDING
                KERNEL  BLOCKS  sections for more information on kernel opera-
                tions that may block lsof.

                While use of this option will reduce lsof startup overhead, it
                may also cause lsof to hang when the kernel doesn't respond to
                a function.  Use this option cautiously.

       -p s     excludes or selects the listing of  files  for  the  processes
                whose optional process IDentification (PID) numbers are in the
                comma-separated set s - e.g., ``123'' or ``123,^456''.  (There
                should be no spaces in the set.)

                PID  numbers  that  begin with `^' (negation) represent exclu-
                sions.

                Multiple process ID numbers are joined in a  single  ORed  set
                before  participating  in  AND option selection.  However, PID
                exclusions are applied without ORing or ANDing and take effect
                before other selection criteria are applied.

       -P       inhibits the conversion of port numbers to port names for net-
                work files.  Inhibiting the conversion may  make  lsof  run  a
                little faster.  It is also useful when port name lookup is not
                working properly.

       -Q       ignore failed search terms. When lsof is told  to  search  for
                users  of  a file, or for users of a device, or for a specific
                PID, or for certain protocols in use by that PID, and  so  on,
                lsof  will  return  an  error if any of the search results are
                empty. The -Q option will change this behavior  so  that  lsof
                will  instead return a successful exit code (0) even if any of
                the search results are  empty.  In  addition,  missing  search
                terms will not be reported to stderr.

       +|-r [t[c<N>][m<fmt>]]
                puts  lsof in repeat mode.  There lsof lists open files as se-
                lected by other options, delays t seconds  (default  fifteen),
                then  repeats  the  listing, delaying and listing repetitively
                until stopped by a condition defined by the prefix to the  op-
                tion.

                If  the prefix is a `-', repeat mode is endless.  Lsof must be
                terminated with an interrupt or quit signal.   `c<N>'  is  for
                specifying  the  limits  of repeating; if the number of itera-
                tions reaches at `<N>', Lsof stops itself.

                If the prefix is `+', repeat mode will end the first cycle  no
                open  files  are  listed  - and of course when lsof is stopped
                with an interrupt or quit signal.  When repeat mode  ends  be-
                cause  no files are listed, the process exit code will be zero
                if any open files were ever listed; one,  if  none  were  ever
                listed.

                Lsof  marks  the  end  of  each listing: if field output is in
                progress (the -F, option  has  been  specified),  the  default
                marker  is  `m'; otherwise the default marker is ``========''.
                The marker is followed by a NL character.

                The optional "m<fmt>" argument  specifies  a  format  for  the
                marker  line.   The  <fmt> characters following `m' are inter-
                preted as a format specification to the strftime(3)  function,
                when  both  it  and the localtime(3) function are available in
                the dialect's C library.  Consult the  strftime(3)  documenta-
                tion  for  what  may appear in its format specification.  Note
                that when field output is requested with the -F option,  <fmt>
                cannot  contain  the  NL  format, ``%n''.  Note also that when
                <fmt> contains spaces or  other  characters  that  affect  the
                shell's  interpretation of arguments, <fmt> must be quoted ap-
                propriately.

                Repeat mode reduces lsof startup overhead, so it is more effi-
                cient  to  use this mode than to call lsof repetitively from a
                shell script, for example.

                To use repeat mode most efficiently, accompany +|-r with spec-
                ification  of  other  lsof selection options, so the amount of
                kernel memory access lsof does will be kept to a minimum.  Op-
                tions  that filter at the process level - e.g., -c, -g, -p, -u
                - are the most efficient selectors.

                Repeat mode is useful when coupled with field output (see  the
                -F,  option description) and a supervising awk or Perl script,
                or a C program.

       -R       directs lsof to list the Parent Process IDentification  number
                in the PPID column.

       -s [p:s] s  alone  directs  lsof to display file size at all times.  It
                causes the SIZE/OFF output column title to be changed to SIZE.
                If the file does not have a size, nothing is displayed.

                The  optional  -s  p:s form is available only for selected di-
                alects, and only when the -h or -?  help output lists it.

                When the optional form is available, the s may be followed  by
                a  protocol  name  (p), either TCP or UDP, a colon (`:') and a
                comma-separated protocol state name list,  the  option  causes
                open  TCP  and UDP files to be excluded if their state name(s)
                are in the list (s) preceded by a `^'; or  included  if  their
                name(s) are not preceded by a `^'.

                Dialects  that support this option may support only one proto-
                col.  When an unsupported protocol  is  specified,  a  message
                will  be displayed indicating state names for the protocol are
                unavailable.

                When an inclusion list is defined,  only  network  files  with
                state  names  in  the list will be present in the lsof output.
                Thus, specifying one state name means that only network  files
                with that lone state name will be listed.

                Case  is unimportant in the protocol or state names, but there
                may be no spaces and the colon (`:') separating  the  protocol
                name (p) and the state name list (s) is required.

                If  only  TCP and UDP files are to be listed, as controlled by
                the specified exclusions and inclusions, the -i option must be
                specified,  too.   If only a single protocol's files are to be
                listed, add its name as an argument to the -i option.

                For example, to list only network files with TCP state LISTEN,
                use:

                     -iTCP -sTCP:LISTEN

                Or, for example, to list network files with all UDP states ex-
                cept Idle, use:

                     -iUDP -sUDP:^Idle

                State names vary with UNIX dialects, so it's not  possible  to
                provide  a  complete  list.   Some common TCP state names are:
                CLOSED, IDLE, BOUND, LISTEN, ESTABLISHED, SYN_SENT,  SYN_RCDV,
                ESTABLISHED,   CLOSE_WAIT,   FIN_WAIT1,   CLOSING,   LAST_ACK,
                FIN_WAIT_2, and TIME_WAIT.  Two common UDP state names are Un-
                bound and Idle.

                See  the  lsof  FAQ (The FAQ section gives its location.)  for
                more information on how to use protocol  state  exclusion  and
                inclusion, including examples.

                The -o (without a following decimal digit count) and -s option
                (without a following protocol and state name list)  are  mutu-
                ally exclusive; they can't both be specified.  When neither is
                specified, lsof displays whatever value - size or offset -  is
                appropriate and available for the type of file.

                Since some types of files don't have true sizes - sockets, FI-
                FOs, pipes, etc. - lsof displays for their sizes  the  content
                amounts in their associated kernel buffers, if possible.

       -S [t]   specifies  an optional time-out seconds value for kernel func-
                tions - lstat(2), readlink(2), and stat(2) - that might other-
                wise  deadlock.   The  minimum for t is two; the default, fif-
                teen; when no value is specified, the default is used.

                See the BLOCKS AND TIMEOUTS section for more information.

       -T [t]   controls the reporting of some TCP/TPI information,  also  re-
                ported  by  netstat(1),  following  the network addresses.  In
                normal output the information  appears  in  parentheses,  each
                item  except  TCP  or  TPI state name identified by a keyword,
                followed by `=', separated from others by a single space:

                     <TCP or TPI state name>
                     QR=<read queue length>
                     QS=<send queue length>
                     SO=<socket options and values>
                     SS=<socket states>
                     TF=<TCP flags and values>
                     WR=<window read length>
                     WW=<window write length>

                Not all values are reported for all UNIX dialects.  Items val-
                ues (when available) are reported after the item name and '='.

                When  the field output mode is in effect (See OUTPUT FOR OTHER
                PROGRAMS.)  each item appears as a field with  a  `T'  leading
                character.

                -T  with no following key characters disables TCP/TPI informa-
                tion reporting.

                -T with following characters selects the reporting of specific
                TCP/TPI information:

                     f    selects reporting of socket options,
                          states and values, and TCP flags and
                          values.
                     q    selects queue length reporting.
                     s    selects connection state reporting.
                     w    selects window size reporting.

                Not  all selections are enabled for some UNIX dialects.  State
                may be selected for all dialects and is reported  by  default.
                The -h or -?  help output for the -T option will show what se-
                lections may be used with the UNIX dialect.

                When -T is used to select information - i.e., it  is  followed
                by  one or more selection characters - the displaying of state
                is disabled by default, and it  must  be  explicitly  selected
                again  in  the characters following -T.  (In effect, then, the
                default is equivalent to -Ts.)  For example, if queue  lengths
                and state are desired, use -Tqs.

                Socket  options,  socket states, some socket values, TCP flags
                and one TCP value may be reported (when available in the  UNIX
                dialect)  in  the form of the names that commonly appear after
                SO_, so_, SS_, TCP_  and TF_ in the dialect's header  files  -
                most     often     <sys/socket.h>,    <sys/socketvar.h>    and
                <netinet/tcp_var.h>.  Consult those header files for the mean-
                ing of the flags, options, states and values.

                ``SO=''  precedes  socket  options and values; ``SS='', socket
                states; and ``TF='', TCP flags and values.

                If a flag or option has a value, the value will follow an  '='
                and   the   name   --  e.g.,  ``SO=LINGER=5'',  ``SO=QLIM=5'',
                ``TF=MSS=512''.  The following seven values may be reported:

                     Name
                     Reported  Description (Common Symbol)

                     KEEPALIVE keep alive time (SO_KEEPALIVE)
                     LINGER    linger time (SO_LINGER)
                     MSS       maximum segment size (TCP_MAXSEG)
                     PQLEN          partial listen queue connections
                     QLEN      established listen queue connections
                     QLIM      established listen queue limit
                     RCVBUF    receive buffer length (SO_RCVBUF)
                     SNDBUF    send buffer length (SO_SNDBUF)

                Details on what socket options and values, socket states,  and
                TCP  flags and values may be displayed for particular UNIX di-
                alects may be found in the answer to the  ``Why  doesn't  lsof
                report socket options, socket states, and TCP flags and values
                for my dialect?'' and ``Why doesn't lsof  report  the  partial
                listen  queue connection count for my dialect?''  questions in
                the lsof FAQ (The FAQ section gives its location.)   On  Linux
                this option also prints the state of UNIX domain sockets.

       -t       produce  terse  output  comprising  only  process  identifiers
                (without a header), so that it is  easy  to  use  programmati-
                cally. e.g.

                     # reload anything using old SSL
                     lsof -t /lib/*/libssl.so.* | xargs -r kill -HUP

                     # get list of processes and then iterate over them (Bash only)
                     mapfile -t pids < <(
                         lsof -wt /var/log/your.log
                     )
                     for pid in "${pids[@]}" ; do
                         your_command -p "$pid"
                     done

                The -t option implies the -w option.

       -u s     selects the listing of files for the user whose login names or
                user ID numbers are in  the  comma-separated  set  s  -  e.g.,
                ``abe'',  or  ``548,root''.  (There should be no spaces in the
                set.)

                Multiple login names or user ID numbers are joined in a single
                ORed set before participating in AND option selection.

                If  a login name or user ID is preceded by a `^', it becomes a
                negation - i.e., files of processes owned by the login name or
                user ID will never be listed.  A negated login name or user ID
                selection is neither ANDed nor ORed with other selections;  it
                is applied before all other selections and absolutely excludes
                the listing of the files of the process.  For example, to  di-
                rect  lsof  to  exclude the listing of files belonging to root
                processes, specify ``-u^root'' or ``-u^0''.

       -U       selects the listing of UNIX domain socket files.

       -v       selects the listing of lsof  version  information,  including:
                revision  number;  when  the  lsof binary was constructed; who
                constructed the binary and where; the  name  of  the  compiler
                used  to  construct the lsof binary; the version number of the
                compiler when readily available; the compiler and loader flags
                used  to  construct  the  lsof binary; and system information,
                typically the output of uname's -a option.

       -V       directs lsof to indicate the items it was asked  to  list  and
                failed to find - command names, file names, Internet addresses
                or files, login names, NFS files, PIDs, PGIDs, and UIDs.

                When other options  are  ANDed  to  search  options,  or  com-
                pile-time options restrict the listing of some files, lsof may
                not report that it failed to find a search item when an  ANDed
                option or compile-time option prevents the listing of the open
                file containing the located search item.

                For example, ``lsof -V -iTCP@foobar -a -d 999'' may not report
                a  failure  to locate open files at ``TCP@foobar'' and may not
                list any, if none have a file descriptor  number  of  999.   A
                similar  situation  arises when HASSECURITY and HASNOSOCKSECU-
                RITY are defined at compile time and they prevent the  listing
                of open files.

       +|-w     Enables  (+)  or  disables (-) the suppression of warning mes-
                sages.

                The lsof builder may choose to have warning messages  disabled
                or  enabled  by default.  The default warning message state is
                indicated in the output of the -h or  -?   option.   Disabling
                warning  messages  when  they are already disabled or enabling
                them when already enabled is acceptable.

                The -t option implies the -w option.

       -x [fl]  may accompany the +d and +D options to direct their processing
                to  cross  over symbolic links and|or file system mount points
                encountered when scanning the directory (+d) or directory tree
                (+D).

                If  -x  is  specified by itself without a following parameter,
                cross-over processing of both symbolic links and  file  system
                mount points is enabled.  Note that when -x is specified with-
                out a parameter, the next argument must begin with '-' or '+'.

                The optional 'f' parameter enables  file  system  mount  point
                cross-over  processing; 'l', symbolic link cross-over process-
                ing.

                The -x option may not be supplied without also supplying a  +d
                or +D option.

       -X       This is a dialect-specific option.

           AIX:
                This IBM AIX RISC/System 6000 option requests the reporting of
                executed text file and shared library references.

                WARNING: because this option uses the kernel readx() function,
                its  use  on  a  busy  AIX  system  might cause an application
                process to hang so completely that it can  neither  be  killed
                nor stopped.  I have never seen this happen or had a report of
                its happening, but I think there is a  remote  possibility  it
                could happen.

                By  default  use  of readx() is disabled.  On AIX 5L and above
                lsof may need setuid-root permission to  perform  the  actions
                this option requests.

                The  lsof builder may specify that the -X option be restricted
                to processes whose real UID is root.  If that has  been  done,
                the -X option will not appear in the -h or -?  help output un-
                less the real UID of the lsof process is  root.   The  default
                lsof  distribution allows any UID to specify -X, so by default
                it will appear in the help output.

                When AIX readx() use is disabled, lsof may not be able to  re-
                port  information for all text and loader file references, but
                it may also avoid exacerbating an AIX kernel directory  search
                kernel error, known as the Stale Segment ID bug.

                The readx() function, used by lsof or any other program to ac-
                cess some sections of kernel virtual memory, can  trigger  the
                Stale  Segment ID bug.  It can cause the kernel's dir_search()
                function to believe erroneously that part of an in-memory copy
                of  a file system directory has been zeroed.  Another applica-
                tion process, distinct from lsof, asking the kernel to  search
                the   directory   -   e.g.,  by  using  open(2)  -  can  cause
                dir_search() to loop forever,  thus  hanging  the  application
                process.

                Consult  the  lsof  FAQ  (The FAQ section gives its location.)
                and the 00README file of the lsof distribution for a more com-
                plete  description  of the Stale Segment ID bug, its APAR, and
                methods for defining readx() use when compiling lsof.

           Linux:
                This Linux option requests that lsof skip the reporting of in-
                formation  on  all  open  TCP,  UDP  and UDPLITE IPv4 and IPv6
                files.

                This Linux option is most useful when the system  has  an  ex-
                tremely  large  number of open TCP, UDP and UDPLITE files, the
                processing of whose  information  in  the  /proc/net/tcp*  and
                /proc/net/udp*  files  would  take lsof a long time, and whose
                reporting is not of interest.

                Use this option with care and only when you are sure that  the
                information  you  want  lsof  to display isn't associated with
                open TCP, UDP or UDPLITE socket files.

           Solaris 10 and above:
                This Solaris 10 and above option  requests  the  reporting  of
                cached  paths for files that have been deleted - i.e., removed
                with rm(1) or unlink(2).

                The cached path is followed by the  string  `` (deleted)''  to
                indicate  that  the path by which the file was opened has been
                deleted.

                Because intervening changes made to the path -  i.e.,  renames
                with mv(1) or rename(2) - are not recorded in the cached path,
                what lsof reports is only the  path  by  which  the  file  was
                opened, not its possibly different final path.

       -z [z]   specifies  how Solaris 10 and higher zone information is to be
                handled.

                Without a following argument - e.g., NO z - the option  speci-
                fies  that zone names are to be listed in the ZONE output col-
                umn.

                The -z option may be followed by a zone name, z.  That  causes
                lsof to list only open files for processes in that zone.  Mul-
                tiple -z z option and argument pairs may be specified to  form
                a list of named zones.  Any open file of any process in any of
                the zones will be listed, subject to other  conditions  speci-
                fied by other options and arguments.

       -Z [Z]   specifies how SELinux security contexts are to be handled.  It
                and 'Z' field output  character  support  are  inhibited  when
                SELinux  is  disabled in the running Linux kernel.  See OUTPUT
                FOR OTHER PROGRAMS for more information on the 'Z' field  out-
                put character.

                Without  a following argument - e.g., NO Z - the option speci-
                fies that security contexts are to  be  listed  in  the  SECU-
                RITY-CONTEXT output column.

                The  -Z  option may be followed by a wildcard security context
                name, Z.  That causes lsof to list only open  files  for  pro-
                cesses in that security context.  Multiple -Z Z option and ar-
                gument pairs may be specified to form a list of security  con-
                texts.   Any  open  file of any process in any of the security
                contexts will be listed, subject to other conditions specified
                by  other  options and arguments.  Note that Z can be A:B:C or
                *:B:C or A:B:* or *:*:C to match against the A:B:C context.

       --       The double minus sign option is a marker that signals the  end
                of  the  keyed options.  It may be used, for example, when the
                first file name begins with a minus sign.  It may also be used
                when  the absence of a value for the last keyed option must be
                signified by the presence of a minus sign in the following op-
                tion and before the start of the file names.

       names    These  are  path  names  of  specific files to list.  Symbolic
                links are resolved before use.  The first name  may  be  sepa-
                rated from the preceding options with the ``--'' option.

                If  a name is the mounted-on directory of a file system or the
                device of the file system, lsof will list all the  files  open
                on  the file system.  To be considered a file system, the name
                must match a mounted-on directory name in mount(8) output,  or
                match  the name of a block device associated with a mounted-on
                directory name.  The +|-f option may be used to force lsof  to
                consider a name a file system identifier (+f) or a simple file
                (-f).

                If name is a path to a directory that is  not  the  mounted-on
                directory name of a file system, it is treated just as a regu-
                lar file is treated - i.e., its listing is restricted to  pro-
                cesses  that  have  it open as a file or as a process-specific
                directory, such as the root or current working directory.   To
                request that lsof look for open files inside a directory name,
                use the +d s and +D D options.

                If a name is the base name of a family of multiplexed files  -
                e.g,  AIX's  /dev/pt[cs]  -  lsof will list all the associated
                multiplexed  files  on  the  device  that  are  open  -  e.g.,
                /dev/pt[cs]/1, /dev/pt[cs]/2, etc.

                If  a  name  is  a  UNIX domain socket name, lsof will usually
                search for it by the characters of the name alone - exactly as
                it  is  specified  and is recorded in the kernel socket struc-
                ture.  (See the next paragraph for an exception to  that  rule
                for  Linux.)   Specifying  a relative path - e.g., ./file - in
                place of the file's absolute path - e.g.,  /tmp/file  -  won't
                work  because  lsof must match the characters you specify with
                what it finds in the kernel UNIX domain socket structures.

                If a name is a Linux UNIX domain socket name, in one case lsof
                is  able  to search for it by its device and inode number, al-
                lowing name to be a relative path.  The case requires that the
                absolute  path  --  i.e.,  one beginning with a slash ('/') be
                used by the process that created  the  socket,  and  hence  be
                stored  in  the /proc/net/unix file; and it requires that lsof
                be able to obtain the device and node numbers of both the  ab-
                solute  path in /proc/net/unix and name via successful stat(2)
                system calls.  When those conditions are  met,  lsof  will  be
                able to search for the UNIX domain socket when some path to it
                is is specified in name.  Thus, for example, if  the  path  is
                /dev/log, and an lsof search is initiated when the working di-
                rectory is /dev, then name could be ./log.

                If a name is none of the above, lsof will list any open  files
                whose device and inode match that of the specified path name.

                If  you  have also specified the -b option, the only names you
                may safely specify are file systems for which your mount table
                supplies  alternate  device  numbers.  See the AVOIDING KERNEL
                BLOCKS and ALTERNATE DEVICE NUMBERS sections for more informa-
                tion.

                Multiple  file  names  are  joined in a single ORed set before
                participating in AND option selection.

EXECUTION EXAMPLE:
COMMAND INPUT:
lsof -i

COMMAND OUTPUT:
(No output)

===

COMMAND: lsmod

DESCRIPTION: lsmod - Show the status of modules in the Linux Kernel

USAGE: lsmod

EXECUTION EXAMPLE:
COMMAND INPUT:
lsmod | head -5

COMMAND OUTPUT:
Module                  Size  Used by
xt_conntrack           16384  1
nft_chain_nat          16384  3
xt_MASQUERADE          20480  1
nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE

===

COMMAND: dmesg

DESCRIPTION: dmesg - print or control the kernel ring buffer

USAGE: dmesg [options]

       dmesg --clear

       dmesg --read-clear [options]

       dmesg --console-level level

       dmesg --console-on

       dmesg --console-off

OPTIONS:
The --clear, --read-clear, --console-on, --console-off, and
       --console-level options are mutually exclusive.

       -C, --clear
           Clear the ring buffer.

       -c, --read-clear
           Clear the ring buffer after first printing its contents.

       -D, --console-off
           Disable the printing of messages to the console.

       -d, --show-delta
           Display the timestamp and the time delta spent between messages. If
           used together with --notime then only the time delta without the
           timestamp is printed.

       -E, --console-on
           Enable printing messages to the console.

       -e, --reltime
           Display the local time and the delta in human-readable format. Be
           aware that conversion to the local time could be inaccurate (see -T
           for more details).

       -F, --file file
           Read the syslog messages from the given file. Note that -F does not
           support messages in kmsg format. The old syslog format is supported
           only.

       -f, --facility list
           Restrict output to the given (comma-separated) list of facilities.
           For example:

           dmesg --facility=daemon

           will print messages from system daemons only. For all supported
           facilities see the --help output.

       -H, --human
           Enable human-readable output. See also --color, --reltime and
           --nopager.

       -J, --json
           Use JSON output format. The time output format is in "sec.usec"
           format only, log priority level is not decoded by default (use
           --decode to split into facility and priority), the other options to
           control the output format or time format are silently ignored.

       -k, --kernel
           Print kernel messages.

       -L, --color[=when]
           Colorize the output. The optional argument when can be auto, never
           or always. If the when argument is omitted, it defaults to auto.
           The colors can be disabled; for the current built-in default see
           the --help output. See also the COLORS section below.

       -l, --level list
           Restrict output to the given (comma-separated) list of levels. For
           example:

           dmesg --level=err,warn

           will print error and warning messages only. For all supported
           levels see the --help output.

       -n, --console-level level
           Set the level at which printing of messages is done to the console.
           The level is a level number or abbreviation of the level name. For
           all supported levels see the --help output.

           For example, -n 1 or -n emerg prevents all messages, except
           emergency (panic) messages, from appearing on the console. All
           levels of messages are still written to /proc/kmsg, so syslogd(8)
           can still be used to control exactly where kernel messages appear.
           When the -n option is used, dmesg will not print or clear the
           kernel ring buffer.

       --noescape
           The unprintable and potentially unsafe characters (e.g., broken
           multi-byte sequences, terminal controlling chars, etc.) are escaped
           in format \x<hex> for security reason by default. This option
           disables this feature at all. It's usable for example for debugging
           purpose together with --raw. Be careful and don't use it by
           default.

       -P, --nopager
           Do not pipe output into a pager. A pager is enabled by default for
           --human output.

       -p, --force-prefix
           Add facility, level or timestamp information to each line of a
           multi-line message.

       -r, --raw
           Print the raw message buffer, i.e., do not strip the log-level
           prefixes, but all unprintable characters are still escaped (see
           also --noescape).

           Note that the real raw format depends on the method how dmesg reads
           kernel messages. The /dev/kmsg device uses a different format than
           syslog(2). For backward compatibility, dmesg returns data always in
           the syslog(2) format. It is possible to read the real raw data from
           /dev/kmsg by, for example, the command 'dd if=/dev/kmsg
           iflag=nonblock'.

       -S, --syslog
           Force dmesg to use the syslog(2) kernel interface to read kernel
           messages. The default is to use /dev/kmsg rather than syslog(2)
           since kernel 3.5.0.

       -s, --buffer-size size
           Use a buffer of size to query the kernel ring buffer. This is 16392
           by default. (The default kernel syslog buffer size was 4096 at
           first, 8192 since 1.3.54, 16384 since 2.1.113.) If you have set the
           kernel buffer to be larger than the default, then this option can
           be used to view the entire buffer.

       -T, --ctime
           Print human-readable timestamps.

           Be aware that the timestamp could be inaccurate! The time source
           used for the logs is not updated after system SUSPEND/RESUME.
           Timestamps are adjusted according to current delta between boottime
           and monotonic clocks, this works only for messages printed after
           last resume.

       --since time
           Display record since the specified time. The time is possible to
           specify in absolute way as well as by relative notation (e.g. '1
           hour ago'). Be aware that the timestamp could be inaccurate and see
           --ctime for more details.

       --until time
           Display record until the specified time. The time is possible to
           specify in absolute way as well as by relative notation (e.g. '1
           hour ago'). Be aware that the timestamp could be inaccurate and see
           --ctime for more details.

       -t, --notime
           Do not print kernel's timestamps.

       --time-format format
           Print timestamps using the given format, which can be ctime,
           reltime, delta or iso. The first three formats are aliases of the
           time-format-specific options. The iso format is a dmesg
           implementation of the ISO-8601 timestamp format. The purpose of
           this format is to make the comparing of timestamps between two
           systems, and any other parsing, easy. The definition of the iso
           timestamp is: YYYY-MM-DD<T>HH:MM:SS,<microseconds><-+><timezone
           offset from UTC>.

           The iso format has the same issue as ctime: the time may be
           inaccurate when a system is suspended and resumed.

       -u, --userspace
           Print userspace messages.

       -w, --follow
           Wait for new messages. This feature is supported only on systems
           with a readable /dev/kmsg (since kernel 3.5.0).

       -W, --follow-new
           Wait and print only new messages.

       -x, --decode
           Decode facility and level (priority) numbers to human-readable
           prefixes.

       -h, --help
           Display help text and exit.

       -V, --version
           Print version and exit.

EXECUTION EXAMPLE:
COMMAND INPUT:
dmesg | tail -5

COMMAND OUTPUT:
dmesg: read kernel buffer failed: Operation not permitted

===

COMMAND: systemctl

DESCRIPTION: systemctl - Control the systemd system and service manager

USAGE: systemctl [OPTIONS...] COMMAND [UNIT...]

EXECUTION EXAMPLE:
COMMAND INPUT:
systemctl status ssh

COMMAND OUTPUT:
● ssh.service - OpenBSD Secure Shell server
     Loaded: loaded (/lib/systemd/system/ssh.service; enabled; preset: enabled)
     Active: active (running) since Mon 2025-03-03 22:29:37 UTC; 32min ago
       Docs: man:sshd(8)
             man:sshd_config(5)
   Main PID: 1384 (sshd)
      Tasks: 1 (limit: 4682)
     Memory: 5.4M
        CPU: 319ms
     CGroup: /system.slice/ssh.service
             └─1384 "sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups"

Mar 03 22:44:18 cybo1 sshd[3094]: pam_unix(sshd:session): session closed for user vega
Mar 03 22:44:19 cybo1 sshd[3120]: Accepted publickey for vega from 130.208.133.151 port 64316 ssh2: RSA SHA256:ZoYcRTkI6ZQ6T16C7QA414BblNb3Z/VUmkeikvOcYt8
Mar 03 22:44:19 cybo1 sshd[3120]: pam_unix(sshd:session): session opened for user vega(uid=1000) by (uid=0)
Mar 03 22:44:19 cybo1 sshd[3120]: pam_env(sshd:session): deprecated reading of user environment enabled
Mar 03 22:49:05 cybo1 sshd[6188]: error: kex_exchange_identification: Connection closed by remote host
Mar 03 22:49:05 cybo1 sshd[6188]: Connection closed by 193.32.162.133 port 43336
Mar 03 23:00:34 cybo1 sshd[9879]: error: kex_exchange_identification: Connection closed by remote host
Mar 03 23:00:34 cybo1 sshd[9879]: Connection closed by 165.154.162.212 port 48978
Mar 03 23:00:34 cybo1 sshd[9880]: Connection closed by 165.154.162.212 port 49162 [preauth]
Mar 03 23:00:35 cybo1 sshd[9882]: Unable to negotiate with 165.154.162.212 port 49450: no matching host key type found. Their offer: ssh-rsa [preauth]

===

COMMAND: systemctl

DESCRIPTION: systemctl - Control the systemd system and service manager

USAGE: systemctl [OPTIONS...] COMMAND [UNIT...]

EXECUTION EXAMPLE:
COMMAND INPUT:
systemctl list-units --type=service --state=running | head -5

COMMAND OUTPUT:
UNIT                                                   LOAD   ACTIVE SUB     DESCRIPTION
  containerd.service                                     loaded active running containerd container runtime
  cron.service                                           loaded active running Regular background program processing daemon
  dbus.service                                           loaded active running D-Bus System Message Bus
  docker.service                                         loaded active running Docker Application Container Engine

===

COMMAND: journalctl

DESCRIPTION: journalctl - Query the systemd journal

USAGE: journalctl [OPTIONS...] [MATCHES...]

OPTIONS:
The following options control where to read journal records from:

       --system, --user
           Show messages from system services and the kernel (with --system).
           Show messages from service of current user (with --user). If
           neither is specified, show all messages that the user can see.

           The --user option affects how --unit arguments are treated. See
           --unit.

       -M, --machine=
           Show messages from a running, local container. Specify a container
           name to connect to.

       -m, --merge
           Show entries interleaved from all available journals, including
           remote ones.

       -D DIR, --directory=DIR
           Takes a directory path as argument. If specified, journalctl will
           operate on the specified journal directory DIR instead of the
           default runtime and system journal paths.

       --file=GLOB
           Takes a file glob as an argument. If specified, journalctl will
           operate on the specified journal files matching GLOB instead of the
           default runtime and system journal paths. May be specified multiple
           times, in which case files will be suitably interleaved.

       --root=ROOT
           Takes a directory path as an argument. If specified, journalctl
           will operate on journal directories and catalog file hierarchy
           underneath the specified directory instead of the root directory
           (e.g.  --update-catalog will create
           ROOT/var/lib/systemd/catalog/database, and journal files under
           ROOT/run/journal/ or ROOT/var/log/journal/ will be displayed).

       --image=IMAGE
           Takes a path to a disk image file or block device node. If
           specified, journalctl will operate on the file system in the
           indicated disk image. This option is similar to --root=, but
           operates on file systems stored in disk images or block devices,
           thus providing an easy way to extract log data from disk images.
           The disk image should either contain just a file system or a set of
           file systems within a GPT partition table, following the
           Discoverable Partitions Specification[1]. For further information
           on supported disk images, see systemd-nspawn(1)'s switch of the
           same name.

       --namespace=NAMESPACE
           Takes a journal namespace identifier string as argument. If not
           specified the data collected by the default namespace is shown. If
           specified shows the log data of the specified namespace instead. If
           the namespace is specified as "*" data from all namespaces is
           shown, interleaved. If the namespace identifier is prefixed with
           "+" data from the specified namespace and the default namespace is
           shown, interleaved, but no other. For details about journal
           namespaces see systemd-journald.service(8).

EXECUTION EXAMPLE:
COMMAND INPUT:
journalctl --no-pager -n 5

COMMAND OUTPUT:
Mar 03 23:02:04 cybo1 groupadd[11376]: group added to /etc/gshadow: name=plocate
Mar 03 23:02:04 cybo1 groupadd[11376]: new group: name=plocate, GID=112
Mar 03 23:02:05 cybo1 systemd[1]: Reloading.
Mar 03 23:02:05 cybo1 systemd[1]: Started plocate-updatedb.timer - Update the plocate database daily.
Mar 03 23:02:10 cybo1 sudo[10543]: pam_unix(sudo:session): session closed for user root

===

COMMAND: top

DESCRIPTION: top - display Linux processes

USAGE: top [options]

EXECUTION EXAMPLE:
COMMAND INPUT:
top -n 1 -b | head -10

COMMAND OUTPUT:
top - 23:02:37 up 33 min,  1 user,  load average: 0.48, 0.29, 0.20
Tasks:  97 total,   1 running,  96 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.0 us,100.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st 
MiB Mem :   3924.7 total,   2112.3 free,    620.9 used,   1450.7 buff/cache     
MiB Swap:      0.0 total,      0.0 free,      0.0 used.   3303.8 avail Mem 

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
  11115 root      20   0 1204764  40572  28824 S   6.2   1.0   0:00.18 contain+
  12215 vega      20   0    9036   5208   3160 R   6.2   0.1   0:00.01 top
      1 root      20   0  168996  13624   9220 S   0.0   0.3   0:04.22 systemd

===

COMMAND: free

DESCRIPTION: free - Display amount of free and used memory in the system

USAGE: free [options]

OPTIONS:
-b, --bytes
              Display the amount of memory in bytes.

       -k, --kibi
              Display the amount of memory in kibibytes.  This is the default.

       -m, --mebi
              Display the amount of memory in mebibytes.

       -g, --gibi
              Display the amount of memory in gibibytes.

       --tebi Display the amount of memory in tebibytes.

       --pebi Display the amount of memory in pebibytes.

       --kilo Display the amount of memory in kilobytes. Implies --si.

       --mega Display the amount of memory in megabytes. Implies --si.

       --giga Display the amount of memory in gigabytes. Implies --si.

       --tera Display the amount of memory in terabytes. Implies --si.

       --peta Display the amount of memory in petabytes. Implies --si.

       -h, --human
              Show  all  output  fields automatically scaled to shortest three
              digit unit and display the units of print out.  Following  units
              are used.

                B = bytes
                Ki = kibibyte
                Mi = mebibyte
                Gi = gibibyte
                Ti = tebibyte
                Pi = pebibyte

              If  unit  is  missing, and you have exbibyte of RAM or swap, the
              number is in tebibytes and columns might  not  be  aligned  with
              header.

       -w, --wide
              Switch  to  the  wide  mode. The wide mode produces lines longer
              than 80 characters. In this mode buffers and cache are  reported
              in two separate columns.

       -c, --count count
              Display the result count times.  Requires the -s option.

       -l, --lohi
              Show detailed low and high memory statistics.

       -s, --seconds delay
              Continuously  display  the result delay  seconds apart.  You may
              actually specify any floating point number for delay  using  ei-
              ther  . or , for decimal point.  usleep(3) is used for microsec-
              ond resolution delay times.

       --si   Use kilo, mega, giga etc (power of 1000) instead of kibi,  mebi,
              gibi (power of 1024).

       -t, --total
              Display a line showing the column totals.

       -v, --committed
              Display  a  line  showing  the memory commit limit and amount of
              committed/uncommitted memory. The total column on this line will
              display the memory commit limit.   This line is relevant if mem-
              ory overcommit is disabled.

       --help Print help.

       -V, --version
              Display version information.

EXECUTION EXAMPLE:
COMMAND INPUT:
free -h

COMMAND OUTPUT:
total        used        free      shared  buff/cache   available
Mem:           3.8Gi       621Mi       2.1Gi       532Ki       1.4Gi       3.2Gi
Swap:             0B          0B          0B

===

COMMAND: lscpu

DESCRIPTION: lscpu - display information about the CPU architecture

USAGE: lscpu [options]

OPTIONS:
-a, --all
           Include lines for online and offline CPUs in the output (default
           for -e). This option may only be specified together with option -e
           or -p.

       -B, --bytes
           Print the sizes in bytes rather than in a human-readable format.

           By default, the unit, sizes are expressed in, is byte, and unit
           prefixes are in power of 2^10 (1024). Abbreviations of symbols are
           exhibited truncated in order to reach a better readability, by
           exhibiting alone the first letter of them; examples: "1 KiB" and "1
           MiB" are respectively exhibited as "1 K" and "1 M", then omitting
           on purpose the mention "iB", which is part of these abbreviations.

       -b, --online
           Limit the output to online CPUs (default for -p). This option may
           only be specified together with option -e or -p.

       -C, --caches[=list]
           Display details about CPU caches. For details about available
           information see --help output.

           If the list argument is omitted, all columns for which data is
           available are included in the command output.

           When specifying the list argument, the string of option, equal sign
           (=), and list must not contain any blanks or other whitespace.
           Examples: -C=NAME,ONE-SIZE or --caches=NAME,ONE-SIZE.

           The default list of columns may be extended if list is specified in
           the format +list (e.g., lscpu -C=+ALLOC-POLICY).

       -c, --offline
           Limit the output to offline CPUs. This option may only be specified
           together with option -e or -p.

       -e, --extended[=list]
           Display the CPU information in human-readable format.

           If the list argument is omitted, the default columns are included
           in the command output. The default output is subject to change.

           When specifying the list argument, the string of option, equal sign
           (=), and list must not contain any blanks or other whitespace.
           Examples: '-e=cpu,node' or '--extended=cpu,node'.

           The default list of columns may be extended if list is specified in
           the format +list (e.g., lscpu -e=+MHZ).

       -J, --json
           Use JSON output format for the default summary or extended output
           (see --extended).

       -p, --parse[=list]
           Optimize the command output for easy parsing.

           If the list argument is omitted, the command output is compatible
           with earlier versions of lscpu. In this compatible format, two
           commas are used to separate CPU cache columns. If no CPU caches are
           identified the cache column is omitted. If the list argument is
           used, cache columns are separated with a colon (:).

           When specifying the list argument, the string of option, equal sign
           (=), and list must not contain any blanks or other whitespace.
           Examples: '-p=cpu,node' or '--parse=cpu,node'.

           The default list of columns may be extended if list is specified in
           the format +list (e.g., lscpu -p=+MHZ).

       -s, --sysroot directory
           Gather CPU data for a Linux instance other than the instance from
           which the lscpu command is issued. The specified directory is the
           system root of the Linux instance to be inspected.

       -x, --hex
           Use hexadecimal masks for CPU sets (for example "ff"). The default
           is to print the sets in list format (for example 0,1). Note that
           before version 2.30 the mask has been printed with 0x prefix.

       -y, --physical
           Display physical IDs for all columns with topology elements (core,
           socket, etc.). Other than logical IDs, which are assigned by lscpu,
           physical IDs are platform-specific values that are provided by the
           kernel. Physical IDs are not necessarily unique and they might not
           be arranged sequentially. If the kernel could not retrieve a
           physical ID for an element lscpu prints the dash (-) character.

           The CPU logical numbers are not affected by this option.

       --output-all
           Output all available columns. This option must be combined with
           either --extended, --parse or --caches.

EXECUTION EXAMPLE:
COMMAND INPUT:
lscpu | head -5

COMMAND OUTPUT:
Architecture:                         x86_64
CPU op-mode(s):                       32-bit, 64-bit
Address sizes:                        46 bits physical, 48 bits virtual
Byte Order:                           Little Endian
CPU(s):                               2

===

COMMAND: lspci

DESCRIPTION: lspci - list all PCI devices

USAGE: lspci [options]

OPTIONS:
Basic display modes
       -m     Dump  PCI  device data in a backward-compatible machine readable
              form.  See below for details.

       -mm    Dump PCI device data in a machine readable form for easy parsing
              by scripts.  See below for details.

       -t     Show  a tree-like diagram containing all buses, bridges, devices
              and connections between them.

   Display options
       -v     Be verbose and display detailed information about all devices.

       -vv    Be very verbose and display more details.  This  level  includes
              everything deemed useful.

       -vvv   Be  even  more  verbose  and  display  everything we are able to
              parse, even if it doesn't look interesting at all  (e.g.,  unde-
              fined memory regions).

       -k     Show kernel drivers handling each device and also kernel modules
              capable of handling it.  Turned on by default when -v  is  given
              in  the  normal  mode of output.  (Currently works only on Linux
              with kernel 2.6 or newer.)

       -x     Show hexadecimal dump of the standard part of the  configuration
              space (the first 64 bytes or 128 bytes for CardBus bridges).

       -xxx   Show  hexadecimal  dump of the whole PCI configuration space. It
              is available only to root as several PCI devices crash when  you
              try to read some parts of the config space (this behavior proba-
              bly doesn't violate the PCI standard, but  it's  at  least  very
              stupid).  However,  such  devices are rare, so you needn't worry
              much.

       -xxxx  Show hexadecimal dump of the extended (4096-byte) PCI configura-
              tion space available on PCI-X 2.0 and PCI Express buses.

       -b     Bus-centric  view. Show all IRQ numbers and addresses as seen by
              the cards on the PCI bus instead of as seen by the kernel.

       -D     Always show PCI domain numbers.  By  default,  lspci  suppresses
              them on machines which have only domain 0.

       -P     Identify  PCI devices by path through each bridge, instead of by
              bus number.

       -PP    Identify PCI devices by path through each  bridge,  showing  the
              bus number as well as the device number.

   Options to control resolving ID's to names
       -n     Show  PCI  vendor and device codes as numbers instead of looking
              them up in the PCI ID list.

       -nn    Show PCI vendor and device codes as both numbers and names.

       -q     Use DNS to query the central PCI ID database if a device is  not
              found  in the local pci.ids file. If the DNS query succeeds, the
              result is cached in ~/.pciids-cache and it is recognized in sub-
              sequent  runs  even if -q is not given any more. Please use this
              switch inside automated scripts only with caution to avoid over-
              loading the database servers.

       -qq    Same as -q, but the local cache is reset.

       -Q     Query the central database even for entries which are recognized
              locally.  Use this if you suspect that the  displayed  entry  is
              wrong.

   Options for selection of devices
       -s [[[[<domain>]:]<bus>]:][<device>][.[<func>]]
              Show  only devices in the specified domain (in case your machine
              has several host bridges, they can either  share  a  common  bus
              number  space  or  each  of them can address a PCI domain of its
              own; domains are numbered from 0 to ffff), bus (0 to ff), device
              (0  to  1f) and function (0 to 7).  Each component of the device
              address can be omitted or set to "*", both meaning "any  value".
              All  numbers  are  hexadecimal.  E.g., "0:" means all devices on
              bus 0, "0" means all functions of device 0 on any bus, "0.3" se-
              lects  third  function  of  device 0 on all buses and ".4" shows
              only the fourth function of each device.

       -d [<vendor>]:[<device>][:<class>[:<prog-if>]]
              Show only devices with specified vendor, device, class  ID,  and
              programming  interface.   The  ID's are given in hexadecimal and
              may be omitted or given as "*", both meaning  "any  value".  The
              class ID can contain "x" characters which stand for "any digit".

   Other options
       -i <file>
              Use    <file>    as    the    PCI    ID    list    instead    of
              /usr/share/misc/pci.ids.

       -p <file>
              Use <file> as the map of PCI ID's handled by kernel modules.  By
              default,  lspci uses /lib/modules/kernel_version/modules.pcimap.
              Applies only to Linux systems with recent enough module tools.

       -M     Invoke bus mapping mode which performs a thorough  scan  of  all
              PCI  devices, including those behind misconfigured bridges, etc.
              This option gives meaningful results only with a direct hardware
              access  mode,  which  usually  requires root privileges.  By de-
              fault, the bus mapper scans domain. You can use the -s option to
              select a different domain.

       --version
              Shows lspci version. This option should be used stand-alone.

   PCI access options
       The  PCI  utilities  use  the  PCI  library to talk to PCI devices (see
       pcilib(7) for details). You can use the following options to  influence
       its behavior:

       -A <method>
              The  library  supports  a  variety  of methods to access the PCI
              hardware.  By default, it uses the first  access  method  avail-
              able, but you can use this option to override this decision. See
              -A help for a list of available methods and their descriptions.

       -O <param>=<value>
              The behavior of the library is controlled by several  named  pa-
              rameters.  This option allows one to set the value of any of the
              parameters. Use -O help for a list of known parameters and their
              default values.

       -H1    Use  direct hardware access via Intel configuration mechanism 1.
              (This is a shorthand for -A intel-conf1.)

       -H2    Use direct hardware access via Intel configuration mechanism  2.
              (This is a shorthand for -A intel-conf2.)

       -F <file>
              Instead of accessing real hardware, read the list of devices and
              values of their configuration registers from the given file pro-
              duced  by  an  earlier run of lspci -x.  This is very useful for
              analysis of user-supplied bug reports, because you  can  display
              the  hardware configuration in any way you want without disturb-
              ing the user with requests for more dumps.

       -G     Increase debug level of the library.

EXECUTION EXAMPLE:
COMMAND INPUT:
lspci | head -2

COMMAND OUTPUT:
00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma] (rev 02)
00:01.0 ISA bridge: Intel Corporation 82371AB/EB/MB PIIX4 ISA (rev 03)

===

COMMAND: lsusb

DESCRIPTION: lsusb - list USB devices

USAGE: lsusb [ options ]

OPTIONS:
-v, --verbose
              Tells lsusb to be verbose and display detailed information about
              the  devices shown.  This includes configuration descriptors for
              the device's current speed.  Class descriptors  will  be  shown,
              when  available,  for  USB  device classes including hub, audio,
              HID, communications, and chipcard. Can be used with  the  t  op-
              tion.

       -s [[bus]:][devnum]
              Show  only devices in specified bus and/or devnum.  Both IDs are
              given in decimal and may be omitted.

       -d [vendor]:[product]
              Show only devices with the  specified  vendor  and  product  ID.
              Both IDs are given in hexadecimal.

       -D device
              Do not scan the /dev/bus/usb directory, instead display only in-
              formation about the device whose device file is given.  The  de-
              vice  file  should be something like /dev/bus/usb/001/001.  This
              option displays detailed information like the v option; you must
              be root to do this.

       -t, --tree
              Tells lsusb to dump the physical USB device hierarchy as a tree.
              Verbosity can be increased twice with the v option.

       -V, --version
              Print version information on standard output, then exit success-
              fully.

EXECUTION EXAMPLE:
COMMAND INPUT:
lsusb | head -2

COMMAND OUTPUT:
(No output)

===

COMMAND: lsblk

DESCRIPTION: lsblk - list block devices

USAGE: lsblk [options] [device...]

OPTIONS:
-A, --noempty
           Don't print empty devices.

       -a, --all
           Disable all built-in filters and list all empty devices and RAM
           disk devices too.

       -b, --bytes
           Print the sizes in bytes rather than in a human-readable format.

           By default, the unit, sizes are expressed in, is byte, and unit
           prefixes are in power of 2^10 (1024). Abbreviations of symbols are
           exhibited truncated in order to reach a better readability, by
           exhibiting alone the first letter of them; examples: "1 KiB" and "1
           MiB" are respectively exhibited as "1 K" and "1 M", then omitting
           on purpose the mention "iB", which is part of these abbreviations.

       -D, --discard
           Print information about the discarding capabilities (TRIM, UNMAP)
           for each device.

       -d, --nodeps
           Do not print holder devices or slaves. For example, lsblk --nodeps
           /dev/sda prints information about the sda device only.

       -E, --dedup column
           Use column as a de-duplication key to de-duplicate output tree. If
           the key is not available for the device, or the device is a
           partition and parental whole-disk device provides the same key than
           the device is always printed.

           The usual use case is to de-duplicate output on system multi-path
           devices, for example by -E WWN.

       -e, --exclude list
           Exclude the devices specified by the comma-separated list of major
           device numbers. Note that RAM disks (major=1) are excluded by
           default if --all is not specified. The filter is applied to the
           top-level devices only. This may be confusing for --list output
           format where hierarchy of the devices is not obvious.

       -f, --fs
           Output info about filesystems. This option is equivalent to -o
           NAME,FSTYPE,FSVER,LABEL,UUID,FSAVAIL,FSUSE%,MOUNTPOINTS. The
           authoritative information about filesystems and raids is provided
           by the blkid(8) command.

       -I, --include list
           Include devices specified by the comma-separated list of major
           device numbers. The filter is applied to the top-level devices
           only. This may be confusing for --list output format where
           hierarchy of the devices is not obvious.

       -i, --ascii
           Use ASCII characters for tree formatting.

       -J, --json
           Use JSON output format. It's strongly recommended to use --output
           and also --tree if necessary.

       -l, --list
           Produce output in the form of a list. The output does not provide
           information about relationships between devices and since version
           2.34 every device is printed only once if --pairs or --raw not
           specified (the parsable outputs are maintained in backwardly
           compatible way).

       -M, --merge
           Group parents of sub-trees to provide more readable output for
           RAIDs and Multi-path devices. The tree-like output is required.

       -m, --perms
           Output info about device owner, group and mode. This option is
           equivalent to -o NAME,SIZE,OWNER,GROUP,MODE.

       -n, --noheadings
           Do not print a header line.

       -o, --output list
           Specify which output columns to print. Use --help to get a list of
           all supported columns. The columns may affect tree-like output. The
           default is to use tree for the column 'NAME' (see also --tree).

           The default list of columns may be extended if list is specified in
           the format +list (e.g., lsblk -o +UUID).

       -O, --output-all
           Output all available columns.

       -P, --pairs
           Produce output in the form of key="value" pairs. The output lines
           are still ordered by dependencies. All potentially unsafe value
           characters are hex-escaped (\x<code>). See also option --shell.

       -p, --paths
           Print full device paths.

       -r, --raw
           Produce output in raw format. The output lines are still ordered by
           dependencies. All potentially unsafe characters are hex-escaped
           (\x<code>) in the NAME, KNAME, LABEL, PARTLABEL and MOUNTPOINT
           columns.

       -S, --scsi
           Output info about SCSI devices only. All partitions, slaves and
           holder devices are ignored.

       -s, --inverse
           Print dependencies in inverse order. If the --list output is
           requested then the lines are still ordered by dependencies.

       -T, --tree[=column]
           Force tree-like output format. If column is specified, then a tree
           is printed in the column. The default is NAME column.

       -t, --topology
           Output info about block-device topology. This option is equivalent
           to

           -o
           NAME,ALIGNMENT,MIN-IO,OPT-IO,PHY-SEC,LOG-SEC,ROTA,SCHED,RQ-SIZE,RA,WSAME.

       -h, --help
           Display help text and exit.

       -V, --version
           Print version and exit.

       -w, --width number
           Specifies output width as a number of characters. The default is
           the number of the terminal columns, and if not executed on a
           terminal, then output width is not restricted at all by default.
           This option also forces lsblk to assume that terminal control
           characters and unsafe characters are not allowed. The expected
           use-case is for example when lsblk is used by the watch(1) command.

       -x, --sort column
           Sort output lines by column. This option enables --list output
           format by default. It is possible to use the option --tree to force
           tree-like output and than the tree branches are sorted by the
           column.

       -y, --shell
           The column name will be modified to contain only characters allowed
           for shell variable identifiers, for example, MIN_IO and FSUSE_PCT
           instead of MIN-IO and FSUSE%. This is usable, for example, with
           --pairs. Note that this feature has been automatically enabled for
           --pairs in version 2.37, but due to compatibility issues, now it's
           necessary to request this behavior by --shell.

       -z, --zoned
           Print the zone related information for each device.

       --sysroot directory
           Gather data for a Linux instance other than the instance from which
           the lsblk command is issued. The specified directory is the system
           root of the Linux instance to be inspected. The real device nodes
           in the target directory can be replaced by text files with udev
           attributes.

EXECUTION EXAMPLE:
COMMAND INPUT:
lsblk

COMMAND OUTPUT:
NAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
sda       8:0    0   10G  0 disk 
├─sda1    8:1    0  9.9G  0 part /
├─sda14   8:14   0    3M  0 part 
└─sda15   8:15   0  124M  0 part /boot/efi

===

COMMAND: fdisk

DESCRIPTION: fdisk - manipulate disk partition table

USAGE: fdisk [options] device

       fdisk -l [device...]

OPTIONS:
-b, --sector-size sectorsize
           Specify the sector size of the disk. Valid values are 512, 1024,
           2048, and 4096. (Recent kernels know the sector size. Use this
           option only on old kernels or to override the kernel's ideas.)
           Since util-linux-2.17, fdisk differentiates between logical and
           physical sector size. This option changes both sector sizes to
           sectorsize.

       -B, --protect-boot
           Don't erase the beginning of the first disk sector when creating a
           new disk label. This feature is supported for GPT and MBR.

       -c, --compatibility[=mode]
           Specify the compatibility mode, 'dos' or 'nondos'. The default is
           non-DOS mode. For backward compatibility, it is possible to use the
           option without the mode argument -- then the default is used. Note
           that the optional mode argument cannot be separated from the -c
           option by a space, the correct form is for example -c=dos.

       -h, --help
           Display help text and exit.

       -V, --version
           Print version and exit.

       -L, --color[=when]
           Colorize the output. The optional argument when can be auto, never
           or always. If the when argument is omitted, it defaults to auto.
           The colors can be disabled; for the current built-in default see
           the --help output. See also the COLORS section.

       -l, --list
           List the partition tables for the specified devices and then exit.

           If no devices are given, the devices mentioned in /proc/partitions
           (if this file exists) are used. Devices are always listed in the
           order in which they are specified on the command-line, or by the
           kernel listed in /proc/partitions.

       -x, --list-details
           Like --list, but provides more details.

       --lock[=mode]
           Use exclusive BSD lock for device or file it operates. The optional
           argument mode can be yes, no (or 1 and 0) or nonblock. If the mode
           argument is omitted, it defaults to yes. This option overwrites
           environment variable $LOCK_BLOCK_DEVICE. The default is not to use
           any lock at all, but it's recommended to avoid collisions with
           systemd-udevd(8) or other tools.

       -n, --noauto-pt
           Don't automatically create a default partition table on empty
           device. The partition table has to be explicitly created by user
           (by command like 'o', 'g', etc.).

       -o, --output list
           Specify which output columns to print. Use --help to get a list of
           all supported columns.

           The default list of columns may be extended if list is specified in
           the format +list (e.g., -o +UUID).

       -s, --getsz
           Print the size in 512-byte sectors of each given block device. This
           option is DEPRECATED in favour of blockdev(8).

       -t, --type type
           Enable support only for disklabels of the specified type, and
           disable support for all other types.

       -u, --units[=unit]
           When listing partition tables, show sizes in 'sectors' or in
           'cylinders'. The default is to show sizes in sectors. For backward
           compatibility, it is possible to use the option without the unit
           argument -- then the default is used. Note that the optional unit
           argument cannot be separated from the -u option by a space, the
           correct form is for example '-u=cylinders'.

       -C, --cylinders number
           Specify the number of cylinders of the disk. I have no idea why
           anybody would want to do so.

       -H, --heads number
           Specify the number of heads of the disk. (Not the physical number,
           of course, but the number used for partition tables.) Reasonable
           values are 255 and 16.

       -S, --sectors number
           Specify the number of sectors per track of the disk. (Not the
           physical number, of course, but the number used for partition
           tables.) A reasonable value is 63.

       -w, --wipe when
           Wipe filesystem, RAID and partition-table signatures from the
           device, in order to avoid possible collisions. The argument when
           can be auto, never or always. When this option is not given, the
           default is auto, in which case signatures are wiped only when in
           interactive mode. In all cases detected signatures are reported by
           warning messages before a new partition table is created. See also
           wipefs(8) command.

       -W, --wipe-partitions when
           Wipe filesystem, RAID and partition-table signatures from a newly
           created partitions, in order to avoid possible collisions. The
           argument when can be auto, never or always. When this option is not
           given, the default is auto, in which case signatures are wiped only
           when in interactive mode and after confirmation by user. In all
           cases detected signatures are reported by warning messages before a
           new partition is created. See also wipefs(8) command.

       -V, --version
           Display version information and exit.

EXECUTION EXAMPLE:
COMMAND INPUT:
fdisk -l | head -5

COMMAND OUTPUT:
# Note: Command 'fdisk -l | head -5' not executed for safety reasons. Use with caution.

===

COMMAND: mount

DESCRIPTION: mount - mount a filesystem

USAGE: mount [-h|-V]

       mount [-l] [-t fstype]

       mount -a [-fFnrsvw] [-t fstype] [-O optlist]

       mount [-fnrsvw] [-o options] device|mountpoint

       mount [-fnrsvw] [-t fstype] [-o options] device mountpoint

       mount --bind|--rbind|--move olddir newdir

       mount
       --make-[shared|slave|private|unbindable|rshared|rslave|rprivate|runbindable]
       mountpoint

OPTIONS:
The full set of mount options used by an invocation of mount is
       determined by first extracting the mount options for the filesystem
       from the fstab table, then applying any options specified by the -o
       argument, and finally applying a -r or -w option, when present.

       The mount command does not pass all command-line options to the
       /sbin/mount.suffix mount helpers. The interface between mount and the
       mount helpers is described below in the EXTERNAL HELPERS section.

       Command-line options available for the mount command are:

       -a, --all
           Mount all filesystems (of the given types) mentioned in fstab
           (except for those whose line contains the noauto keyword). The
           filesystems are mounted following their order in fstab. The mount
           command compares filesystem source, target (and fs root for bind
           mount or btrfs) to detect already mounted filesystems. The kernel
           table with already mounted filesystems is cached during mount
           --all. This means that all duplicated fstab entries will be
           mounted.

           The correct functionality depends on /proc (to detect already
           mounted filesystems) and on /sys (to evaluate filesystem tags like
           UUID= or LABEL=). It's strongly recommended to mount /proc and /sys
           filesystems before mount -a is executed, or keep /proc and /sys at
           the beginning of fstab.

           The option --all is possible to use for remount operation too. In
           this case all filters (-t and -O) are applied to the table of
           already mounted filesystems.

           Since version 2.35 it is possible to use the command line option -o
           to alter mount options from fstab (see also --options-mode).

           Note that it is a bad practice to use mount -a for fstab checking.
           The recommended solution is findmnt --verify.

       -B, --bind
           Remount a subtree somewhere else (so that its contents are
           available in both places). See above, under Bind mounts.

       -c, --no-canonicalize
           Don't canonicalize paths. The mount command canonicalizes all paths
           (from the command line or fstab) by default. This option can be
           used together with the -f flag for already canonicalized absolute
           paths. The option is designed for mount helpers which call mount
           -i. It is strongly recommended to not use this command-line option
           for normal mount operations.

           Note that mount does not pass this option to the /sbin/mount.type
           helpers.

       -F, --fork
           (Used in conjunction with -a.) Fork off a new incarnation of mount
           for each device. This will do the mounts on different devices or
           different NFS servers in parallel. This has the advantage that it
           is faster; also NFS timeouts proceed in parallel. A disadvantage is
           that the order of the mount operations is undefined. Thus, you
           cannot use this option if you want to mount both /usr and
           /usr/spool.

       -f, --fake
           Causes everything to be done except for the actual system call; if
           it's not obvious, this "fakes" mounting the filesystem. This option
           is useful in conjunction with the -v flag to determine what the
           mount command is trying to do. It can also be used to add entries
           for devices that were mounted earlier with the -n option. The -f
           option checks for an existing record in /etc/mtab and fails when
           the record already exists (with a regular non-fake mount, this
           check is done by the kernel).

       -i, --internal-only
           Don't call the /sbin/mount.filesystem helper even if it exists.

       -L, --label label
           Mount the partition that has the specified label.

       -l, --show-labels
           Add the labels in the mount output. mount must have permission to
           read the disk device (e.g. be set-user-ID root) for this to work.
           One can set such a label for ext2, ext3 or ext4 using the
           e2label(8) utility, or for XFS using xfs_admin(8), or for reiserfs
           using reiserfstune(8).

       -M, --move
           Move a subtree to some other place. See above, the subsection The
           move operation.

       -m, --mkdir[=mode]
           Allow to make a target directory (mountpoint) if it does not exist
           yet. Alias to "-o X-mount.mkdir[=mode]", the default mode is 0755.
           For more details see X-mount.mkdir below.

       -n, --no-mtab
           Mount without writing in /etc/mtab. This is necessary for example
           when /etc is on a read-only filesystem.

       -N, --namespace ns
           Perform the mount operation in the mount namespace specified by ns.
           ns is either PID of process running in that namespace or special
           file representing that namespace.

           mount switches to the mount namespace when it reads /etc/fstab,
           writes /etc/mtab: (or writes to _/run/mount) and calls mount(2),
           otherwise it runs in the original mount namespace. This means that
           the target namespace does not have to contain any libraries or
           other requirements necessary to execute the mount(2) call.

           See mount_namespaces(7) for more information.

       -O, --test-opts opts
           Limit the set of filesystems to which the -a option applies. In
           this regard it is like the -t option except that -O is useless
           without -a. For example, the command

           mount -a -O no_netdev

           mounts all filesystems except those which have the option netdev
           specified in the options field in the /etc/fstab file.

           It is different from -t in that each option is matched exactly; a
           leading no at the beginning of one option does not negate the rest.

           The -t and -O options are cumulative in effect; that is, the
           command

           mount -a -t ext2 -O  _netdev

           mounts all ext2 filesystems with the _netdev option, not all
           filesystems that are either ext2 or have the _netdev option
           specified.

       -o, --options opts
           Use the specified mount options. The opts argument is a
           comma-separated list. For example:

           mount LABEL=mydisk -o noatime,nodev,nosuid

           For more details, see the FILESYSTEM-INDEPENDENT MOUNT OPTIONS and
           FILESYSTEM-SPECIFIC MOUNT OPTIONS sections.

       --options-mode mode
           Controls how to combine options from fstab/mtab with options from
           the command line. mode can be one of ignore, append, prepend or
           replace. For example, append means that options from fstab are
           appended to options from the command line. The default value is
           prepend -- it means command line options are evaluated after fstab
           options. Note that the last option wins if there are conflicting
           ones.

       --options-source source
           Source of default options. source is a comma-separated list of
           fstab, mtab and disable. disable disables fstab and mtab and
           enables --options-source-force. The default value is fstab,mtab.

       --options-source-force
           Use options from fstab/mtab even if both device and dir are
           specified.

       -R, --rbind
           Remount a subtree and all possible submounts somewhere else (so
           that its contents are available in both places). See above, the
           subsection Bind mounts.

       -r, --read-only
           Mount the filesystem read-only. A synonym is -o ro.

           Note that, depending on the filesystem type, state and kernel
           behavior, the system may still write to the device. For example,
           ext3 and ext4 will replay the journal if the filesystem is dirty.
           To prevent this kind of write access, you may want to mount an ext3
           or ext4 filesystem with the ro,noload mount options or set the
           block device itself to read-only mode, see the blockdev(8) command.

       -s
           Tolerate sloppy mount options rather than failing. This will ignore
           mount options not supported by a filesystem type. Not all
           filesystems support this option. Currently it's supported by the
           mount.nfs mount helper only.

       --source device
           If only one argument for the mount command is given, then the
           argument might be interpreted as the target (mountpoint) or source
           (device). This option allows you to explicitly define that the
           argument is the mount source.

       --target directory
           If only one argument for the mount command is given, then the
           argument might be interpreted as the target (mountpoint) or source
           (device). This option allows you to explicitly define that the
           argument is the mount target.

       --target-prefix directory
           Prepend the specified directory to all mount targets. This option
           can be used to follow fstab, but mount operations are done in
           another place, for example:

           mount --all --target-prefix /chroot -o X-mount.mkdir

           mounts all from system fstab to /chroot, all missing mountpoint are
           created (due to X-mount.mkdir). See also --fstab to use an
           alternative fstab.

       -T, --fstab path
           Specifies an alternative fstab file. If path is a directory, then
           the files in the directory are sorted by strverscmp(3); files that
           start with "." or without an .fstab extension are ignored. The
           option can be specified more than once. This option is mostly
           designed for initramfs or chroot scripts where additional
           configuration is specified beyond standard system configuration.

           Note that mount does not pass the option --fstab to the
           /sbin/mount.type helpers, meaning that the alternative fstab files
           will be invisible for the helpers. This is no problem for normal
           mounts, but user (non-root) mounts always require fstab to verify
           the user's rights.

       -t, --types fstype
           The argument following the -t is used to indicate the filesystem
           type. The filesystem types which are currently supported depend on
           the running kernel. See /proc/filesystems and /lib/modules/$(uname
           -r)/kernel/fs for a complete list of the filesystems. The most
           common are ext2, ext3, ext4, xfs, btrfs, vfat, sysfs, proc, nfs and
           cifs.

           The programs mount and umount(8) support filesystem subtypes. The
           subtype is defined by a '.subtype' suffix. For example
           'fuse.sshfs'. It's recommended to use subtype notation rather than
           add any prefix to the mount source (for example 'sshfs#example.com'
           is deprecated).

           If no -t option is given, or if the auto type is specified, mount
           will try to guess the desired type. mount uses the libblkid(3)
           library for guessing the filesystem type; if that does not turn up
           anything that looks familiar, mount will try to read the file
           /etc/filesystems, or, if that does not exist, /proc/filesystems.
           All of the filesystem types listed there will be tried, except for
           those that are labeled "nodev" (e.g. devpts, proc and nfs). If
           /etc/filesystems ends in a line with a single *, mount will read
           /proc/filesystems afterwards. While trying, all filesystem types
           will be mounted with the mount option silent.

           The auto type may be useful for user-mounted floppies. Creating a
           file /etc/filesystems can be useful to change the probe order
           (e.g., to try vfat before msdos or ext3 before ext2) or if you use
           a kernel module autoloader.

           More than one type may be specified in a comma-separated list, for
           the -t option as well as in an /etc/fstab entry. The list of
           filesystem types for the -t option can be prefixed with no to
           specify the filesystem types on which no action should be taken.
           The prefix no has no effect when specified in an /etc/fstab entry.

           The prefix no can be meaningful with the -a option. For example,
           the command

           mount -a -t nomsdos,smbfs

           mounts all filesystems except those of type msdos and smbfs.

           For most types all the mount program has to do is issue a simple
           mount(2) system call, and no detailed knowledge of the filesystem
           type is required. For a few types however (like nfs, nfs4, cifs,
           smbfs, ncpfs) an ad hoc code is necessary. The nfs, nfs4, cifs,
           smbfs, and ncpfs filesystems have a separate mount program. In
           order to make it possible to treat all types in a uniform way,
           mount will execute the program /sbin/mount.type (if that exists)
           when called with type type. Since different versions of the
           smbmount program have different calling conventions,
           /sbin/mount.smbfs may have to be a shell script that sets up the
           desired call.

       -U, --uuid uuid
           Mount the partition that has the specified uuid.

       -v, --verbose
           Verbose mode.

       -w, --rw, --read-write
           Mount the filesystem read/write. Read-write is the kernel default
           and the mount default is to try read-only if the previous mount(2)
           syscall with read-write flags on write-protected devices failed.

           A synonym is -o rw.

           Note that specifying -w on the command line forces mount to never
           try read-only mount on write-protected devices or already mounted
           read-only filesystems.

       -h, --help
           Display help text and exit.

       -V, --version
           Print version and exit.

EXECUTION EXAMPLE:
COMMAND INPUT:
mount | head -5

COMMAND OUTPUT:
sysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime)
proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)
udev on /dev type devtmpfs (rw,nosuid,relatime,size=1997724k,nr_inodes=499431,mode=755,inode64)
devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000)
tmpfs on /run type tmpfs (rw,nosuid,nodev,noexec,relatime,size=401892k,mode=755,inode64)

===

COMMAND: apt

DESCRIPTION: apt - command-line interface

USAGE: apt [-h] [-o=config_string] [-c=config_file] [-t=target_release]
           [-a=architecture] {list | search | show | update |
           install pkg [{=pkg_version_number | /target_release}]...  |
           remove pkg...  | upgrade | full-upgrade | edit-sources |
           {-v | --version} | {-h | --help}}

EXECUTION EXAMPLE:
COMMAND INPUT:
apt list --installed | head -5

COMMAND OUTPUT:
Listing...
adduser/stable,now 3.134 all [installed]
apparmor/stable,now 3.0.8-3 amd64 [installed]
apt-listchanges/stable,now 3.24 all [installed]
apt-utils/stable,now 2.6.1 amd64 [installed]

===

COMMAND: find

DESCRIPTION: find - search for files in a directory hierarchy

USAGE: find  [-H]  [-L] [-P] [-D debugopts] [-Olevel] [starting-point...] [ex-
       pression]

OPTIONS:
The -H, -L and -P options control  the  treatment  of  symbolic  links.
       Command-line  arguments  following these are taken to be names of files
       or directories to be examined, up to the  first  argument  that  begins
       with  `-', or the argument `(' or `!'.  That argument and any following
       arguments are taken to be the  expression  describing  what  is  to  be
       searched  for.   If  no paths are given, the current directory is used.
       If no expression is given, the  expression  -print  is  used  (but  you
       should probably consider using -print0 instead, anyway).

       This  manual  page  talks  about  `options' within the expression list.
       These options control the behaviour of find but are  specified  immedi-
       ately after the last path name.  The five `real' options -H, -L, -P, -D
       and -O must appear before the first path name, if  at  all.   A  double
       dash  -- could theoretically be used to signal that any remaining argu-
       ments are not options, but this does not really work  due  to  the  way
       find  determines  the end of the following path arguments: it does that
       by reading until an expression argument comes (which also starts with a
       `-').   Now, if a path argument would start with a `-', then find would
       treat it as expression argument instead.   Thus,  to  ensure  that  all
       start points are taken as such, and especially to prevent that wildcard
       patterns expanded by the calling shell are not  mistakenly  treated  as
       expression  arguments, it is generally safer to prefix wildcards or du-
       bious path names with either `./' or to use absolute path names  start-
       ing  with '/'.  Alternatively, it is generally safe though non-portable
       to use the GNU option -files0-from to pass arbitrary starting points to
       find.

       -P     Never  follow  symbolic  links.   This is the default behaviour.
              When find examines or prints information about  files,  and  the
              file  is  a  symbolic  link, the information used shall be taken
              from the properties of the symbolic link itself.

       -L     Follow symbolic links.  When find examines or prints information
              about  files, the information used shall be taken from the prop-
              erties of the file to which the link points, not from  the  link
              itself (unless it is a broken symbolic link or find is unable to
              examine the file to which the link points).  Use of this  option
              implies  -noleaf.   If you later use the -P option, -noleaf will
              still be in effect.  If -L is in effect  and  find  discovers  a
              symbolic link to a subdirectory during its search, the subdirec-
              tory pointed to by the symbolic link will be searched.

              When the -L option is in effect, the -type predicate will always
              match  against  the type of the file that a symbolic link points
              to rather than the link itself (unless the symbolic link is bro-
              ken).   Actions  that  can cause symbolic links to become broken
              while find is executing (for example -delete) can give  rise  to
              confusing  behaviour.   Using  -L  causes the -lname and -ilname
              predicates always to return false.

       -H     Do not follow symbolic links, except while processing  the  com-
              mand  line  arguments.  When find examines or prints information
              about files, the information used shall be taken from the  prop-
              erties  of the symbolic link itself.  The only exception to this
              behaviour is when a file specified on the command line is a sym-
              bolic  link,  and the link can be resolved.  For that situation,
              the information used is taken from whatever the link  points  to
              (that is, the link is followed).  The information about the link
              itself is used as a fallback if the file pointed to by the  sym-
              bolic  link  cannot  be examined.  If -H is in effect and one of
              the paths specified on the command line is a symbolic link to  a
              directory,  the  contents  of  that  directory  will be examined
              (though of course -maxdepth 0 would prevent this).

       If more than one of -H, -L and -P is specified, each overrides the oth-
       ers; the last one appearing on the command line takes effect.  Since it
       is the default, the -P option should be considered to be in effect  un-
       less either -H or -L is specified.

       GNU  find  frequently  stats files during the processing of the command
       line itself, before any searching has begun.  These options also affect
       how those arguments are processed.  Specifically, there are a number of
       tests that compare files listed on the command line against a  file  we
       are  currently  considering.   In  each case, the file specified on the
       command line will have been examined and some of  its  properties  will
       have been saved.  If the named file is in fact a symbolic link, and the
       -P option is in effect (or if neither -H nor -L  were  specified),  the
       information  used  for the comparison will be taken from the properties
       of the symbolic link.  Otherwise, it will be taken from the  properties
       of  the  file  the link points to.  If find cannot follow the link (for
       example because it has insufficient privileges or the link points to  a
       nonexistent file) the properties of the link itself will be used.

       When  the  -H or -L options are in effect, any symbolic links listed as
       the argument of -newer will be dereferenced, and the timestamp will  be
       taken  from  the file to which the symbolic link points.  The same con-
       sideration applies to -newerXY, -anewer and -cnewer.

       The -follow option has a similar effect to -L, though it  takes  effect
       at  the  point where it appears (that is, if -L is not used but -follow
       is, any symbolic links appearing after -follow on the command line will
       be dereferenced, and those before it will not).

       -D debugopts
              Print  diagnostic  information;  this can be helpful to diagnose
              problems with why find is not doing what you want.  The list  of
              debug  options  should be comma separated.  Compatibility of the
              debug options is not guaranteed between releases  of  findutils.
              For  a  complete  list of valid debug options, see the output of
              find -D help.  Valid debug options include

              exec   Show diagnostic information relating to -exec,  -execdir,
                     -ok and -okdir

              opt    Prints  diagnostic  information relating to the optimisa-
                     tion of the expression tree; see the -O option.

              rates  Prints a summary indicating how often each predicate suc-
                     ceeded or failed.

              search Navigate the directory tree verbosely.

              stat   Print  messages  as  files are examined with the stat and
                     lstat system calls.  The find program tries  to  minimise
                     such calls.

              tree   Show  the  expression  tree in its original and optimised
                     form.

              all    Enable all of the other debug options (but help).

              help   Explain the debugging options.

       -Olevel
              Enables query optimisation.  The find program reorders tests  to
              speed up execution while preserving the overall effect; that is,
              predicates with side effects are not reordered relative to  each
              other.   The  optimisations performed at each optimisation level
              are as follows.

              0      Equivalent to optimisation level 1.

              1      This is the default optimisation level and corresponds to
                     the  traditional behaviour.  Expressions are reordered so
                     that tests based only on the names of files (for  example
                     -name and -regex) are performed first.

              2      Any  -type  or -xtype tests are performed after any tests
                     based only on the names of files, but  before  any  tests
                     that  require information from the inode.  On many modern
                     versions of Unix, file types are  returned  by  readdir()
                     and so these predicates are faster to evaluate than pred-
                     icates which need to stat the file first.  If you use the
                     -fstype FOO  predicate  and specify a filesystem type FOO
                     which is not known (that is, present in  `/etc/mtab')  at
                     the  time  find  starts,  that predicate is equivalent to
                     -false.

              3      At this optimisation level, the full cost-based query op-
                     timiser  is  enabled.   The order of tests is modified so
                     that cheap (i.e. fast) tests are performed first and more
                     expensive ones are performed later, if necessary.  Within
                     each cost band, predicates are evaluated earlier or later
                     according  to  whether they are likely to succeed or not.
                     For -o, predicates which are likely to succeed are evalu-
                     ated  earlier, and for -a, predicates which are likely to
                     fail are evaluated earlier.

              The cost-based optimiser has a fixed  idea  of  how  likely  any
              given  test  is to succeed.  In some cases the probability takes
              account of the specific nature of the test (for example, -type f
              is  assumed  to  be  more  likely to succeed than -type c).  The
              cost-based optimiser is currently being evaluated.  If  it  does
              not actually improve the performance of find, it will be removed
              again.  Conversely, optimisations that prove to be reliable, ro-
              bust  and  effective may be enabled at lower optimisation levels
              over time.  However, the default  behaviour  (i.e.  optimisation
              level  1)  will not be changed in the 4.3.x release series.  The
              findutils test suite runs all the tests on find at each  optimi-
              sation level and ensures that the result is the same.

EXECUTION EXAMPLE:
COMMAND INPUT:
find /etc -name "*.conf" -type f | head -5

COMMAND OUTPUT:
/etc/mke2fs.conf
/etc/ld.so.conf
/etc/sudo.conf
/etc/e2scrub.conf
/etc/needrestart/needrestart.conf

===

COMMAND: locate

DESCRIPTION: plocate - find files by name, quickly

USAGE: plocate [OPTION]...  PATTERN...

OPTIONS:
-A, --all
              Ignored for compatibility with mlocate(1).

       -b, --basename
              Match only against the file name portion of the path name,  ie.,
              the  directory  names will be excluded from the match (but still
              printed). This does not speed up the search,  but  can  suppress
              uninteresting matches.

       -c, --count
              Do  not  print  each match. Instead, count them, and print out a
              total number at the end.

       -d, --database DBPATH
              Find matches in the given  database,  instead  of  /var/lib/plo-
              cate/plocate.db.   This argument can be given multiple times, to
              search multiple databases.  It is also possible to give multiple
              databases  in one argument, separated by :.  (Any character, in-
              cluding : and \, can be escaped by prepending a \.)

       -e, --existing
              Print only entries that refer to files existing at the time  lo-
              cate  is run. Note that unlike mlocate(1), symlinks are not fol-
              lowed by default (and indeed,  there  is  no  option  to  change
              this).

       -i, --ignore-case
              Do  a case-insensitive match as given by the current locale (de-
              fault is case-sensitive, byte-by-byte match). Note that  plocate
              does  not  support the full range of Unicode case folding rules;
              in particular, searching for  will not give you  matches  on  ss
              even  in  a  German  locale.  Also note that this option will be
              somewhat slower than a case-sensitive match, since it  needs  to
              generate more candidates for searching the index.

       -l, --limit LIMIT
              Stop  searching  after LIMIT matches have been found. If --count
              is given, the number printed out will be at most LIMIT.

       -N, --literal
              Print entry names without quoting. Normally, plocate will escape
              special  characters in filenames, so that they are safe for con-
              sumption by typical shells (similar to the GNU coreutils  shell-
              escape-always  quoting  style),  unless  printing to a pipe, but
              this options will turn off such quoting.

       -0, --null
              Instead of writing a newline after  every  match,  write  a  NUL
              (ASCII  0).  This is useful for creating unambiguous output when
              it is to be processed by other tools (like xargs(1)),  as  file-
              names are allowed to contain embedded newlines.

       -r, --regexp
              Patterns  are  taken to be POSIX basic regular expressions.  See
              regex(7) for more information. Note that this  forces  a  linear
              scan through the entire database, which is slow.

       --regex
              Like  --regexp,  but  patterns are instead taken to be POSIX ex-
              tended regular expressions.

       -w, --wholename
              Match against the entire path name. This is the default, so  un-
              less  -b  is  given  first (see above), it will not do anything.
              This option thus exists only as compatibility with mlocate(1).

       --help Print out usage information, then exit successfully.

       --version
              Print out version information, then exit successfully.

EXECUTION EXAMPLE:
COMMAND INPUT:
locate passwd | head -3

COMMAND OUTPUT:
/var/lib/plocate/plocate.db: No such file or directory

===

COMMAND: tar

DESCRIPTION: tar - an archiving utility

USAGE: Traditional usage
       tar {A|c|d|r|t|u|x}[GnSkUWOmpsMBiajJzZhPlRvwo] [ARG...]

   UNIX-style usage
       tar -A [OPTIONS] ARCHIVE ARCHIVE

       tar -c [-f ARCHIVE] [OPTIONS] [FILE...]

       tar -d [-f ARCHIVE] [OPTIONS] [FILE...]

       tar -t [-f ARCHIVE] [OPTIONS] [MEMBER...]

       tar -r [-f ARCHIVE] [OPTIONS] [FILE...]

       tar -u [-f ARCHIVE] [OPTIONS] [FILE...]

       tar -x [-f ARCHIVE] [OPTIONS] [MEMBER...]

   GNU-style usage
       tar {--catenate|--concatenate} [OPTIONS] ARCHIVE ARCHIVE

       tar --create [--file ARCHIVE] [OPTIONS] [FILE...]

       tar {--diff|--compare} [--file ARCHIVE] [OPTIONS] [FILE...]

       tar --delete [--file ARCHIVE] [OPTIONS] [MEMBER...]

       tar --append [-f ARCHIVE] [OPTIONS] [FILE...]

       tar --list [-f ARCHIVE] [OPTIONS] [MEMBER...]

       tar --test-label [--file ARCHIVE] [OPTIONS] [LABEL...]

       tar --update [--file ARCHIVE] [OPTIONS] [FILE...]

       tar --update [-f ARCHIVE] [OPTIONS] [FILE...]

       tar {--extract|--get} [-f ARCHIVE] [OPTIONS] [MEMBER...]

OPTIONS:
Operation modifiers
       --check-device
              Check  device  numbers  when  creating incremental archives (de-
              fault).

       -g, --listed-incremental=FILE
              Handle new GNU-format incremental backups.  FILE is the name  of
              a  snapshot  file, where tar stores additional information which
              is used to decide which files changed since the previous  incre-
              mental  dump  and,  consequently, must be dumped again.  If FILE
              does not exist when creating an archive, it will be created  and
              all  files  will  be added to the resulting archive (the level 0
              dump).  To create incremental archives of non-zero level N, cre-
              ate  a  copy  of the snapshot file created during the level N-1,
              and use it as FILE.

              When listing or extracting, the actual contents of FILE  is  not
              inspected,  it  is  needed only due to syntactical requirements.
              It is therefore common practice to use /dev/null in its place.

       --hole-detection=METHOD
              Use METHOD to detect holes in sparse files.  This option implies
              --sparse.  Valid values for METHOD are seek and raw.  Default is
              seek with fallback to raw when not applicable.

       -G, --incremental
              Handle old GNU-format incremental backups.

       --ignore-failed-read
              Do not exit with nonzero on unreadable files.

       --level=NUMBER
              Set dump level for  created  listed-incremental  archive.   Cur-
              rently  only  --level=0 is meaningful: it instructs tar to trun-
              cate the snapshot file before dumping, thereby forcing a level 0
              dump.

       -n, --seek
              Assume  the  archive is seekable.  Normally tar determines auto-
              matically whether the archive can be seeked or not.  This option
              is  intended  for  use in cases when such recognition fails.  It
              takes effect only if the archive is open for reading (e.g.  with
              --list or --extract options).

       --no-check-device
              Do not check device numbers when creating incremental archives.

       --no-seek
              Assume the archive is not seekable.

       --occurrence[=N]
              Process  only  the  Nth  occurrence of each file in the archive.
              This option is valid only when used with one  of  the  following
              subcommands:  --delete,  --diff,  --extract or --list and when a
              list of files is given either on the command line or via the  -T
              option.  The default N is 1.

       --restrict
              Disable the use of some potentially harmful options.

       --sparse-version=MAJOR[.MINOR]
              Set  version  of  the  sparse  format to use (implies --sparse).
              This option implies --sparse.  Valid argument  values  are  0.0,
              0.1,  and 1.0.  For a detailed discussion of sparse formats, re-
              fer to the GNU Tar Manual, appendix D, "Sparse Formats".   Using
              info  reader,  it can be accessed running the following command:
              info tar 'Sparse Formats'.

       -S, --sparse
              Handle sparse files efficiently.  Some files in the file  system
              may have segments which were actually never written (quite often
              these are database files created by such systems as DBM).   When
              given  this  option,  tar  attempts  to determine if the file is
              sparse prior to archiving it, and if so, to reduce the resulting
              archive size by not dumping empty parts of the file.

   Overwrite control
       These options control tar actions when extracting a file over an exist-
       ing copy on disk.

       -k, --keep-old-files
              Don't replace existing files when extracting.

       --keep-newer-files
              Don't replace existing files that are newer than  their  archive
              copies.

       --keep-directory-symlink
              Don't replace existing symlinks to directories when extracting.

       --no-overwrite-dir
              Preserve metadata of existing directories.

       --one-top-level[=DIR]
              Extract all files into DIR, or, if used without argument, into a
              subdirectory named by the base name of the archive (minus  stan-
              dard compression suffixes recognizable by --auto-compress).

       --overwrite
              Overwrite existing files when extracting.

       --overwrite-dir
              Overwrite  metadata of existing directories when extracting (de-
              fault).

       --recursive-unlink
              Recursively remove all files in the directory prior to  extract-
              ing it.

       --remove-files
              Remove files from disk after adding them to the archive.

       --skip-old-files
              Don't replace existing files when extracting, silently skip over
              them.

       -U, --unlink-first
              Remove each file prior to extracting over it.

       -W, --verify
              Verify the archive after writing it.

   Output stream selection
       --ignore-command-error

       Ignore subprocess exit codes.

       --no-ignore-command-error
              Treat non-zero exit codes of children as error (default).

       -O, --to-stdout
              Extract files to standard output.

       --to-command=COMMAND
              Pipe extracted files to COMMAND.  The argument is  the  pathname
              of  an external program, optionally with command line arguments.
              The program will be invoked and the contents of the  file  being
              extracted supplied to it on its standard input.  Additional data
              will be supplied via the following environment variables:

              TAR_FILETYPE
                     Type of the file. It is a single letter with the  follow-
                     ing meaning:

                             f           Regular file
                             d           Directory
                             l           Symbolic link
                             h           Hard link
                             b           Block device
                             c           Character device

                     Currently only regular files are supported.

              TAR_MODE
                     File mode, an octal number.

              TAR_FILENAME
                     The name of the file.

              TAR_REALNAME
                     Name of the file as stored in the archive.

              TAR_UNAME
                     Name of the file owner.

              TAR_GNAME
                     Name of the file owner group.

              TAR_ATIME
                     Time of last access. It is a decimal number, representing
                     seconds since the Epoch.  If the archive  provides  times
                     with  nanosecond  precision, the nanoseconds are appended
                     to the timestamp after a decimal point.

              TAR_MTIME
                     Time of last modification.

              TAR_CTIME
                     Time of last status change.

              TAR_SIZE
                     Size of the file.

              TAR_UID
                     UID of the file owner.

              TAR_GID
                     GID of the file owner.

              Additionally, the following variables contain information  about
              tar operation mode and the archive being processed:

              TAR_VERSION
                     GNU tar version number.

              TAR_ARCHIVE
                     The name of the archive tar is processing.

              TAR_BLOCKING_FACTOR
                     Current  blocking  factor, i.e. number of 512-byte blocks
                     in a record.

              TAR_VOLUME
                     Ordinal number of the volume tar is  processing  (set  if
                     reading a multi-volume archive).

              TAR_FORMAT
                     Format  of  the  archive  being  processed.  One of: gnu,
                     oldgnu, posix, ustar, v7.

              TAR_SUBCOMMAND
                     A short option (with a leading dash) describing the oper-
                     ation tar is executing.

   Handling of file attributes
       --atime-preserve[=METHOD]
              Preserve  access  times on dumped files, either by restoring the
              times after reading (METHOD=replace, this is the default) or  by
              not setting the times in the first place (METHOD=system)

       --delay-directory-restore
              Delay  setting  modification  times and permissions of extracted
              directories until the end of extraction.  Use this  option  when
              extracting from an archive which has unusual member ordering.

       --group=NAME[:GID]
              Force  NAME  as  group for added files.  If GID is not supplied,
              NAME can be either a user name or numeric GID.  In this case the
              missing  part  (GID  or  name) will be inferred from the current
              host's group database.

              When used with --group-map=FILE, affects only those files  whose
              owner group is not listed in FILE.

       --group-map=FILE
              Read  group translation map from FILE.  Empty lines are ignored.
              Comments are introduced with # sign and extend  to  the  end  of
              line.   Each  non-empty  line  in FILE defines translation for a
              single group.  It must consist of two fields, delimited  by  any
              amount of whitespace:

              OLDGRP NEWGRP[:NEWGID]

              OLDGRP  is  either  a valid group name or a GID prefixed with +.
              Unless NEWGID is supplied, NEWGRP must also be  either  a  valid
              group  name  or  a +GID.  Otherwise, both NEWGRP and NEWGID need
              not be listed in the system group database.

              As a result, each input file with owner  group  OLDGRP  will  be
              stored in archive with owner group NEWGRP and GID NEWGID.

       --mode=CHANGES
              Force symbolic mode CHANGES for added files.

       --mtime=DATE-OR-FILE
              Set  mtime  for added files.  DATE-OR-FILE is either a date/time
              in almost arbitrary format, or the name of an existing file.  In
              the latter case the mtime of that file will be used.

       -m, --touch
              Don't extract file modified time.

       --no-delay-directory-restore
              Cancel the effect of the prior --delay-directory-restore option.

       --no-same-owner
              Extract files as yourself (default for ordinary users).

       --no-same-permissions
              Apply  the user's umask when extracting permissions from the ar-
              chive (default for ordinary users).

       --numeric-owner
              Always use numbers for user/group names.

       --owner=NAME[:UID]
              Force NAME as owner for added files.  If UID  is  not  supplied,
              NAME can be either a user name or numeric UID.  In this case the
              missing part (UID or name) will be  inferred  from  the  current
              host's user database.

              When  used with --owner-map=FILE, affects only those files whose
              owner is not listed in FILE.

       --owner-map=FILE
              Read owner translation map from FILE.  Empty lines are  ignored.
              Comments  are  introduced  with  # sign and extend to the end of
              line.  Each non-empty line in FILE  defines  translation  for  a
              single  UID.   It  must  consist of two fields, delimited by any
              amount of whitespace:

              OLDUSR NEWUSR[:NEWUID]

              OLDUSR is either a valid user name or a  UID  prefixed  with  +.
              Unless  NEWUID  is  supplied, NEWUSR must also be either a valid
              user name or a +UID.  Otherwise, both NEWUSR and NEWUID need not
              be listed in the system user database.

              As  a  result, each input file owned by OLDUSR will be stored in
              archive with owner name NEWUSR and UID NEWUID.

       -p, --preserve-permissions, --same-permissions
              extract information about file permissions  (default  for  supe-
              ruser)

       --same-owner
              Try  extracting  files  with the same ownership as exists in the
              archive (default for superuser).

       -s, --preserve-order, --same-order
              Sort names to extract to match archive

       --sort=ORDER
              When creating an archive, sort directory  entries  according  to
              ORDER, which is one of none, name, or inode.

              The  default is --sort=none, which stores archive members in the
              same order as returned by the operating system.

              Using --sort=name ensures the member ordering in the created ar-
              chive is uniform and reproducible.

              Using  --sort=inode  reduces  the number of disk seeks made when
              creating the archive and thus can considerably speed up archiva-
              tion.   This  sorting  order is supported only if the underlying
              system provides the necessary information.

   Extended file attributes
       --acls Enable POSIX ACLs support.

       --no-acls
              Disable POSIX ACLs support.

       --selinux
              Enable SELinux context support.

       --no-selinux
              Disable SELinux context support.

       --xattrs
              Enable extended attributes support.

       --no-xattrs
              Disable extended attributes support.

       --xattrs-exclude=PATTERN
              Specify the exclude pattern for xattr keys.  PATTERN is a  POSIX
              regular  expression,  e.g. --xattrs-exclude='^user.', to exclude
              attributes from the user namespace.

       --xattrs-include=PATTERN
              Specify the include pattern for xattr keys.  PATTERN is a  POSIX
              regular expression.

   Device selection and switching
       -f, --file=ARCHIVE
              Use  archive  file  or  device  ARCHIVE.   If this option is not
              given, tar will first examine the environment  variable  `TAPE'.
              If  it is set, its value will be used as the archive name.  Oth-
              erwise, tar will assume the compiled-in  default.   The  default
              value  can be inspected either using the --show-defaults option,
              or at the end of the tar --help output.

              An archive name that has a colon in it specifies a file  or  de-
              vice on a remote machine.  The part before the colon is taken as
              the machine name or IP address, and the part  after  it  as  the
              file or device pathname, e.g.:

              --file=remotehost:/dev/sr0

              An  optional username can be prefixed to the hostname, placing a
              @ sign between them.

              By default, the remote host is accessed via the rsh(1)  command.
              Nowadays  it  is common to use ssh(1) instead.  You can do so by
              giving the following command line option:

              --rsh-command=/usr/bin/ssh

              The remote machine should have the rmt(8) command installed.  If
              its  pathname  does  not match tar's default, you can inform tar
              about the correct pathname using the --rmt-command option.

       --force-local
              Archive file is local even if it has a colon.

       -F, --info-script=COMMAND, --new-volume-script=COMMAND
              Run COMMAND at the end of each tape (implies -M).   The  command
              can  include arguments.  When started, it will inherit tar's en-
              vironment plus the following variables:

              TAR_VERSION
                     GNU tar version number.

              TAR_ARCHIVE
                     The name of the archive tar is processing.

              TAR_BLOCKING_FACTOR
                     Current blocking factor, i.e. number of  512-byte  blocks
                     in a record.

              TAR_VOLUME
                     Ordinal  number  of  the volume tar is processing (set if
                     reading a multi-volume archive).

              TAR_FORMAT
                     Format of the archive  being  processed.   One  of:  gnu,
                     oldgnu, posix, ustar, v7.

              TAR_SUBCOMMAND
                     A short option (with a leading dash) describing the oper-
                     ation tar is executing.

              TAR_FD File descriptor which can be used to communicate the  new
                     volume name to tar.

              If  the info script fails, tar exits; otherwise, it begins writ-
              ing the next volume.

       -L, --tape-length=N
              Change tape after writing Nx1024 bytes.  If N is followed  by  a
              size suffix (see the subsection Size suffixes below), the suffix
              specifies the multiplicative factor to be used instead of 1024.

              This option implies -M.

       -M, --multi-volume
              Create/list/extract multi-volume archive.

       --rmt-command=COMMAND
              Use COMMAND instead of rmt when accessing remote archives.   See
              the description of the -f option, above.

       --rsh-command=COMMAND
              Use  COMMAND instead of rsh when accessing remote archives.  See
              the description of the -f option, above.

       --volno-file=FILE
              When this option is used in conjunction with --multi-volume, tar
              will  keep track of which volume of a multi-volume archive it is
              working in FILE.

   Device blocking
       -b, --blocking-factor=BLOCKS
              Set record size to BLOCKSx512 bytes.

       -B, --read-full-records
              When listing or extracting, accept incomplete input records  af-
              ter end-of-file marker.

       -i, --ignore-zeros
              Ignore  zeroed  blocks  in  archive.   Normally  two consecutive
              512-blocks filled with zeroes mean EOF and tar stops reading af-
              ter encountering them.  This option instructs it to read further
              and is useful when reading archives created with the -A option.

       --record-size=NUMBER
              Set record size.  NUMBER is the number of bytes per record.   It
              must  be  multiple  of  512.  It can can be suffixed with a size
              suffix, e.g. --record-size=10K, for 10 Kilobytes.  See the  sub-
              section Size suffixes, for a list of valid suffixes.

   Archive format selection
       -H, --format=FORMAT
              Create archive of the given format.  Valid formats are:

              gnu    GNU tar 1.13.x format

              oldgnu GNU format as per tar <= 1.12.

              pax, posix
                     POSIX 1003.1-2001 (pax) format.

              ustar  POSIX 1003.1-1988 (ustar) format.

              v7     Old V7 tar format.

       --old-archive, --portability
              Same as --format=v7.

       --pax-option=keyword[[:]=value][,keyword[[:]=value]]...
              Control  pax keywords when creating PAX archives (-H pax).  This
              option is equivalent to the -o option of the pax(1) utility.

       --posix
              Same as --format=posix.

       -V, --label=TEXT
              Create archive with volume name TEXT.  If listing or extracting,
              use TEXT as a globbing pattern for volume name.

   Compression options
       -a, --auto-compress
              Use archive suffix to determine the compression program.

       -I, --use-compress-program=COMMAND
              Filter  data through COMMAND.  It must accept the -d option, for
              decompression.  The argument can contain command line options.

       -j, --bzip2
              Filter the archive through bzip2(1).

       -J, --xz
              Filter the archive through xz(1).

       --lzip Filter the archive through lzip(1).

       --lzma Filter the archive through lzma(1).

       --lzop Filter the archive through lzop(1).

       --no-auto-compress
              Do not use archive suffix to determine the compression program.

       -z, --gzip, --gunzip, --ungzip
              Filter the archive through gzip(1).

       -Z, --compress, --uncompress
              Filter the archive through compress(1).

       --zstd Filter the archive through zstd(1).

   Local file selection
       --add-file=FILE
              Add FILE to the archive (useful if its name starts with a dash).

       --backup[=CONTROL]
              Backup before removal.  The CONTROL argument, if supplied,  con-
              trols the backup policy.  Its valid values are:

              none, off
                     Never make backups.

              t, numbered
                     Make numbered backups.

              nil, existing
                     Make  numbered  backups if numbered backups exist, simple
                     backups otherwise.

              never, simple
                     Always make simple backups

              If CONTROL is not given,  the  value  is  taken  from  the  VER-
              SION_CONTROL  environment  variable.  If it is not set, existing
              is assumed.

       -C, --directory=DIR
              Change to DIR before performing any operations.  This option  is
              order-sensitive, i.e. it affects all options that follow.

       --exclude=PATTERN
              Exclude  files  matching  PATTERN, a glob(3)-style wildcard pat-
              tern.

       --exclude-backups
              Exclude backup and lock files.

       --exclude-caches
              Exclude contents of directories  containing  file  CACHEDIR.TAG,
              except for the tag file itself.

       --exclude-caches-all
              Exclude  directories  containing  file CACHEDIR.TAG and the file
              itself.

       --exclude-caches-under
              Exclude everything under directories containing CACHEDIR.TAG

       --exclude-ignore=FILE
              Before dumping a directory, see if it  contains  FILE.   If  so,
              read  exclusion  patterns  from  this file.  The patterns affect
              only the directory itself.

       --exclude-ignore-recursive=FILE
              Same as --exclude-ignore, except that patterns from FILE  affect
              both the directory and all its subdirectories.

       --exclude-tag=FILE
              Exclude contents of directories containing FILE, except for FILE
              itself.

       --exclude-tag-all=FILE
              Exclude directories containing FILE.

       --exclude-tag-under=FILE
              Exclude everything under directories containing FILE.

       --exclude-vcs
              Exclude version control system directories.

       --exclude-vcs-ignores
              Exclude files that match patterns read from VCS-specific  ignore
              files.  Supported files are: .cvsignore, .gitignore, .bzrignore,
              and .hgignore.

       -h, --dereference
              Follow symlinks; archive and dump the files they point to.

       --hard-dereference
              Follow hard links; archive and dump the files they refer to.

       -K, --starting-file=MEMBER
              Begin at the given member in the archive.

       --newer-mtime=DATE
              Work on files whose data changed after the DATE.  If DATE starts
              with  /  or  .  it is taken to be a file name; the mtime of that
              file is used as the date.

       --no-null
              Disable the effect of the previous --null option.

       --no-recursion
              Avoid descending automatically in directories.

       --no-unquote
              Do not unquote input file or member names.

       --no-verbatim-files-from
              Treat each line read from a file list as if it were supplied  in
              the  command line.  I.e., leading and trailing whitespace is re-
              moved and, if the resulting string begins with  a  dash,  it  is
              treated as tar command line option.

              This  is the default behavior.  The --no-verbatim-files-from op-
              tion  is  provided  as  a  way  to  restore  it  after  --verba-
              tim-files-from option.

              This  option  is positional: it affects all --files-from options
              that occur after it in, until  --verbatim-files-from  option  or
              end of line, whichever occurs first.

              It is implied by the --no-null option.

       --null Instruct  subsequent  -T  options  to read null-terminated names
              verbatim (disables special handling of names that start  with  a
              dash).

              See also --verbatim-files-from.

       -N, --newer=DATE, --after-date=DATE
              Only store files newer than DATE.  If DATE starts with / or . it
              is taken to be a file name; the mtime of that file  is  used  as
              the date.

       --one-file-system
              Stay in local file system when creating archive.

       -P, --absolute-names
              Don't  strip  leading  slashes from file names when creating ar-
              chives.

       --recursion
              Recurse into directories (default).

       --suffix=STRING
              Backup before removal, override usual suffix.  Default suffix is
              ~,  unless overridden by environment variable SIMPLE_BACKUP_SUF-
              FIX.

       -T, --files-from=FILE
              Get names to extract or create from FILE.

              Unless specified otherwise, the FILE  must  contain  a  list  of
              names separated by ASCII LF (i.e. one name per line).  The names
              read are handled the same way as command line  arguments.   They
              undergo  quote  removal  and word splitting, and any string that
              starts with a - is handled as tar command line option.

              If this behavior is undesirable, it can be turned off using  the
              --verbatim-files-from option.

              The --null option instructs tar that the names in FILE are sepa-
              rated by ASCII NUL character, instead of LF.  It  is  useful  if
              the list is generated by find(1) -print0 predicate.

       --unquote
              Unquote file or member names (default).

       --verbatim-files-from
              Treat  each  line obtained from a file list as a file name, even
              if it starts with a dash.  File  lists  are  supplied  with  the
              --files-from  (-T)  option.   The  default behavior is to handle
              names supplied in file lists as if they were typed in  the  com-
              mand  line,  i.e.  any names starting with a dash are treated as
              tar options.  The --verbatim-files-from option disables this be-
              havior.

              This option affects all --files-from options that occur after it
              in the command line.  Its effect is reverted by the  --no-verba-
              tim-files-from} option.

              This option is implied by the --null option.

              See also --add-file.

       -X, --exclude-from=FILE
              Exclude files matching patterns listed in FILE.

   File name transformations
       --strip-components=NUMBER
              Strip NUMBER leading components from file names on extraction.

       --transform=EXPRESSION, --xform=EXPRESSION
              Use sed replace EXPRESSION to transform file names.

   File name matching options
       These options affect both exclude and include patterns.

       --anchored
              Patterns match file name start.

       --ignore-case
              Ignore case.

       --no-anchored
              Patterns match after any / (default for exclusion).

       --no-ignore-case
              Case sensitive matching (default).

       --no-wildcards
              Verbatim string matching.

       --no-wildcards-match-slash
              Wildcards do not match /.

       --wildcards
              Use wildcards (default for exclusion).

       --wildcards-match-slash
              Wildcards match / (default for exclusion).

   Informative output
       --checkpoint[=N]
              Display progress messages every Nth record (default 10).

       --checkpoint-action=ACTION
              Run ACTION on each checkpoint.

       --clamp-mtime
              Only  set  time when the file is more recent than what was given
              with --mtime.

       --full-time
              Print file time to its full resolution.

       --index-file=FILE
              Send verbose output to FILE.

       -l, --check-links
              Print a message if not all links are dumped.

       --no-quote-chars=STRING
              Disable quoting for characters from STRING.

       --quote-chars=STRING
              Additionally quote characters from STRING.

       --quoting-style=STYLE
              Set quoting style for file and member names.  Valid  values  for
              STYLE  are literal, shell, shell-always, c, c-maybe, escape, lo-
              cale, clocale.

       -R, --block-number
              Show block number within archive with each message.

       --show-omitted-dirs
              When listing or extracting, list each directory  that  does  not
              match search criteria.

       --show-transformed-names, --show-stored-names
              Show  file  or archive names after transformation by --strip and
              --transform options.

       --totals[=SIGNAL]
              Print total bytes after processing the archive.   If  SIGNAL  is
              given, print total bytes when this signal is delivered.  Allowed
              signals are: SIGHUP, SIGQUIT, SIGINT, SIGUSR1, and SIGUSR2.  The
              SIG prefix can be omitted.

       --utc  Print file modification times in UTC.

       -v, --verbose
              Verbosely list files processed.  Each instance of this option on
              the command line increases the verbosity level by one.  The max-
              imum  verbosity  level  is  3.  For a detailed discussion of how
              various verbosity levels affect tar's output,  please  refer  to
              GNU Tar Manual, subsection 2.5.1 "The --verbose Option".

       --warning=KEYWORD
              Enable  or  disable warning messages identified by KEYWORD.  The
              messages are suppressed if KEYWORD is prefixed with no- and  en-
              abled otherwise.

              Multiple --warning messages accumulate.

              Keywords controlling general tar operation:

              all    Enable all warning messages.  This is the default.

              none   Disable all warning messages.

              filename-with-nuls
                     "%s: file name read contains nul character"

              alone-zero-block
                     "A lone zero block at %s"

              Keywords applicable for tar --create:

              cachedir
                     "%s: contains a cache directory tag %s; %s"

              file-shrank
                     "%s: File shrank by %s bytes; padding with zeros"

              xdev   "%s: file is on a different filesystem; not dumped"

              file-ignored
                     "%s: Unknown file type; file ignored"
                     "%s: socket ignored"
                     "%s: door ignored"

              file-unchanged
                     "%s: file is unchanged; not dumped"

              ignore-archive
                     "%s: file is the archive; not dumped"

              file-removed
                     "%s: File removed before we read it"

              file-changed
                     "%s: file changed as we read it"

              failed-read
                     Suppresses  warnings  about  unreadable files or directo-
                     ries. This keyword applies only if used together with the
                     --ignore-failed-read option.

              Keywords applicable for tar --extract:

              existing-file
                     "%s: skipping existing file"

              timestamp
                     "%s: implausibly old time stamp %s"
                     "%s: time stamp %s is %s s in the future"

              contiguous-cast
                     "Extracting contiguous files as regular files"

              symlink-cast
                     "Attempting extraction of symbolic links as hard links"

              unknown-cast
                     "%s: Unknown file type '%c', extracted as normal file"

              ignore-newer
                     "Current %s is newer or same age"

              unknown-keyword
                     "Ignoring unknown extended header keyword '%s'"

              decompress-program
                     Controls  verbose  description of failures occurring when
                     trying to run alternative  decompressor  programs.   This
                     warning  is  disabled  by  default  (unless  --verbose is
                     used).  A common example of what you can get  when  using
                     this warning is:

                     $ tar --warning=decompress-program -x -f archive.Z
                     tar (child): cannot run compress: No such file or directory
                     tar (child): trying gzip

                     This  means  that tar first tried to decompress archive.Z
                     using compress, and, when that failed, switched to gzip.

              record-size
                     "Record size = %lu blocks"

              Keywords controlling incremental extraction:

              rename-directory
                     "%s: Directory has been renamed from %s"
                     "%s: Directory has been renamed"

              new-directory
                     "%s: Directory is new"

              xdev   "%s: directory is on a different device: not purging"

              bad-dumpdir
                     "Malformed dumpdir: 'X' never used"

       -w, --interactive, --confirmation
              Ask for confirmation for every action.

   Compatibility options
       -o     When creating, same as --old-archive.  When extracting, same  as
              --no-same-owner.

   Size suffixes
               Suffix    Units                   Byte Equivalent
               b         Blocks                  SIZE x 512
               B         Kilobytes               SIZE x 1024
               c         Bytes                   SIZE
               G         Gigabytes               SIZE x 1024^3
               K         Kilobytes               SIZE x 1024
               k         Kilobytes               SIZE x 1024
               M         Megabytes               SIZE x 1024^2
               P         Petabytes               SIZE x 1024^5
               T         Terabytes               SIZE x 1024^4
               w         Words                   SIZE x 2

EXECUTION EXAMPLE:
COMMAND INPUT:
tar --version

COMMAND OUTPUT:
tar (GNU tar) 1.34
Copyright (C) 2021 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <https://gnu.org/licenses/gpl.html>.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Written by John Gilmore and Jay Fenlason.

===

COMMAND: gzip

DESCRIPTION: gzip, gunzip, zcat - compress or expand files

USAGE: gzip [ -acdfhklLnNrtvV19 ] [-S suffix] [ name ...  ]
       gunzip [ -acfhklLnNrtvV ] [-S suffix] [ name ...  ]
       zcat [ -fhLV ] [ name ...  ]

OPTIONS:
-a --ascii
              Ascii  text  mode: convert end-of-lines using local conventions.
              This option is supported only on some non-Unix systems. For  MS-
              DOS,  CR  LF is converted to LF when compressing, and LF is con-
              verted to CR LF when decompressing.

       -c --stdout --to-stdout
              Write output on standard output; keep original files  unchanged.
              If  there  are several input files, the output consists of a se-
              quence of independently compressed  members.  To  obtain  better
              compression,  concatenate  all  input  files  before compressing
              them.

       -d --decompress --uncompress
              Decompress.

       -f --force
              Force compression or decompression even if the file has multiple
              links  or  the corresponding file already exists, or if the com-
              pressed data is read from or written to a terminal. If the input
              data  is  not  in a format recognized by gzip, and if the option
              --stdout is also given, copy the input data  without  change  to
              the  standard  output:  let  zcat  behave  as cat.  If -f is not
              given, and when not running in the background, gzip  prompts  to
              verify whether an existing file should be overwritten.

       -h --help
              Display a help screen and quit.

       -k --keep
              Keep (don't delete) input files during compression or decompres-
              sion.

       -l --list
              For each compressed file, list the following fields:

                  compressed size: size of the compressed file
                  uncompressed size: size of the uncompressed file
                  ratio: compression ratio (0.0% if unknown)
                  uncompressed_name: name of the uncompressed file

              The uncompressed size is given as -1 for files not in gzip  for-
              mat,  such  as compressed .Z files. To get the uncompressed size
              for such a file, you can use:

                  zcat file.Z | wc -c

              In combination with the --verbose option, the  following  fields
              are also displayed:

                  method: compression method
                  crc: the 32-bit CRC of the uncompressed data
                  date & time: timestamp for the uncompressed file

              The  compression  methods  currently supported are deflate, com-
              press, lzh (SCO compress -H) and pack.   The  crc  is  given  as
              ffffffff for a file not in gzip format.

              With  --name,  the  uncompressed name,  date and time  are those
              stored within the compress file if present.

              With --verbose, the size totals and compression  ratio  for  all
              files  is  also  displayed,  unless some sizes are unknown. With
              --quiet, the title and totals lines are not displayed.

       -L --license
              Display the gzip license and quit.

       -n --no-name
              When compressing, do not save the original file name  and  time-
              stamp by default. (The original name is always saved if the name
              had to be truncated.) When decompressing,  do  not  restore  the
              original  file name if present (remove only the gzip suffix from
              the compressed file name) and do not restore the original  time-
              stamp if present (copy it from the compressed file). This option
              is the default when decompressing.

       -N --name
              When compressing, always save the original file name,  and  save
              the  seconds  part of the original modification timestamp if the
              original is a regular file and  its  timestamp  is  at  least  1
              (1970-01-01  00:00:01  UTC)  and  is less than 2**32 (2106-02-07
              06:28:16 UTC, assuming leap seconds are not  counted);  this  is
              the  default.  When  decompressing,  restore from the saved file
              name and timestamp if present. This option is useful on  systems
              which have a limit on file name length or when the timestamp has
              been lost after a file transfer.

       -q --quiet
              Suppress all warnings.

       -r --recursive
              Travel the directory structure recursively. If any of  the  file
              names  specified  on the command line are directories, gzip will
              descend into the directory and compress all the files  it  finds
              there (or decompress them in the case of gunzip ).

       -S .suf --suffix .suf
              When compressing, use suffix .suf instead of .gz.  Any non-empty
              suffix can be given, but suffixes other than .z and  .gz  should
              be  avoided  to  avoid  confusion  when files are transferred to
              other systems.

              When decompressing, add .suf to the beginning  of  the  list  of
              suffixes to try, when deriving an output file name from an input
              file name.

       --synchronous
              Use synchronous output.  With this option, gzip is  less  likely
              to  lose  data during a system crash, but it can be considerably
              slower.

       -t --test
              Test. Check the compressed file integrity then quit.

       -v --verbose
              Verbose. Display the name and percentage reduction for each file
              compressed or decompressed.

       -V --version
              Version. Display the version number and compilation options then
              quit.

       -# --fast --best
              Regulate the speed of compression using the specified  digit  #,
              where  -1  or  --fast  indicates  the fastest compression method
              (less compression) and -9 or --best indicates the  slowest  com-
              pression  method  (best  compression).   The default compression
              level is -6 (that is, biased towards high compression at expense
              of speed).

       --rsyncable
              When  you  synchronize  a compressed file between two computers,
              this option allows  rsync  to  transfer  only  files  that  were
              changed in the archive instead of the entire archive.  Normally,
              after a change is made to any file in the archive, the  compres-
              sion  algorithm  can  generate a new version of the archive that
              does not match the previous version  of  the  archive.  In  this
              case,  rsync  transfers the entire new version of the archive to
              the remote computer.  With this option, rsync can transfer  only
              the  changed files as well as a small amount of metadata that is
              required to update the archive structure in the  area  that  was
              changed.

EXECUTION EXAMPLE:
COMMAND INPUT:
gzip --version

COMMAND OUTPUT:
gzip 1.12
Copyright (C) 2018 Free Software Foundation, Inc.
Copyright (C) 1993 Jean-loup Gailly.
This is free software.  You may redistribute copies of it under the terms of
the GNU General Public License <https://www.gnu.org/licenses/gpl.html>.
There is NO WARRANTY, to the extent permitted by law.

Written by Jean-loup Gailly.

===

COMMAND: rsync

DESCRIPTION: rsync - a fast, versatile, remote (and local) file-copying tool

USAGE: Local:
           rsync [OPTION...] SRC... [DEST]

       Access via remote shell:
           Pull:
               rsync [OPTION...] [USER@]HOST:SRC... [DEST]
           Push:
               rsync [OPTION...] SRC... [USER@]HOST:DEST

       Access via rsync daemon:
           Pull:
               rsync [OPTION...] [USER@]HOST::SRC... [DEST]
               rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST]
           Push:
               rsync [OPTION...] SRC... [USER@]HOST::DEST
               rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST)

       Usages with just one SRC arg and no DEST arg will list the source files
       instead of copying.

       The online version of this manpage (that includes cross-linking of top-
       ics) is available at https://download.samba.org/pub/rsync/rsync.1.

OPTIONS:
Rsync  accepts  both long (double-dash + word) and short (single-dash +
       letter) options.  The full list of the available options are  described
       below.  If an option can be specified in more than one way, the choices
       are comma-separated.  Some options only have  a  long  variant,  not  a
       short.

       If the option takes a parameter, the parameter is only listed after the
       long variant, even though it must also  be  specified  for  the  short.
       When  specifying  a  parameter,  you  can  either  use  the  form --op-
       tion=param, --option param, -o=param, -o param, or -oparam (the  latter
       choices assume that your option has a short variant).

       The  parameter  may  need to be quoted in some manner for it to survive
       the shell's command-line parsing.  Also keep in  mind  that  a  leading
       tilde (~) in a pathname is substituted by your shell, so make sure that
       you separate the option name from the pathname using  a  space  if  you
       want the local shell to expand it.

       --help Print  a  short  help  page  describing the options available in
              rsync and exit.  You can also use -h for --help when it is  used
              without any other options (since it normally means --human-read-
              able).

       --version, -V
              Print the rsync version plus other  info  and  exit.   When  re-
              peated, the information is output is a JSON format that is still
              fairly readable (client side only).

              The output includes a list of compiled-in capabilities,  a  list
              of  optimizations,  the default list of checksum algorithms, the
              default list of compression algorithms, the default list of dae-
              mon  auth digests, a link to the rsync web site, and a few other
              items.

       --verbose, -v
              This option increases the amount of information  you  are  given
              during  the transfer.  By default, rsync works silently.  A sin-
              gle -v will give you information  about  what  files  are  being
              transferred and a brief summary at the end.  Two -v options will
              give you  information  on  what  files  are  being  skipped  and
              slightly  more information at the end.  More than two -v options
              should only be used if you are debugging rsync.

              The end-of-run summary tells you the number of bytes sent to the
              remote  rsync (which is the receiving side on a local copy), the
              number of bytes received from the remote host, and  the  average
              bytes  per  second of the transferred data computed over the en-
              tire length of the rsync run. The second line  shows  the  total
              size  (in  bytes),  which  is the sum of all the file sizes that
              rsync considered transferring.  It also shows a "speedup" value,
              which  is  a  ratio of the total file size divided by the sum of
              the sent and received bytes (which is really  just  a  feel-good
              bigger-is-better  number).   Note  that these byte values can be
              made more (or less) human-readable by using the --human-readable
              (or --no-human-readable) options.

              In a modern rsync, the -v option is equivalent to the setting of
              groups of --info and --debug options.  You  can  choose  to  use
              these  newer options in addition to, or in place of using --ver-
              bose, as any fine-grained settings override the implied settings
              of  -v.  Both --info and --debug have a way to ask for help that
              tells you exactly what flags are set for each increase  in  ver-
              bosity.

              However, do keep in mind that a daemon's "max verbosity" setting
              will limit how high of a level the various individual flags  can
              be  set on the daemon side.  For instance, if the max is 2, then
              any info and/or debug flag that is set to a  higher  value  than
              what  would be set by -vv will be downgraded to the -vv level in
              the daemon's logging.

       --info=FLAGS
              This option lets you have fine-grained control over the informa-
              tion  output  you  want  to see.  An individual flag name may be
              followed by a level number, with 0 meaning to silence that  out-
              put,  1  being  the default output level, and higher numbers in-
              creasing the output of that flag (for those that support  higher
              levels).   Use  --info=help to see all the available flag names,
              what they output, and what flag names are  added  for  each  in-
              crease in the verbose level.  Some examples:

                  rsync -a --info=progress2 src/ dest/
                  rsync -avv --info=stats2,misc1,flist0 src/ dest/

              Note  that  --info=name's output is affected by the --out-format
              and --itemize-changes (-i) options.  See those options for  more
              information on what is output and when.

              This  option was added to 3.1.0, so an older rsync on the server
              side might reject your attempts at fine-grained control (if  one
              or more flags needed to be send to the server and the server was
              too old to  understand  them).   See  also  the  "max verbosity"
              caveat above when dealing with a daemon.

       --debug=FLAGS
              This  option  lets  you have fine-grained control over the debug
              output you want to see.  An individual flag name may be followed
              by  a level number, with 0 meaning to silence that output, 1 be-
              ing the default output level, and higher numbers increasing  the
              output of that flag (for those that support higher levels).  Use
              --debug=help to see all the available flag names, what they out-
              put, and what flag names are added for each increase in the ver-
              bose level.  Some examples:

                  rsync -avvv --debug=none src/ dest/
                  rsync -avA --del --debug=del2,acl src/ dest/

              Note that some debug messages  will  only  be  output  when  the
              --stderr=all option is specified, especially those pertaining to
              I/O and buffer debugging.

              Beginning in 3.2.0, this option is no longer  auto-forwarded  to
              the server side in order to allow you to specify different debug
              values for each side of the transfer, as well as  to  specify  a
              new  debug  option that is only present in one of the rsync ver-
              sions.  If you want to duplicate the same option on both  sides,
              using  brace  expansion  is an easy way to save you some typing.
              This works in zsh and bash:

                  rsync -aiv {-M,}--debug=del2 src/ dest/

       --stderr=errors|all|client
              This option controls which processes output  to  stderr  and  if
              info  messages are also changed to stderr.  The mode strings can
              be abbreviated, so feel free to use a single letter value.   The
              3 possible choices are:

              o      errors  - (the default) causes all the rsync processes to
                     send an error directly to stderr, even if the process  is
                     on  the  remote  side of the transfer.  Info messages are
                     sent to the client side  via  the  protocol  stream.   If
                     stderr  is  not  available (i.e. when directly connecting
                     with a daemon via a socket) errors  fall  back  to  being
                     sent via the protocol stream.

              o      all  -  causes all rsync messages (info and error) to get
                     written directly to stderr from all (possible) processes.
                     This  causes  stderr  to become line-buffered (instead of
                     raw) and eliminates the ability to divide up the info and
                     error messages by file handle.  For those doing debugging
                     or using several levels of  verbosity,  this  option  can
                     help  to  avoid  clogging  up  the transfer stream (which
                     should prevent any  chance  of  a  deadlock  bug  hanging
                     things  up).  It also allows --debug to enable some extra
                     I/O related messages.

              o      client - causes all rsync messages  to  be  sent  to  the
                     client  side via the protocol stream.  One client process
                     outputs all messages, with errors on stderr and info mes-
                     sages  on  stdout.   This  was the default in older rsync
                     versions, but can cause error delays when a lot of trans-
                     fer  data  is  ahead  of the messages.  If you're pushing
                     files to an older rsync, you may want to use --stderr=all
                     since that idiom has been around for several releases.

              This  option  was added in rsync 3.2.3.  This version also began
              the forwarding of a non-default  setting  to  the  remote  side,
              though  rsync uses the backward-compatible options --msgs2stderr
              and --no-msgs2stderr to represent the all and  client  settings,
              respectively.  A newer rsync will continue to accept these older
              option names to maintain compatibility.

       --quiet, -q
              This option decreases the amount of information  you  are  given
              during  the  transfer,  notably suppressing information messages
              from the remote server.  This option  is  useful  when  invoking
              rsync from cron.

       --no-motd
              This option affects the information that is output by the client
              at the start of a daemon transfer.  This suppresses the message-
              of-the-day  (MOTD) text, but it also affects the list of modules
              that the daemon sends in response to the "rsync host::"  request
              (due to a limitation in the rsync protocol), so omit this option
              if you want to request the list of modules from the daemon.

       --ignore-times, -I
              Normally rsync will skip any files that  are  already  the  same
              size  and  have  the  same  modification timestamp.  This option
              turns off this "quick check" behavior, causing all files  to  be
              updated.

              This  option  can be confusing compared to --ignore-existing and
              --ignore-non-existing in that that they cause rsync to  transfer
              fewer  files,  while  this  option causes rsync to transfer more
              files.

       --size-only
              This modifies rsync's "quick check" algorithm for finding  files
              that  need  to  be  transferred, changing it from the default of
              transferring files with either a changed size or a changed last-
              modified  time  to  just  looking for files that have changed in
              size.  This is useful when starting to use rsync after using an-
              other  mirroring  system  which  may not preserve timestamps ex-
              actly.

       --modify-window=NUM, -@
              When comparing two timestamps, rsync treats  the  timestamps  as
              being  equal  if  they  differ by no more than the modify-window
              value.  The default is 0, which matches  just  integer  seconds.
              If  you  specify  a negative value (and the receiver is at least
              version 3.1.3) then nanoseconds will also be taken into account.
              Specifying  1  is  useful  for  copies  to/from  MS  Windows FAT
              filesystems, because FAT represents times with a 2-second  reso-
              lution  (allowing  times  to differ from the original by up to 1
              second).

              If you want all your transfers to default to comparing  nanosec-
              onds, you can create a ~/.popt file and put these lines in it:

                  rsync alias -a -a@-1
                  rsync alias -t -t@-1

              With  that  as  the default, you'd need to specify --modify-win-
              dow=0 (aka -@0) to override it and ignore nanoseconds,  e.g.  if
              you're  copying between ext3 and ext4, or if the receiving rsync
              is older than 3.1.3.

       --checksum, -c
              This changes the way rsync checks if the files have been changed
              and  are in need of a transfer.  Without this option, rsync uses
              a "quick check" that (by default) checks if each file's size and
              time of last modification match between the sender and receiver.
              This option changes this to compare a 128-bit checksum for  each
              file  that  has a matching size.  Generating the checksums means
              that both sides will expend a lot of disk I/O  reading  all  the
              data  in the files in the transfer, so this can slow things down
              significantly (and this is prior to any  reading  that  will  be
              done to transfer changed files)

              The  sending  side generates its checksums while it is doing the
              file-system scan that builds the list of  the  available  files.
              The  receiver  generates  its  checksums when it is scanning for
              changed files, and will checksum any file that has the same size
              as  the corresponding sender's file: files with either a changed
              size or a changed checksum are selected for transfer.

              Note that rsync always verifies that each transferred  file  was
              correctly  reconstructed  on  the  receiving  side by checking a
              whole-file checksum that is generated  as  the  file  is  trans-
              ferred,  but  that automatic after-the-transfer verification has
              nothing to do with this option's before-the-transfer "Does  this
              file need to be updated?" check.

              The  checksum used is auto-negotiated between the client and the
              server, but can be overridden using either the --checksum-choice
              (--cc)  option  or  an environment variable that is discussed in
              that option's section.

       --archive, -a
              This is equivalent to -rlptgoD.  It is a quick way of saying you
              want recursion and want to preserve almost everything.  Be aware
              that it does not include  preserving  ACLs  (-A),  xattrs  (-X),
              atimes  (-U),  crtimes  (-N),  nor the finding and preserving of
              hardlinks (-H).

              The only exception to the above equivalence is when --files-from
              is specified, in which case -r is not implied.

       --no-OPTION
              You  may  turn  off one or more implied options by prefixing the
              option name with "no-".  Not all positive options have a negated
              opposite, but a lot do, including those that can be used to dis-
              able an implied option (e.g.  --no-D, --no-perms) or  have  dif-
              ferent  defaults in various circumstances (e.g. --no-whole-file,
              --no-blocking-io, --no-dirs).  Every valid  negated  option  ac-
              cepts  both  the  short and the long option name after the "no-"
              prefix (e.g. --no-R is the same as --no-relative).

              As an example, if you want to use --archive (-a) but don't  want
              --owner  (-o),  instead  of  converting -a into -rlptgD, you can
              specify -a --no-o (aka --archive --no-owner).

              The order of the options is important: if you specify --no-r -a,
              the  -r  option  would  end  up being turned on, the opposite of
              -a --no-r.  Note also that the side-effects of the  --files-from
              option  are  NOT  positional, as it affects the default state of
              several options and slightly changes the meaning of -a (see  the
              --files-from option for more details).

       --recursive, -r
              This  tells  rsync  to  copy  directories recursively.  See also
              --dirs (-d) for an option that allows the scanning of  a  single
              directory.

              See the --inc-recursive option for a discussion of the incremen-
              tal recursion for creating the list of files to transfer.

       --inc-recursive, --i-r
              This option explicitly enables  on  incremental  recursion  when
              scanning  for  files, which is enabled by default when using the
              --recursive option and both sides of the  transfer  are  running
              rsync 3.0.0 or newer.

              Incremental  recursion  uses much less memory than non-incremen-
              tal, while also beginning the transfer more  quickly  (since  it
              doesn't  need  to  scan  the entire transfer hierarchy before it
              starts transferring files).  If no recursion is enabled  in  the
              source files, this option has no effect.

              Some  options require rsync to know the full file list, so these
              options disable the incremental recursion mode.  These include:

              o      --delete-before (the old default of --delete)

              o      --delete-after

              o      --prune-empty-dirs

              o      --delay-updates

              In order to make --delete compatible with incremental recursion,
              rsync  3.0.0 made --delete-during the default delete mode (which
              was first added in 2.6.4).

              One side-effect of incremental recursion  is  that  any  missing
              sub-directories  inside  a recursively-scanned directory are (by
              default) created prior to recursing  into  the  sub-dirs.   This
              earlier creation point (compared to a non-incremental recursion)
              allows rsync to then set the modify time of the finished  direc-
              tory  right  away (without having to delay that until a bunch of
              recursive copying has finished).  However, these early  directo-
              ries  don't  yet  have their completed mode, mtime, or ownership
              set -- they have more restrictive  rights  until  the  subdirec-
              tory's  copying  actually begins.  This early-creation idiom can
              be avoided by using the --omit-dir-times option.

              Incremental recursion can be disabled using the  --no-inc-recur-
              sive (--no-i-r) option.

       --no-inc-recursive, --no-i-r
              Disables the new incremental recursion algorithm of the --recur-
              sive option.  This makes rsync scan the full file list before it
              begins to transfer files.  See --inc-recursive for more info.

       --relative, -R
              Use  relative paths.  This means that the full path names speci-
              fied on the command line are sent to the server rather than just
              the  last  parts  of the filenames.  This is particularly useful
              when you want to send several different directories at the  same
              time.  For example, if you used this command:

                  rsync -av /foo/bar/baz.c remote:/tmp/

              would  create a file named baz.c in /tmp/ on the remote machine.
              If instead you used

                  rsync -avR /foo/bar/baz.c remote:/tmp/

              then a file named /tmp/foo/bar/baz.c would be created on the re-
              mote  machine,  preserving its full path.  These extra path ele-
              ments are called "implied directories" (i.e. the "foo"  and  the
              "foo/bar" directories in the above example).

              Beginning with rsync 3.0.0, rsync always sends these implied di-
              rectories as real directories in the file list, even if  a  path
              element  is really a symlink on the sending side.  This prevents
              some really unexpected behaviors when copying the full path of a
              file  that you didn't realize had a symlink in its path.  If you
              want to duplicate a server-side symlink, include both  the  sym-
              link via its path, and referent directory via its real path.  If
              you're dealing with an older rsync on the sending side, you  may
              need to use the --no-implied-dirs option.

              It is also possible to limit the amount of path information that
              is sent as implied directories for each path you specify.   With
              a  modern  rsync on the sending side (beginning with 2.6.7), you
              can insert a dot and a slash into the source path, like this:

                  rsync -avR /foo/./bar/baz.c remote:/tmp/

              That would create /tmp/bar/baz.c on the  remote  machine.  (Note
              that  the dot must be followed by a slash, so "/foo/." would not
              be abbreviated.) For older rsync versions, you would need to use
              a  chdir  to  limit  the source path.  For example, when pushing
              files:

                  (cd /foo; rsync -avR bar/baz.c remote:/tmp/)

              (Note that the parens put the two commands into a sub-shell,  so
              that  the  "cd" command doesn't remain in effect for future com-
              mands.) If you're pulling files from an older  rsync,  use  this
              idiom (but only for a non-daemon transfer):

                  rsync -avR --rsync-path="cd /foo; rsync" \
                       remote:bar/baz.c /tmp/

       --no-implied-dirs
              This  option  affects the default behavior of the --relative op-
              tion.  When it is specified, the attributes of the  implied  di-
              rectories  from  the source names are not included in the trans-
              fer.  This means that the corresponding  path  elements  on  the
              destination  system  are  left  unchanged if they exist, and any
              missing implied directories are created with default attributes.
              This even allows these implied path elements to have big differ-
              ences, such as being a symlink to a directory on  the  receiving
              side.

              For  instance,  if a command-line arg or a files-from entry told
              rsync to transfer  the  file  "path/foo/file",  the  directories
              "path"  and  "path/foo" are implied when --relative is used.  If
              "path/foo" is a symlink to "bar" on the destination system,  the
              receiving  rsync would ordinarily delete "path/foo", recreate it
              as a directory, and receive the file  into  the  new  directory.
              With    --no-implied-dirs,    the    receiving   rsync   updates
              "path/foo/file" using the existing path  elements,  which  means
              that  the file ends up being created in "path/bar".  Another way
              to accomplish this link  preservation  is  to  use  the  --keep-
              dirlinks  option (which will also affect symlinks to directories
              in the rest of the transfer).

              When pulling files from an rsync older than 3.0.0, you may  need
              to use this option if the sending side has a symlink in the path
              you request and you wish the implied directories  to  be  trans-
              ferred as normal directories.

       --backup, -b
              With  this  option, preexisting destination files are renamed as
              each file is transferred or deleted.  You can control where  the
              backup  file  goes  and what (if any) suffix gets appended using
              the --backup-dir and --suffix options.

              If you don't specify --backup-dir:

              1.     the --omit-dir-times option will be forced on

              2.     the use of --delete (without  --delete-excluded),  causes
                     rsync  to add a "protect" filter-rule for the backup suf-
                     fix to the end of all your existing  filters  that  looks
                     like  this:  -f "P *~".   This  rule  prevents previously
                     backed-up files from being deleted.

              Note that if you are supplying your own filter  rules,  you  may
              need  to manually insert your own exclude/protect rule somewhere
              higher up in the list so that it has a high enough  priority  to
              be  effective  (e.g.  if  your  rules  specify a trailing inclu-
              sion/exclusion  of  *,  the  auto-added  rule  would  never   be
              reached).

       --backup-dir=DIR
              This  implies  the --backup option, and tells rsync to store all
              backups in the specified directory on the receiving side.   This
              can be used for incremental backups.  You can additionally spec-
              ify a backup suffix using the  --suffix  option  (otherwise  the
              files backed up in the specified directory will keep their orig-
              inal filenames).

              Note that if you specify a relative path, the  backup  directory
              will  be  relative to the destination directory, so you probably
              want to specify either an absolute path or a  path  that  starts
              with  "../".  If an rsync daemon is the receiver, the backup dir
              cannot go outside the module's path  hierarchy,  so  take  extra
              care not to delete it or copy into it.

       --suffix=SUFFIX
              This  option  allows  you  to override the default backup suffix
              used with the --backup (-b) option.  The default suffix is  a  ~
              if  no  --backup-dir  was  specified,  otherwise  it is an empty
              string.

       --update, -u
              This forces rsync to skip any files which exist on the  destina-
              tion  and  have  a  modified  time that is newer than the source
              file. (If an existing destination file has a  modification  time
              equal  to the source file's, it will be updated if the sizes are
              different.)

              Note that this does not affect the copying of dirs, symlinks, or
              other  special files.  Also, a difference of file format between
              the sender and receiver is always  considered  to  be  important
              enough for an update, no matter what date is on the objects.  In
              other words, if the source has a directory where the destination
              has  a  file,  the  transfer would occur regardless of the time-
              stamps.

              This option is a TRANSFER RULE, so don't expect any exclude side
              effects.

              A  caution for those that choose to combine --inplace with --up-
              date: an interrupted transfer will leave behind a  partial  file
              on  the  receiving side that has a very recent modified time, so
              re-running the transfer will probably not  continue  the  inter-
              rupted  file.   As  such,  it is usually best to avoid combining
              this with --inplace unless you have implemented manual steps  to
              handle any interrupted in-progress files.

       --inplace
              This  option  changes  how  rsync transfers a file when its data
              needs to be updated: instead of the default method of creating a
              new  copy  of  the file and moving it into place when it is com-
              plete, rsync instead writes the updated  data  directly  to  the
              destination file.

              This has several effects:

              o      Hard  links are not broken.  This means the new data will
                     be visible through other hard links  to  the  destination
                     file.   Moreover, attempts to copy differing source files
                     onto a multiply-linked destination file will result in  a
                     "tug  of war" with the destination data changing back and
                     forth.

              o      In-use binaries cannot be updated  (either  the  OS  will
                     prevent  this from happening, or binaries that attempt to
                     swap-in their data will misbehave or crash).

              o      The file's data will be in an inconsistent  state  during
                     the transfer and will be left that way if the transfer is
                     interrupted or if an update fails.

              o      A file that rsync cannot  write  to  cannot  be  updated.
                     While  a  super  user  can update any file, a normal user
                     needs to be granted write permission for the open of  the
                     file for writing to be successful.

              o      The efficiency of rsync's delta-transfer algorithm may be
                     reduced if some data in the destination file is overwrit-
                     ten  before  it  can be copied to a position later in the
                     file.  This does not apply if  you  use  --backup,  since
                     rsync is smart enough to use the backup file as the basis
                     file for the transfer.

              WARNING: you should not use this option to update files that are
              being  accessed  by  others,  so be careful when choosing to use
              this for a copy.

              This option is useful for transferring large files  with  block-
              based  changes  or  appended  data, and also on systems that are
              disk bound, not network bound.  It can also help keep a copy-on-
              write  filesystem snapshot from diverging the entire contents of
              a file that only has minor changes.

              The option implies --partial (since an interrupted transfer does
              not delete the file), but conflicts with --partial-dir and --de-
              lay-updates.  Prior to rsync 2.6.4 --inplace was also incompati-
              ble with --compare-dest and --link-dest.

       --append
              This  special  copy  mode only works to efficiently update files
              that are known to be growing larger where any  existing  content
              on  the  receiving side is also known to be the same as the con-
              tent on the sender.  The use of --append can be dangerous if you
              aren't  100% sure that all the files in the transfer are shared,
              growing files.  You should thus use filter rules to ensure  that
              you weed out any files that do not fit this criteria.

              Rsync  updates these growing file in-place without verifying any
              of the existing content in the file (it only verifies  the  con-
              tent that it is appending).  Rsync skips any files that exist on
              the receiving side that are not shorter than the associated file
              on  the  sending  side  (which  means  that new files are trans-
              ferred).  It also skips any files whose size on the sending side
              gets  shorter  during the send negotiations (rsync warns about a
              "diminished" file when this happens).

              This does not interfere with the updating of a  file's  non-con-
              tent  attributes  (e.g.   permissions, ownership, etc.) when the
              file does not need to be transferred, nor does it affect the up-
              dating of any directories or non-regular files.

       --append-verify
              This  special  copy mode works like --append except that all the
              data in the file is included in the checksum verification  (mak-
              ing  it less efficient but also potentially safer).  This option
              can be dangerous if you aren't 100% sure that all the  files  in
              the transfer are shared, growing files.  See the --append option
              for more details.

              Note: prior to rsync 3.0.0,  the  --append  option  worked  like
              --append-verify,  so  if you are interacting with an older rsync
              (or the transfer is using a protocol prior  to  30),  specifying
              either append option will initiate an --append-verify transfer.

       --dirs, -d
              Tell  the  sending  side to include any directories that are en-
              countered.  Unlike --recursive, a directory's contents  are  not
              copied unless the directory name specified is "." or ends with a
              trailing slash (e.g.  ".", "dir/.", "dir/", etc.).  Without this
              option  or  the --recursive option, rsync will skip all directo-
              ries it encounters (and output a message to that effect for each
              one).   If  you specify both --dirs and --recursive, --recursive
              takes precedence.

              The --dirs option is implied by the --files-from option  or  the
              --list-only  option  (including an implied --list-only usage) if
              --recursive wasn't specified (so that directories  are  seen  in
              the listing).  Specify --no-dirs (or --no-d) if you want to turn
              this off.

              There is also a backward-compatibility helper option, --old-dirs
              (--old-d)  that tells rsync to use a hack of -r --exclude='/*/*'
              to get an older rsync to list a single directory without recurs-
              ing.

       --mkpath
              Create all missing path components of the destination path.

              By  default, rsync allows only the final component of the desti-
              nation path to not exist, which is an attempt  to  help  you  to
              validate your destination path.  With this option, rsync creates
              all  the  missing  destination-path  components,  just   as   if
              mkdir -p $DEST_PATH had been run on the receiving side.

              When  specifying  a destination path, including a trailing slash
              ensures that the whole path is treated as directory names to  be
              created,  even  when  the  file  list has a single item. See the
              COPYING TO A DIFFERENT NAME section  for  full  details  on  how
              rsync  decides  if  a final destination-path component should be
              created as a directory or not.

              If you would like the newly-created destination  dirs  to  match
              the  dirs  on  the  sending side, you should be using --relative
              (-R) instead of --mkpath.  For instance, the following two  com-
              mands  result  in the same destination tree, but only the second
              command ensures that the "some/extra/path" components match  the
              dirs on the sending side:

                  rsync -ai --mkpath host:some/extra/path/*.c some/extra/path/
                  rsync -aiR host:some/extra/path/*.c ./

       --links, -l
              Add  symlinks to the transferred files instead of noisily ignor-
              ing them with a "non-regular file" warning for each symlink  en-
              countered.   You can alternately silence the warning by specify-
              ing --info=nonreg0.

              The default handling of symlinks is to recreate  each  symlink's
              unchanged value on the receiving side.

              See the SYMBOLIC LINKS section for multi-option info.

       --copy-links, -L
              The  sender  transforms each symlink encountered in the transfer
              into the referent item, following the symlink chain to the  file
              or  directory that it references.  If a symlink chain is broken,
              an error is output and the file is dropped from the transfer.

              This option supersedes any other options that affect symlinks in
              the transfer, since there are no symlinks left in the transfer.

              This option does not change the handling of existing symlinks on
              the receiving side, unlike versions  of  rsync  prior  to  2.6.3
              which  had the side-effect of telling the receiving side to also
              follow symlinks.  A modern rsync won't forward this option to  a
              remote  receiver (since only the sender needs to know about it),
              so this caveat should only affect someone using an rsync  client
              older  than  2.6.7  (which is when -L stopped being forwarded to
              the receiver).

              See the --keep-dirlinks (-K) if you need a symlink to  a  direc-
              tory to be treated as a real directory on the receiving side.

              See the SYMBOLIC LINKS section for multi-option info.

       --copy-unsafe-links
              This  tells  rsync  to  copy the referent of symbolic links that
              point outside the  copied  tree.   Absolute  symlinks  are  also
              treated  like  ordinary  files,  and  so are any symlinks in the
              source path itself when --relative is used.

              Note that the cut-off point is the top of the transfer, which is
              the  part of the path that rsync isn't mentioning in the verbose
              output.  If you copy "/src/subdir" to "/dest/" then the "subdir"
              directory is a name inside the transfer tree, not the top of the
              transfer (which is /src) so it is  legal  for  created  relative
              symlinks  to  refer to other names inside the /src and /dest di-
              rectories.  If you instead copy "/src/subdir/" (with a  trailing
              slash)  to  "/dest/subdir"  that would not allow symlinks to any
              files outside of "subdir".

              Note that safe symlinks are only  copied  if  --links  was  also
              specified  or implied. The --copy-unsafe-links option has no ex-
              tra effect when combined with --copy-links.

              See the SYMBOLIC LINKS section for multi-option info.

       --safe-links
              This tells the receiving rsync to ignore any symbolic  links  in
              the  transfer which point outside the copied tree.  All absolute
              symlinks are also ignored.

              Since this ignoring is happening on the receiving side, it  will
              still  be  effective  even when the sending side has munged sym-
              links (when it is using --munge-links). It  also  affects  dele-
              tions, since the file being present in the transfer prevents any
              matching file on the receiver from being deleted when  the  sym-
              link is deemed to be unsafe and is skipped.

              This option must be combined with --links (or --archive) to have
              any symlinks in the transfer to conditionally ignore. Its effect
              is superseded by --copy-unsafe-links.

              Using  this option in conjunction with --relative may give unex-
              pected results.

              See the SYMBOLIC LINKS section for multi-option info.

       --munge-links
              This option affects just one side  of  the  transfer  and  tells
              rsync  to munge symlink values when it is receiving files or un-
              munge symlink values when it is sending files.  The munged  val-
              ues  make  the symlinks unusable on disk but allows the original
              contents of the symlinks to be recovered.

              The server-side rsync often  enables  this  option  without  the
              client's  knowledge,  such as in an rsync daemon's configuration
              file or by an option given  to  the  rrsync  (restricted  rsync)
              script.   When  specified on the client side, specify the option
              normally if it is the client side that has/needs the munged sym-
              links,  or  use -M--munge-links to give the option to the server
              when it has/needs the munged symlinks.  Note  that  on  a  local
              transfer, the client is the sender, so specifying the option di-
              rectly unmunges symlinks while specifying it as a remote  option
              munges symlinks.

              This option has no effect when sent to a daemon via --remote-op-
              tion because the daemon configures whether it wants munged  sym-
              links via its "munge symlinks" parameter.

              The symlink value is munged/unmunged once it is in the transfer,
              so any option that transforms symlinks into non-symlinks  occurs
              prior to the munging/unmunging except for --safe-links, which is
              a choice that the receiver makes, so it bases  its  decision  on
              the  munged/unmunged  value.   This does mean that if a receiver
              has munging enabled, that using --safe-links will cause all sym-
              links to be ignored (since they are all absolute).

              The  method  that  rsync uses to munge the symlinks is to prefix
              each one's value with the string "/rsyncd-munged/".   This  pre-
              vents  the  links  from being used as long as the directory does
              not exist.  When this option is enabled, rsync  will  refuse  to
              run  if  that  path  is  a directory or a symlink to a directory
              (though it only checks at startup).  See  also  the  "munge-sym-
              links" python script in the support directory of the source code
              for a way to munge/unmunge one or more symlinks in-place.

       --copy-dirlinks, -k
              This option causes the sending side to treat a symlink to a  di-
              rectory  as  though it were a real directory.  This is useful if
              you don't want symlinks to non-directories to  be  affected,  as
              they would be using --copy-links.

              Without  this  option, if the sending side has replaced a direc-
              tory with a symlink to a  directory,  the  receiving  side  will
              delete anything that is in the way of the new symlink, including
              a directory hierarchy (as long as --force or --delete is in  ef-
              fect).

              See also --keep-dirlinks for an analogous option for the receiv-
              ing side.

              --copy-dirlinks applies to all symlinks to  directories  in  the
              source.   If you want to follow only a few specified symlinks, a
              trick you can use is to pass them as additional source args with
              a  trailing  slash,  using --relative to make the paths match up
              right.  For example:

                  rsync -r --relative src/./ src/./follow-me/ dest/

              This works because rsync calls lstat(2) on  the  source  arg  as
              given, and the trailing slash makes lstat(2) follow the symlink,
              giving rise to a directory in the file-list which overrides  the
              symlink found during the scan of "src/./".

              See the SYMBOLIC LINKS section for multi-option info.

       --keep-dirlinks, -K
              This  option  causes  the receiving side to treat a symlink to a
              directory as though it were a real directory,  but  only  if  it
              matches  a real directory from the sender.  Without this option,
              the receiver's symlink would be deleted and replaced with a real
              directory.

              For  example,  suppose  you transfer a directory "foo" that con-
              tains a file "file", but "foo" is a symlink to  directory  "bar"
              on  the receiver.  Without --keep-dirlinks, the receiver deletes
              symlink "foo", recreates it as a  directory,  and  receives  the
              file into the new directory.  With --keep-dirlinks, the receiver
              keeps the symlink and "file" ends up in "bar".

              One note of caution: if you use --keep-dirlinks, you must  trust
              all  the symlinks in the copy or enable the --munge-links option
              on the receiving side!  If it is possible for an untrusted  user
              to  create  their  own  symlink  to any real directory, the user
              could then (on a subsequent copy) replace  the  symlink  with  a
              real  directory and affect the content of whatever directory the
              symlink references.  For backup copies, you are better off using
              something  like a bind mount instead of a symlink to modify your
              receiving hierarchy.

              See also --copy-dirlinks for an analogous option for the sending
              side.

              See the SYMBOLIC LINKS section for multi-option info.

       --hard-links, -H
              This tells rsync to look for hard-linked files in the source and
              link together the corresponding files on the destination.  With-
              out  this option, hard-linked files in the source are treated as
              though they were separate files.

              This option does NOT necessarily ensure that the pattern of hard
              links  on  the  destination  exactly matches that on the source.
              Cases in which the destination may end up with extra hard  links
              include the following:

              o      If  the  destination contains extraneous hard-links (more
                     linking than what is present in the  source  file  list),
                     the  copying  algorithm  will  not break them explicitly.
                     However, if one or more of the paths have content differ-
                     ences,  the  normal  file-update process will break those
                     extra links (unless you are using the --inplace option).

              o      If you specify a --link-dest directory that contains hard
                     links,  the  linking of the destination files against the
                     --link-dest files can cause some paths in the destination
                     to become linked together due to the --link-dest associa-
                     tions.

              Note that rsync can only detect hard links  between  files  that
              are  inside  the transfer set.  If rsync updates a file that has
              extra hard-link connections to files outside the transfer,  that
              linkage will be broken.  If you are tempted to use the --inplace
              option to avoid this breakage, be very careful that you know how
              your files are being updated so that you are certain that no un-
              intended changes happen due to lingering hard links (and see the
              --inplace option for more caveats).

              If  incremental recursion is active (see --inc-recursive), rsync
              may transfer a missing hard-linked file before it finds that an-
              other  link for that contents exists elsewhere in the hierarchy.
              This does not affect the accuracy of the  transfer  (i.e.  which
              files are hard-linked together), just its efficiency (i.e. copy-
              ing the data for a new, early copy of a  hard-linked  file  that
              could have been found later in the transfer in another member of
              the hard-linked set of files).  One way to  avoid  this  ineffi-
              ciency  is  to disable incremental recursion using the --no-inc-
              recursive option.

       --perms, -p
              This option causes the receiving rsync to  set  the  destination
              permissions  to be the same as the source permissions. (See also
              the --chmod option for a way to modify what rsync  considers  to
              be the source permissions.)

              When this option is off, permissions are set as follows:

              o      Existing files (including updated files) retain their ex-
                     isting permissions,  though  the  --executability  option
                     might change just the execute permission for the file.

              o      New  files  get their "normal" permission bits set to the
                     source file's permissions masked with the  receiving  di-
                     rectory's   default  permissions  (either  the  receiving
                     process's umask, or the  permissions  specified  via  the
                     destination  directory's  default ACL), and their special
                     permission bits disabled except in the case where  a  new
                     directory  inherits  a  setgid bit from its parent direc-
                     tory.

              Thus,  when  --perms  and  --executability  are  both  disabled,
              rsync's  behavior  is the same as that of other file-copy utili-
              ties, such as cp(1) and tar(1).

              In summary: to give destination files (both  old  and  new)  the
              source permissions, use --perms.  To give new files the destina-
              tion-default  permissions  (while  leaving  existing  files  un-
              changed),  make  sure  that  the  --perms  option is off and use
              --chmod=ugo=rwX (which ensures that all non-masked bits get  en-
              abled).   If  you'd  care to make this latter behavior easier to
              type, you could define a popt alias for it, such as putting this
              line  in  the file ~/.popt (the following defines the -Z option,
              and includes --no-g to use the default group of the  destination
              dir):

                  rsync alias -Z --no-p --no-g --chmod=ugo=rwX

              You  could  then  use  this new option in a command such as this
              one:

                  rsync -avZ src/ dest/

              (Caveat: make sure that -a does not follow -Z, or it will re-en-
              able the two --no-* options mentioned above.)

              The  preservation  of the destination's setgid bit on newly-cre-
              ated directories when --perms is off was added in  rsync  2.6.7.
              Older  rsync  versions  erroneously  preserved the three special
              permission bits for newly-created files when  --perms  was  off,
              while  overriding  the  destination's  setgid  bit  setting on a
              newly-created directory.  Default ACL observance  was  added  to
              the  ACL  patch  for  rsync 2.6.7, so older (or non-ACL-enabled)
              rsyncs use the umask even if default ACLs are present.  (Keep in
              mind  that it is the version of the receiving rsync that affects
              these behaviors.)

       --executability, -E
              This option causes rsync to preserve the executability (or  non-
              executability)  of regular files when --perms is not enabled.  A
              regular file is considered to be executable if at least one  'x'
              is  turned  on in its permissions.  When an existing destination
              file's executability differs  from  that  of  the  corresponding
              source  file,  rsync modifies the destination file's permissions
              as follows:

              o      To make a file non-executable, rsync turns  off  all  its
                     'x' permissions.

              o      To  make  a file executable, rsync turns on each 'x' per-
                     mission that has a corresponding 'r' permission enabled.

              If --perms is enabled, this option is ignored.

       --acls, -A
              This option causes rsync to update the destination  ACLs  to  be
              the same as the source ACLs.  The option also implies --perms.

              The  source and destination systems must have compatible ACL en-
              tries for this option to work properly.   See  the  --fake-super
              option for a way to backup and restore ACLs that are not compat-
              ible.

       --xattrs, -X
              This option causes rsync to update the destination extended  at-
              tributes to be the same as the source ones.

              For  systems  that support extended-attribute namespaces, a copy
              being done by a super-user copies  all  namespaces  except  sys-
              tem.*.   A  normal user only copies the user.* namespace.  To be
              able to backup and restore non-user namespaces as a normal user,
              see the --fake-super option.

              The  above name filtering can be overridden by using one or more
              filter options with the x modifier.  When you specify an  xattr-
              affecting  filter rule, rsync requires that you do your own sys-
              tem/user filtering, as well as any additional filtering for what
              xattr names are copied and what names are allowed to be deleted.
              For example, to skip the system namespace, you could specify:

                  --filter='-x system.*'

              To skip all namespaces except  the  user  namespace,  you  could
              specify a negated-user match:

                  --filter='-x! user.*'

              To  prevent any attributes from being deleted, you could specify
              a receiver-only rule that excludes all names:

                  --filter='-xr *'

              Note that the -X option does not copy rsync's special xattr val-
              ues (e.g.  those used by --fake-super) unless you repeat the op-
              tion (e.g. -XX).  This "copy all xattrs"  mode  cannot  be  used
              with --fake-super.

       --chmod=CHMOD
              This  option  tells  rsync  to apply one or more comma-separated
              "chmod" modes to the permission of the files  in  the  transfer.
              The resulting value is treated as though it were the permissions
              that the sending side supplied for the file,  which  means  that
              this  option  can  seem  to  have no effect on existing files if
              --perms is not enabled.

              In addition  to  the  normal  parsing  rules  specified  in  the
              chmod(1) manpage, you can specify an item that should only apply
              to a directory by prefixing it with a 'D', or  specify  an  item
              that  should  only  apply  to a file by prefixing it with a 'F'.
              For example, the following will ensure that all directories  get
              marked  set-gid, that no files are other-writable, that both are
              user-writable and group-writable, and that both have  consistent
              executability across all bits:

                  --chmod=Dg+s,ug+w,Fo-w,+X

              Using octal mode numbers is also allowed:

                  --chmod=D2775,F664

              It  is  also  legal to specify multiple --chmod options, as each
              additional option is just appended to the  list  of  changes  to
              make.

              See  the --perms and --executability options for how the result-
              ing permission value can be applied to the files in  the  trans-
              fer.

       --owner, -o
              This  option  causes  rsync  to set the owner of the destination
              file to be the same as the source file, but only if the  receiv-
              ing  rsync  is being run as the super-user (see also the --super
              and --fake-super options).  Without this option,  the  owner  of
              new and/or transferred files are set to the invoking user on the
              receiving side.

              The preservation of ownership will associate matching  names  by
              default,  but  may fall back to using the ID number in some cir-
              cumstances (see also the --numeric-ids option for a full discus-
              sion).

       --group, -g
              This  option  causes  rsync  to set the group of the destination
              file to be the same as the source file.  If the  receiving  pro-
              gram  is  not  running  as  the super-user (or if --no-super was
              specified), only groups that the invoking user on the  receiving
              side is a member of will be preserved.  Without this option, the
              group is set to the default group of the invoking  user  on  the
              receiving side.

              The  preservation  of  group information will associate matching
              names by default, but may fall back to using the  ID  number  in
              some circumstances (see also the --numeric-ids option for a full
              discussion).

       --devices
              This option causes rsync to transfer character and block  device
              files  to  the  remote system to recreate these devices.  If the
              receiving rsync is  not  being  run  as  the  super-user,  rsync
              silently  skips  creating the device files (see also the --super
              and --fake-super options).

              By default, rsync generates a  "non-regular  file"  warning  for
              each  device  file encountered when this option is not set.  You
              can silence the warning by specifying --info=nonreg0.

       --specials
              This option causes rsync to  transfer  special  files,  such  as
              named  sockets  and  fifos.  If the receiving rsync is not being
              run as the super-user, rsync silently skips creating the special
              files (see also the --super and --fake-super options).

              By  default,  rsync  generates  a "non-regular file" warning for
              each special file encountered when this option is not set.   You
              can silence the warning by specifying --info=nonreg0.

       -D     The -D option is equivalent to "--devices --specials".

       --copy-devices
              This tells rsync to treat a device on the sending side as a reg-
              ular file, allowing it to be copied to a normal destination file
              (or another device if --write-devices was also specified).

              This option is refused by default by an rsync daemon.

       --write-devices
              This  tells  rsync  to treat a device on the receiving side as a
              regular file, allowing the writing of file data into a device.

              This option implies the --inplace option.

              Be careful using this, as  you  should  know  what  devices  are
              present  on  the receiving side of the transfer, especially when
              running rsync as root.

              This option is refused by default by an rsync daemon.

       --times, -t
              This tells rsync to transfer modification times along  with  the
              files  and  update them on the remote system.  Note that if this
              option is not used, the optimization that  excludes  files  that
              have  not  been  modified cannot be effective; in other words, a
              missing -t (or -a) will cause the next transfer to behave as  if
              it  used  --ignore-times  (-I),  causing all files to be updated
              (though rsync's delta-transfer algorithm will  make  the  update
              fairly  efficient  if the files haven't actually changed, you're
              much better off using -t).

              A modern rsync that is using transfer protocol 30 or 31  conveys
              a  modify  time using up to 8-bytes. If rsync is forced to speak
              an older protocol (perhaps due to the remote rsync  being  older
              than  3.0.0)  a  modify time is conveyed using 4-bytes. Prior to
              3.2.7, these  shorter  values  could  convey  a  date  range  of
              13-Dec-1901  to 19-Jan-2038.  Beginning with 3.2.7, these 4-byte
              values now convey a date range of 1-Jan-1970 to 7-Feb-2106.   If
              you  have files dated older than 1970, make sure your rsync exe-
              cutables are upgraded so that the full range  of  dates  can  be
              conveyed.

       --atimes, -U
              This  tells  rsync to set the access (use) times of the destina-
              tion files to the same value as the source files.

              If repeated, it also sets the --open-noatime option,  which  can
              help you to make the sending and receiving systems have the same
              access times on the transferred files  without  needing  to  run
              rsync an extra time after a file is transferred.

              Note  that  some  older rsync versions (prior to 3.2.0) may have
              been built with a pre-release --atimes patch that does not imply
              --open-noatime when this option is repeated.

       --open-noatime
              This  tells rsync to open files with the O_NOATIME flag (on sys-
              tems that support it) to avoid changing the access time  of  the
              files  that  are being transferred.  If your OS does not support
              the O_NOATIME flag then rsync will silently ignore this  option.
              Note  also  that  some filesystems are mounted to avoid updating
              the atime on read access even without the O_NOATIME  flag  being
              set.

       --crtimes, -N,
              This tells rsync to set the create times (newness) of the desti-
              nation files to the same value as the source files.

       --omit-dir-times, -O
              This tells rsync to omit directories when it is preserving modi-
              fication,  access,  and create times.  If NFS is sharing the di-
              rectories on the receiving side, it is a good idea  to  use  -O.
              This  option  is  inferred if you use --backup without --backup-
              dir.

              This option also has the side-effect of avoiding early  creation
              of  missing  sub-directories  when  incremental recursion is en-
              abled, as discussed in the --inc-recursive section.

       --omit-link-times, -J
              This tells rsync to omit symlinks when it is preserving  modifi-
              cation, access, and create times.

       --super
              This  tells  the receiving side to attempt super-user activities
              even if the receiving rsync wasn't run by the super-user.  These
              activities  include:  preserving  users  via the --owner option,
              preserving all groups (not just the current user's  groups)  via
              the  --group  option,  and copying devices via the --devices op-
              tion.  This is useful for systems  that  allow  such  activities
              without  being  the  super-user,  and also for ensuring that you
              will get errors if the receiving side isn't being run as the su-
              per-user.  To turn off super-user activities, the super-user can
              use --no-super.

       --fake-super
              When this option is enabled, rsync simulates super-user  activi-
              ties  by  saving/restoring the privileged attributes via special
              extended attributes that are attached to each file (as  needed).
              This  includes  the file's owner and group (if it is not the de-
              fault), the file's device info (device & special files are  cre-
              ated as empty text files), and any permission bits that we won't
              allow to be set on the real file (e.g. the real file gets u-s,g-
              s,o-t  for safety) or that would limit the owner's access (since
              the real super-user can always access/change a file,  the  files
              we  create can always be accessed/changed by the creating user).
              This option also handles ACLs (if --acls was specified) and non-
              user extended attributes (if --xattrs was specified).

              This  is  a  good way to backup data without using a super-user,
              and to store ACLs from incompatible systems.

              The --fake-super option only affects the side where  the  option
              is  used.   To  affect the remote side of a remote-shell connec-
              tion, use the --remote-option (-M) option:

                  rsync -av -M--fake-super /src/ host:/dest/

              For a local copy, this option affects both the  source  and  the
              destination.   If  you  wish  a local copy to enable this option
              just for the destination files, specify -M--fake-super.  If  you
              wish  a  local  copy  to  enable this option just for the source
              files, combine --fake-super with -M--super.

              This option is overridden by both --super and --no-super.

              See also the fake super  setting  in  the  daemon's  rsyncd.conf
              file.

       --sparse, -S
              Try  to  handle  sparse  files  efficiently so they take up less
              space on the destination.  If combined with --inplace  the  file
              created  might  not end up with sparse blocks with some combina-
              tions of kernel version and/or filesystem type.  If --whole-file
              is  in  effect  (e.g. for a local copy) then it will always work
              because rsync truncates the file prior to writing  out  the  up-
              dated version.

              Note  that  versions  of  rsync older than 3.1.3 will reject the
              combination of --sparse and --inplace.

       --preallocate
              This tells the receiver to allocate each destination file to its
              eventual  size before writing data to the file.  Rsync will only
              use the real filesystem-level preallocation support provided  by
              Linux's fallocate(2) system call or Cygwin's posix_fallocate(3),
              not the slow glibc implementation that writes a null  byte  into
              each block.

              Without this option, larger files may not be entirely contiguous
              on the filesystem, but with this option rsync will probably copy
              more  slowly.   If  the  destination is not an extent-supporting
              filesystem (such as ext4, xfs, NTFS, etc.), this option may have
              no positive effect at all.

              If combined with --sparse, the file will only have sparse blocks
              (as opposed to allocated sequences of null bytes) if the  kernel
              version  and filesystem type support creating holes in the allo-
              cated data.

       --dry-run, -n
              This makes rsync perform a  trial  run  that  doesn't  make  any
              changes (and produces mostly the same output as a real run).  It
              is most commonly used in combination  with  the  --verbose  (-v)
              and/or  --itemize-changes (-i) options to see what an rsync com-
              mand is going to do before one actually runs it.

              The output of --itemize-changes is supposed to  be  exactly  the
              same on a dry run and a subsequent real run (barring intentional
              trickery and system call failures); if it isn't, that's  a  bug.
              Other  output should be mostly unchanged, but may differ in some
              areas.  Notably, a dry run does not send  the  actual  data  for
              file  transfers,  so --progress has no effect, the "bytes sent",
              "bytes received", "literal data", and "matched data"  statistics
              are  too  small,  and the "speedup" value is equivalent to a run
              where no file transfers were needed.

       --whole-file, -W
              This option disables  rsync's  delta-transfer  algorithm,  which
              causes all transferred files to be sent whole.  The transfer may
              be faster if this option is used when the bandwidth between  the
              source  and destination machines is higher than the bandwidth to
              disk  (especially  when  the  "disk"  is  actually  a  networked
              filesystem).   This is the default when both the source and des-
              tination are specified as local paths, but  only  if  no  batch-
              writing option is in effect.

       --no-whole-file, --no-W
              Disable  whole-file updating when it is enabled by default for a
              local transfer.  This usually slows rsync down, but  it  can  be
              useful  if you are trying to minimize the writes to the destina-
              tion file (if combined with --inplace) or for testing the check-
              sum-based update algorithm.

              See also the --whole-file option.

       --checksum-choice=STR, --cc=STR
              This option overrides the checksum algorithms.  If one algorithm
              name is specified, it is used for both  the  transfer  checksums
              and  (assuming  --checksum is specified) the pre-transfer check-
              sums.  If two comma-separated names are supplied, the first name
              affects  the transfer checksums, and the second name affects the
              pre-transfer checksums (-c).

              The checksum options that you may be able to use are:

              o      auto (the default automatic choice)

              o      xxh128

              o      xxh3

              o      xxh64 (aka xxhash)

              o      md5

              o      md4

              o      sha1

              o      none

              Run rsync --version to see the default  checksum  list  compiled
              into your version (which may differ from the list above).

              If  "none"  is  specified  for  the  first  (or  only) name, the
              --whole-file option is forced on and no checksum verification is
              performed  on  the transferred data.  If "none" is specified for
              the second (or only) name, the --checksum option cannot be used.

              The "auto" option is the default, where rsync  bases  its  algo-
              rithm  choice on a negotiation between the client and the server
              as follows:

              When both sides of  the  transfer  are  at  least  3.2.0,  rsync
              chooses the first algorithm in the client's list of choices that
              is also in the server's list of choices.  If no common  checksum
              choice is found, rsync exits with an error.  If the remote rsync
              is too old to support checksum negotiation, a  value  is  chosen
              based  on  the  protocol  version (which chooses between MD5 and
              various flavors of MD4 based on protocol age).

              The default order can be customized by setting  the  environment
              variable  RSYNC_CHECKSUM_LIST  to  a space-separated list of ac-
              ceptable checksum names.  If the string contains a  "&"  charac-
              ter,  it  is separated into the "client string & server string",
              otherwise the same string applies to both.  If  the  string  (or
              string  portion)  contains no non-whitespace characters, the de-
              fault checksum list is used.  This method does not allow you  to
              specify  the  transfer checksum separately from the pre-transfer
              checksum, and it discards "auto" and all unknown checksum names.
              A list with only invalid names results in a failed negotiation.

              The  use of the --checksum-choice option overrides this environ-
              ment list.

       --one-file-system, -x
              This tells rsync to avoid crossing a  filesystem  boundary  when
              recursing.   This  does  not limit the user's ability to specify
              items to copy from multiple filesystems, just rsync's  recursion
              through the hierarchy of each directory that the user specified,
              and also the analogous recursion on the  receiving  side  during
              deletion.  Also keep in mind that rsync treats a "bind" mount to
              the same device as being on the same filesystem.

              If this option is repeated, rsync omits all mount-point directo-
              ries  from  the copy.  Otherwise, it includes an empty directory
              at each mount-point it encounters (using the attributes  of  the
              mounted  directory  because  those of the underlying mount-point
              directory are inaccessible).

              If rsync has been told to collapse symlinks (via --copy-links or
              --copy-unsafe-links), a symlink to a directory on another device
              is treated like a mount-point.  Symlinks to non-directories  are
              unaffected by this option.

       --ignore-non-existing, --existing
              This  tells rsync to skip creating files (including directories)
              that do not exist yet on the destination.   If  this  option  is
              combined with the --ignore-existing option, no files will be up-
              dated (which can be useful if all you want to do is  delete  ex-
              traneous files).

              This option is a TRANSFER RULE, so don't expect any exclude side
              effects.

       --ignore-existing
              This tells rsync to skip updating files that  already  exist  on
              the  destination  (this does not ignore existing directories, or
              nothing would get done).  See also --ignore-non-existing.

              This option is a TRANSFER RULE, so don't expect any exclude side
              effects.

              This  option  can  be  useful  for those doing backups using the
              --link-dest option when they need to continue a backup run  that
              got  interrupted.   Since a --link-dest run is copied into a new
              directory hierarchy (when it is used properly), using [--ignore-
              existing  will  ensure  that the already-handled files don't get
              tweaked (which avoids a change in permissions on the hard-linked
              files).   This does mean that this option is only looking at the
              existing files in the destination hierarchy itself.

              When --info=skip2 is used rsync  will  output  "FILENAME  exists
              (INFO)"  messages where the INFO indicates one of "type change",
              "sum change" (requires -c), "file change" (based  on  the  quick
              check), "attr change", or "uptodate".  Using --info=skip1 (which
              is also implied by 2 -v  options)  outputs  the  exists  message
              without the INFO suffix.

       --remove-source-files
              This  tells  rsync  to  remove  from  the sending side the files
              (meaning non-directories) that are a part of  the  transfer  and
              have been successfully duplicated on the receiving side.

              Note  that  you should only use this option on source files that
              are quiescent.  If you are using this to move files that show up
              in  a  particular directory over to another host, make sure that
              the finished files get renamed into the  source  directory,  not
              directly  written into it, so that rsync can't possibly transfer
              a file that is not yet fully written.  If you can't first  write
              the  files  into  a different directory, you should use a naming
              idiom that lets rsync avoid transferring files that are not  yet
              finished  (e.g.  name the file "foo.new" when it is written, re-
              name it to "foo" when it is done, and then use the option  --ex-
              clude='*.new' for the rsync transfer).

              Starting  with  3.1.0,  rsync  will skip the sender-side removal
              (and output an error) if the file's size or modify time has  not
              stayed unchanged.

              Starting  with  3.2.6,  a  local rsync copy will ensure that the
              sender does not remove a file the receiver just  verified,  such
              as  when  the user accidentally makes the source and destination
              directory the same path.

       --delete
              This tells rsync to delete extraneous files from  the  receiving
              side  (ones  that  aren't on the sending side), but only for the
              directories that are being synchronized.  You  must  have  asked
              rsync to send the whole directory (e.g. "dir" or "dir/") without
              using a wildcard for the  directory's  contents  (e.g.  "dir/*")
              since  the wildcard is expanded by the shell and rsync thus gets
              a request to transfer individual files, not  the  files'  parent
              directory.   Files  that are excluded from the transfer are also
              excluded from being deleted unless you use the --delete-excluded
              option  or  mark  the rules as only matching on the sending side
              (see the include/exclude modifiers in the FILTER RULES section).

              Prior to rsync 2.6.7, this option would have  no  effect  unless
              --recursive  was  enabled.  Beginning with 2.6.7, deletions will
              also occur when --dirs (-d) is enabled, but only for directories
              whose contents are being copied.

              This  option  can be dangerous if used incorrectly! It is a very
              good idea to first try a run using the --dry-run (-n) option  to
              see what files are going to be deleted.

              If the sending side detects any I/O errors, then the deletion of
              any files at the destination  will  be  automatically  disabled.
              This  is  to  prevent temporary filesystem failures (such as NFS
              errors) on the sending side from causing a massive  deletion  of
              files  on the destination.  You can override this with the --ig-
              nore-errors option.

              The --delete option may be combined with one  of  the  --delete-
              WHEN  options  without  conflict,  as well as --delete-excluded.
              However, if none of the  --delete-WHEN  options  are  specified,
              rsync  will choose the --delete-during algorithm when talking to
              rsync 3.0.0 or newer,  or  the  --delete-before  algorithm  when
              talking   to  an  older  rsync.   See  also  --delete-delay  and
              --delete-after.

       --delete-before
              Request that the file-deletions on the receiving  side  be  done
              before the transfer starts.  See --delete (which is implied) for
              more details on file-deletion.

              Deleting before the transfer is helpful  if  the  filesystem  is
              tight for space and removing extraneous files would help to make
              the transfer possible.  However, it does introduce a  delay  be-
              fore  the  start of the transfer, and this delay might cause the
              transfer to timeout  (if  --timeout  was  specified).   It  also
              forces rsync to use the old, non-incremental recursion algorithm
              that requires rsync to scan all the files in the  transfer  into
              memory at once (see --recursive).

       --delete-during, --del
              Request  that  the  file-deletions on the receiving side be done
              incrementally as the transfer happens.  The per-directory delete
              scan is done right before each directory is checked for updates,
              so it behaves like a more efficient  --delete-before,  including
              doing  the deletions prior to any per-directory filter files be-
              ing updated.  This option  was  first  added  in  rsync  version
              2.6.4.   See  --delete  (which  is  implied) for more details on
              file-deletion.

       --delete-delay
              Request that the file-deletions on the receiving  side  be  com-
              puted  during  the transfer (like --delete-during), and then re-
              moved after the transfer completes.  This is  useful  when  com-
              bined with --delay-updates and/or --fuzzy, and is more efficient
              than using --delete-after (but  can  behave  differently,  since
              --delete-after  computes  the deletions in a separate pass after
              all updates are done).  If the number of removed files overflows
              an  internal buffer, a temporary file will be created on the re-
              ceiving side to hold the names (it is removed while open, so you
              shouldn't  see  it during the transfer).  If the creation of the
              temporary file fails, rsync will  try  to  fall  back  to  using
              --delete-after  (which  it  cannot do if --recursive is doing an
              incremental scan).  See --delete (which is implied) for more de-
              tails on file-deletion.

       --delete-after
              Request  that  the  file-deletions on the receiving side be done
              after the transfer has completed.  This is  useful  if  you  are
              sending  new per-directory merge files as a part of the transfer
              and you want their exclusions to  take  effect  for  the  delete
              phase  of the current transfer.  It also forces rsync to use the
              old, non-incremental recursion algorithm that requires rsync  to
              scan  all  the  files  in  the transfer into memory at once (see
              --recursive). See --delete (which is implied) for  more  details
              on file-deletion.

              See also the --delete-delay option that might be a faster choice
              for those that just want the deletions to occur at  the  end  of
              the transfer.

       --delete-excluded
              This  option  turns  any  unqualified exclude/include rules into
              server-side rules that do not affect the receiver's deletions.

              By default, an exclude or include has both a server-side  effect
              (to  "hide"  and  "show"  files  when building the server's file
              list) and a receiver-side effect (to "protect" and "risk"  files
              when deletions are occurring).  Any rule that has no modifier to
              specify what sides it is executed on will be instead treated  as
              if  it  were a server-side rule only, avoiding any "protect" ef-
              fects of the rules.

              A rule can still apply to both sides even with this option spec-
              ified  if  the rule is given both the sender & receiver modifier
              letters (e.g., -f'-sr foo').  Receiver-side  protect/risk  rules
              can  also  be explicitly specified to limit the deletions.  This
              saves you from having to edit a bunch of  -f'- foo'  rules  into
              -f'-s foo' (aka -f'H foo') rules (not to mention the correspond-
              ing includes).

              See the FILTER RULES section for more information.  See --delete
              (which is implied) for more details on deletion.

       --ignore-missing-args
              When  rsync  is first processing the explicitly requested source
              files (e.g.  command-line arguments or --files-from entries), it
              is  normally  an error if the file cannot be found.  This option
              suppresses that error, and does not try to  transfer  the  file.
              This  does  not affect subsequent vanished-file errors if a file
              was initially found to be present and later is no longer there.

       --delete-missing-args
              This option takes the behavior of the  (implied)  --ignore-miss-
              ing-args  option  a step farther: each missing arg will become a
              deletion request of the corresponding destination  file  on  the
              receiving  side (should it exist).  If the destination file is a
              non-empty directory, it will only  be  successfully  deleted  if
              --force or --delete are in effect.  Other than that, this option
              is independent of any other type of delete processing.

              The missing source files are represented  by  special  file-list
              entries  which  display as a "*missing" entry in the --list-only
              output.

       --ignore-errors
              Tells --delete to go ahead and delete files even when there  are
              I/O errors.

       --force
              This  option tells rsync to delete a non-empty directory when it
              is to be replaced by a non-directory.  This is only relevant  if
              deletions are not active (see --delete for details).

              Note for older rsync versions: --force used to still be required
              when using --delete-after, and it used to be non-functional  un-
              less the --recursive option was also enabled.

       --max-delete=NUM
              This  tells  rsync not to delete more than NUM files or directo-
              ries.  If that limit is  exceeded,  all  further  deletions  are
              skipped through the end of the transfer.  At the end, rsync out-
              puts a warning (including a count of the skipped deletions)  and
              exits with an error code of 25 (unless some more important error
              condition also occurred).

              Beginning with version 3.0.0, you may specify --max-delete=0  to
              be  warned about any extraneous files in the destination without
              removing any of them.  Older clients interpreted this as "unlim-
              ited",  so if you don't know what version the client is, you can
              use the less obvious --max-delete=-1  as  a  backward-compatible
              way  to  specify that no deletions be allowed (though really old
              versions didn't warn when the limit was exceeded).

       --max-size=SIZE
              This tells rsync to avoid transferring any file that  is  larger
              than the specified SIZE.  A numeric value can be suffixed with a
              string to indicate the numeric  units  or  left  unqualified  to
              specify  bytes.   Feel free to use a fractional value along with
              the units, such as --max-size=1.5m.

              This option is a TRANSFER RULE, so don't expect any exclude side
              effects.

              The first letter of a units string can be B (bytes), K (kilo), M
              (mega), G (giga), T (tera), or P (peta).  If  the  string  is  a
              single char or has "ib" added to it (e.g. "G" or "GiB") then the
              units are multiples of 1024.  If you  use  a  two-letter  suffix
              that  ends  with  a  "B" (e.g. "kb") then you get units that are
              multiples of 1000.  The string's letters can be any mix of upper
              and lower-case that you want to use.

              Finally, if the string ends with either "+1" or "-1", it is off-
              set by one byte in the indicated direction.  The largest  possi-
              ble value is usually 8192P-1.

              Examples:   --max-size=1.5mb-1  is  1499999  bytes,  and  --max-
              size=2g+1 is 2147483649 bytes.

              Note that rsync versions prior to 3.1.0  did  not  allow  --max-
              size=0.

       --min-size=SIZE
              This  tells rsync to avoid transferring any file that is smaller
              than the specified SIZE, which  can  help  in  not  transferring
              small,  junk files.  See the --max-size option for a description
              of SIZE and other info.

              Note that rsync versions prior to 3.1.0  did  not  allow  --min-
              size=0.

       --max-alloc=SIZE
              By  default  rsync  limits an individual malloc/realloc to about
              1GB in size.  For most people this limit  works  just  fine  and
              prevents  a  protocol  error  causing  rsync  to request massive
              amounts of memory.  However, if you have many millions of  files
              in  a  transfer,  a large amount of server memory, and you don't
              want to split up your transfer into multiple parts, you can  in-
              crease  the  per-allocation  limit to something larger and rsync
              will consume more memory.

              Keep in mind that this is not a limit on the total size of allo-
              cated  memory.   It  is a sanity-check value for each individual
              allocation.

              See the --max-size option for a description of how SIZE  can  be
              specified.  The default suffix if none is given is bytes.

              Beginning in 3.2.3, a value of 0 specifies no limit.

              You  can  set  a  default  value  using the environment variable
              RSYNC_MAX_ALLOC using the same SIZE values as supported by  this
              option.   If the remote rsync doesn't understand the --max-alloc
              option, you can override an environmental  value  by  specifying
              --max-alloc=1g,  which  will make rsync avoid sending the option
              to the remote side (because "1G" is the default).

       --block-size=SIZE, -B
              This forces the block size used in rsync's delta-transfer  algo-
              rithm  to  a  fixed value.  It is normally selected based on the
              size of each file being updated.  See the technical  report  for
              details.

              Beginning  in  3.2.3  the SIZE can be specified with a suffix as
              detailed in the --max-size option.  Older versions only accepted
              a byte count.

       --rsh=COMMAND, -e
              This  option  allows  you  to choose an alternative remote shell
              program to use for communication between the  local  and  remote
              copies  of  rsync.  Typically, rsync is configured to use ssh by
              default, but you may prefer to use rsh on a local network.

              If this option is used with [user@]host::module/path,  then  the
              remote  shell COMMAND will be used to run an rsync daemon on the
              remote host, and all data will be transmitted through  that  re-
              mote  shell connection, rather than through a direct socket con-
              nection to a running rsync daemon on the remote host.   See  the
              USING  RSYNC-DAEMON  FEATURES VIA A REMOTE-SHELL CONNECTION sec-
              tion above.

              Beginning with rsync 3.2.0, the RSYNC_PORT environment  variable
              will be set when a daemon connection is being made via a remote-
              shell connection.  It is set to 0 if the default daemon port  is
              being  assumed, or it is set to the value of the rsync port that
              was specified via either the --port option or a  non-empty  port
              value  in an rsync:// URL.  This allows the script to discern if
              a non-default port is being requested, allowing for things  such
              as  an  SSL  or stunnel helper script to connect to a default or
              alternate port.

              Command-line arguments are permitted in  COMMAND  provided  that
              COMMAND  is  presented  to rsync as a single argument.  You must
              use spaces (not tabs or other whitespace) to separate  the  com-
              mand  and  args  from each other, and you can use single- and/or
              double-quotes to preserve spaces in an argument (but  not  back-
              slashes).   Note  that  doubling a single-quote inside a single-
              quoted string gives you a  single-quote;  likewise  for  double-
              quotes  (though  you  need to pay attention to which quotes your
              shell is parsing and which quotes rsync is parsing).  Some exam-
              ples:

                  -e 'ssh -p 2234'
                  -e 'ssh -o "ProxyCommand nohup ssh firewall nc -w1 %h %p"'

              (Note  that  ssh  users  can alternately customize site-specific
              connect options in their .ssh/config file.)

              You can also choose the remote shell program using the RSYNC_RSH
              environment  variable, which accepts the same range of values as
              -e.

              See also the --blocking-io option which is affected by this  op-
              tion.

       --rsync-path=PROGRAM
              Use  this to specify what program is to be run on the remote ma-
              chine to start-up rsync.  Often used when rsync is  not  in  the
              default    remote-shell's   path   (e.g.   --rsync-path=/usr/lo-
              cal/bin/rsync).  Note that PROGRAM is run with  the  help  of  a
              shell,  so  it  can  be any program, script, or command sequence
              you'd care to run, so long as it does not corrupt the  standard-
              in & standard-out that rsync is using to communicate.

              One  tricky  example  is to set a different default directory on
              the remote machine for use with the --relative option.  For  in-
              stance:

                  rsync -avR --rsync-path="cd /a/b && rsync" host:c/d /e/

       --remote-option=OPTION, -M
              This  option is used for more advanced situations where you want
              certain effects to be limited to one side of the transfer  only.
              For instance, if you want to pass --log-file=FILE and --fake-su-
              per to the remote system, specify it like this:

                  rsync -av -M --log-file=foo -M--fake-super src/ dest/

              If you want to have an option affect only the local  side  of  a
              transfer  when it normally affects both sides, send its negation
              to the remote side.  Like this:

                  rsync -av -x -M--no-x src/ dest/

              Be cautious using this, as it is possible to  toggle  an  option
              that  will  cause rsync to have a different idea about what data
              to expect next over the socket, and that will make it fail in  a
              cryptic fashion.

              Note  that  you  should use a separate -M option for each remote
              option you want to pass.  On older rsync versions, the  presence
              of  any  spaces  in  the  remote-option arg could cause it to be
              split into separate remote args, but this requires  the  use  of
              --old-args in a modern rsync.

              When performing a local transfer, the "local" side is the sender
              and the "remote" side is the receiver.

              Note some versions of the popt option-parsing library have a bug
              in  them  that  prevents  you from using an adjacent arg with an
              equal in it  next  to  a  short  option  letter  (e.g.  -M--log-
              file=/tmp/foo).   If  this bug affects your version of popt, you
              can use the version of popt that is included with rsync.

       --cvs-exclude, -C
              This is a useful shorthand for excluding a broad range of  files
              that  you often don't want to transfer between systems.  It uses
              a similar algorithm to CVS to determine if a file should be  ig-
              nored.

              The  exclude  list is initialized to exclude the following items
              (these initial items are marked as perishable -- see the  FILTER
              RULES section):

                  RCS  SCCS CVS CVS.adm RCSLOG cvslog.*  tags TAGS .make.state
                  .nse_depinfo *~ #* .#* ,* _$* *$ *.old  *.bak  *.BAK  *.orig
                  *.rej  .del-*  *.a *.olb *.o *.obj *.so *.exe *.Z *.elc *.ln
                  core .svn/ .git/ .hg/ .bzr/

              then, files listed in a $HOME/.cvsignore are added to  the  list
              and  any files listed in the CVSIGNORE environment variable (all
              cvsignore names are delimited by whitespace).

              Finally, any file is ignored if it is in the same directory as a
              .cvsignore  file and matches one of the patterns listed therein.
              Unlike rsync's filter/exclude files, these patterns are split on
              whitespace.  See the cvs(1) manual for more information.

              If  you're combining -C with your own --filter rules, you should
              note that these CVS excludes are appended at the end of your own
              rules,  regardless  of  where  the -C was placed on the command-
              line.  This makes them a lower priority than any rules you spec-
              ified  explicitly.   If  you want to control where these CVS ex-
              cludes get inserted into your filter rules, you should omit  the
              -C as a command-line option and use a combination of --filter=:C
              and --filter=-C (either on your command-line or by  putting  the
              ":C"  and  "-C" rules into a filter file with your other rules).
              The first option turns on the  per-directory  scanning  for  the
              .cvsignore  file.   The  second option does a one-time import of
              the CVS excludes mentioned above.

       --filter=RULE, -f
              This option allows you to add rules to selectively exclude  cer-
              tain  files  from  the list of files to be transferred.  This is
              most useful in combination with a recursive transfer.

              You may use as many --filter options on the command line as  you
              like  to  build  up the list of files to exclude.  If the filter
              contains whitespace, be sure to quote it so that the shell gives
              the  rule  to  rsync  as a single argument.  The text below also
              mentions that you can use an underscore  to  replace  the  space
              that separates a rule from its arg.

              See  the  FILTER  RULES section for detailed information on this
              option.

       -F     The -F option is a shorthand for adding two  --filter  rules  to
              your command.  The first time it is used is a shorthand for this
              rule:

                  --filter='dir-merge /.rsync-filter'

              This tells rsync to look for per-directory  .rsync-filter  files
              that  have  been  sprinkled  through the hierarchy and use their
              rules to filter the files in the transfer.  If -F  is  repeated,
              it is a shorthand for this rule:

                  --filter='exclude .rsync-filter'

              This  filters  out  the  .rsync-filter files themselves from the
              transfer.

              See the FILTER RULES section for  detailed  information  on  how
              these options work.

       --exclude=PATTERN
              This  option  is  a  simplified form of the --filter option that
              specifies an exclude rule and does not allow the full rule-pars-
              ing syntax of normal filter rules.  This is equivalent to speci-
              fying -f'- PATTERN'.

              See the FILTER RULES section for detailed  information  on  this
              option.

       --exclude-from=FILE
              This option is related to the --exclude option, but it specifies
              a FILE that contains exclude patterns  (one  per  line).   Blank
              lines  in  the file are ignored, as are whole-line comments that
              start with ';' or '#' (filename rules that contain those charac-
              ters are unaffected).

              If  a line begins with "- " (dash, space) or "+ " (plus, space),
              then the type of rule is being explicitly specified  as  an  ex-
              clude  or  an  include (respectively).  Any rules without such a
              prefix are taken to be an exclude.

              If a line consists of just "!", then the  current  filter  rules
              are cleared before adding any further rules.

              If FILE is '-', the list will be read from standard input.

       --include=PATTERN
              This  option  is  a  simplified form of the --filter option that
              specifies an include rule and does not allow the full rule-pars-
              ing syntax of normal filter rules.  This is equivalent to speci-
              fying -f'+ PATTERN'.

              See the FILTER RULES section for detailed  information  on  this
              option.

       --include-from=FILE
              This option is related to the --include option, but it specifies
              a FILE that contains include patterns  (one  per  line).   Blank
              lines  in  the file are ignored, as are whole-line comments that
              start with ';' or '#' (filename rules that contain those charac-
              ters are unaffected).

              If  a line begins with "- " (dash, space) or "+ " (plus, space),
              then the type of rule is being explicitly specified  as  an  ex-
              clude  or  an  include (respectively).  Any rules without such a
              prefix are taken to be an include.

              If a line consists of just "!", then the  current  filter  rules
              are cleared before adding any further rules.

              If FILE is '-', the list will be read from standard input.

       --files-from=FILE
              Using  this option allows you to specify the exact list of files
              to transfer (as read from the specified FILE or '-' for standard
              input).   It  also  tweaks the default behavior of rsync to make
              transferring just the specified files and directories easier:

              o      The --relative (-R) option is  implied,  which  preserves
                     the  path  information that is specified for each item in
                     the file (use --no-relative or --no-R if you want to turn
                     that off).

              o      The  --dirs (-d) option is implied, which will create di-
                     rectories specified in the list on the destination rather
                     than  noisily  skipping  them (use --no-dirs or --no-d if
                     you want to turn that off).

              o      The --archive (-a) option's behavior does not imply --re-
                     cursive (-r), so specify it explicitly, if you want it.

              o      These  side-effects change the default state of rsync, so
                     the position of the --files-from option on  the  command-
                     line has no bearing on how other options are parsed (e.g.
                     -a works the same before or after --files-from,  as  does
                     --no-R and all other options).

              The  filenames  that  are read from the FILE are all relative to
              the source dir -- any leading slashes are removed  and  no  ".."
              references  are  allowed  to go higher than the source dir.  For
              example, take this command:

                  rsync -a --files-from=/tmp/foo /usr remote:/backup

              If /tmp/foo contains the string  "bin"  (or  even  "/bin"),  the
              /usr/bin  directory will be created as /backup/bin on the remote
              host.  If it contains "bin/" (note the trailing slash), the  im-
              mediate  contents  of  the directory would also be sent (without
              needing to be explicitly mentioned in the file -- this began  in
              version  2.6.4).   In  both cases, if the -r option was enabled,
              that dir's entire hierarchy would also be transferred  (keep  in
              mind that -r needs to be specified explicitly with --files-from,
              since it is not implied by -a.  Also note that the effect of the
              (enabled  by  default)  -r  option is to duplicate only the path
              info that is read from the file -- it does not force the  dupli-
              cation of the source-spec path (/usr in this case).

              In  addition,  the --files-from file can be read from the remote
              host instead of the local host if you specify a "host:" in front
              of the file (the host must match one end of the transfer).  As a
              short-cut, you can specify just a prefix of ":" to mean "use the
              remote end of the transfer".  For example:

                  rsync -a --files-from=:/path/file-list src:/ /tmp/copy

              This  would  copy all the files specified in the /path/file-list
              file that was located on the remote "src" host.

              If the --iconv and --secluded-args options are specified and the
              --files-from  filenames are being sent from one host to another,
              the filenames will be translated from the sending host's charset
              to the receiving host's charset.

              NOTE:  sorting the list of files in the --files-from input helps
              rsync to be more efficient, as it  will  avoid  re-visiting  the
              path  elements that are shared between adjacent entries.  If the
              input is not sorted, some path  elements  (implied  directories)
              may  end up being scanned multiple times, and rsync will eventu-
              ally unduplicate them after they get turned into file-list  ele-
              ments.

       --from0, -0
              This  tells  rsync that the rules/filenames it reads from a file
              are terminated by a null ('\0') character,  not  a  NL,  CR,  or
              CR+LF.   This  affects  --exclude-from, --include-from, --files-
              from, and any merged files specified in  a  --filter  rule.   It
              does  not  affect  --cvs-exclude  (since  all  names read from a
              .cvsignore file are split on whitespace).

       --old-args
              This option tells rsync to stop trying to protect the arg values
              on  the remote side from unintended word-splitting or other mis-
              interpretation.  It also allows the client to treat an empty arg
              as a "." instead of generating an error.

              The  default  in a modern rsync is for "shell-active" characters
              (including spaces) to be backslash-escaped in the args that  are
              sent  to the remote shell.  The wildcard characters *, ?, [, & ]
              are not escaped in filename args (allowing them to  expand  into
              multiple  filenames)  while being protected in option args, such
              as --usermap.

              If you have a script that wants to use old-style  arg  splitting
              in its filenames, specify this option once.  If the remote shell
              has a problem with any backslash escapes at  all,  specify  this
              option twice.

              You  may  also control this setting via the RSYNC_OLD_ARGS envi-
              ronment variable.  If it has the value "1", rsync  will  default
              to  a single-option setting.  If it has the value "2" (or more),
              rsync will default to a repeated-option setting.  If it is  "0",
              you'll  get  the  default escaping behavior.  The environment is
              always overridden by manually specified positive or negative op-
              tions (the negative is --no-old-args).

              Note that this option also disables the extra safety check added
              in 3.2.5 that ensures that a remote sender isn't including extra
              top-level  items in the file-list that you didn't request.  This
              side-effect is necessary because we can't  know  for  sure  what
              names to expect when the remote shell is interpreting the args.

              This option conflicts with the --secluded-args option.

       --secluded-args, -s
              This  option  sends all filenames and most options to the remote
              rsync via the protocol (not the remote shell command line) which
              avoids  letting the remote shell modify them.  Wildcards are ex-
              panded on the remote host by rsync instead of a shell.

              This is similar to the default backslash-escaping of  args  that
              was  added  in 3.2.4 (see --old-args) in that it prevents things
              like space splitting  and  unwanted  special-character  side-ef-
              fects.  However, it has the drawbacks of being incompatible with
              older rsync versions (prior to 3.0.0) and of  being  refused  by
              restricted shells that want to be able to inspect all the option
              values for safety.

              This option is useful for those times that you  need  the  argu-
              ment's character set to be converted for the remote host, if the
              remote shell is incompatible with the default backslash-escpaing
              method, or there is some other reason that you want the majority
              of the options and arguments to bypass the command-line  of  the
              remote shell.

              If you combine this option with --iconv, the args related to the
              remote side will be translated from  the  local  to  the  remote
              character-set.   The  translation  happens before wild-cards are
              expanded.  See also the --files-from option.

              You may also control this setting via the RSYNC_PROTECT_ARGS en-
              vironment  variable.   If  it has a non-zero value, this setting
              will be enabled by default, otherwise it will be disabled by de-
              fault.  Either state is overridden by a manually specified posi-
              tive or negative version of this option (note  that  --no-s  and
              --no-secluded-args are the negative versions).  This environment
              variable is also superseded by a non-zero RSYNC_OLD_ARGS export.

              This option conflicts with the --old-args option.

              This option used to be called --protect-args (before 3.2.6)  and
              that older name can still be used (though specifying it as -s is
              always the easiest and most compatible choice).

       --trust-sender
              This option disables two extra validation checks  that  a  local
              client  performs  on the file list generated by a remote sender.
              This option should only be used if you trust the sender  to  not
              put  something  malicious in the file list (something that could
              possibly be done via a modified rsync, a modified shell, or some
              other similar manipulation).

              Normally,  the rsync client (as of version 3.2.5) runs two extra
              validation checks when pulling files from a remote rsync:

              o      It verifies that additional arg items didn't get added at
                     the top of the transfer.

              o      It  verifies  that none of the items in the file list are
                     names that should have been  excluded  (if  filter  rules
                     were specified).

              Note  that  various  options  can  turn off one or both of these
              checks if the option interferes with the  validation.   For  in-
              stance:

              o      Using a per-directory filter file reads filter rules that
                     only the server knows about, so the  filter  checking  is
                     disabled.

              o      Using  the --old-args option allows the sender to manipu-
                     late the requested args, so the arg checking is disabled.

              o      Reading the files-from list from the  server  side  means
                     that  the  client  doesn't  know the arg list, so the arg
                     checking is disabled.

              o      Using --read-batch disables both checks since  the  batch
                     file's  contents will have been verified when it was cre-
                     ated.

              This option may help an under-powered client server if the extra
              pattern  matching is slowing things down on a huge transfer.  It
              can also be used to work around a currently-unknown bug  in  the
              verification logic for a transfer from a trusted sender.

              When  using this option it is a good idea to specify a dedicated
              destination directory, as discussed in the  MULTI-HOST  SECURITY
              section.

       --copy-as=USER[:GROUP]
              This  option  instructs  rsync to use the USER and (if specified
              after a colon) the GROUP for the  copy  operations.   This  only
              works  if  the  user  that  is  running rsync has the ability to
              change users.  If the group is not specified then the user's de-
              fault groups are used.

              This option can help to reduce the risk of an rsync being run as
              root into or out of a directory that  might  have  live  changes
              happening  to  it and you want to make sure that root-level read
              or write actions of system files are not  possible.   While  you
              could  alternatively  run  all  of  rsync as the specified user,
              sometimes you need the root-level host-access credentials to  be
              used,  so this allows rsync to drop root for the copying part of
              the operation after the remote-shell or daemon connection is es-
              tablished.

              The  option  only  affects  one  side of the transfer unless the
              transfer is local, in which case it affects both sides.  Use the
              --remote-option  to  affect  the  remote side, such as -M--copy-
              as=joe.  For a local transfer, the lsh (or lsh.sh) support  file
              provides a local-shell helper script that can be used to allow a
              "localhost:" or "lh:" host-spec to be specified without  needing
              to  setup  any remote shells, allowing you to specify remote op-
              tions that affect the side of the transfer  that  is  using  the
              host-spec  (and using hostname "lh" avoids the overriding of the
              remote directory to the user's home dir).

              For example, the following rsync writes the local files as  user
              "joe":

                  sudo rsync -aiv --copy-as=joe host1:backups/joe/ /home/joe/

              This  makes  all files owned by user "joe", limits the groups to
              those that are available to that user, and makes  it  impossible
              for  the  joe user to do a timed exploit of the path to induce a
              change to a file that the joe user has no permissions to change.

              The following command does a local copy into the "dest/" dir  as
              user  "joe" (assuming you've installed support/lsh into a dir on
              your $PATH):

                  sudo rsync -aive lsh -M--copy-as=joe src/ lh:dest/

       --temp-dir=DIR, -T
              This option instructs rsync to use DIR as  a  scratch  directory
              when  creating  temporary copies of the files transferred on the
              receiving side.  The default behavior is to create  each  tempo-
              rary  file  in  the same directory as the associated destination
              file.  Beginning with rsync 3.1.1, the  temp-file  names  inside
              the specified DIR will not be prefixed with an extra dot (though
              they will still have a random suffix added).

              This option is most often used when the receiving disk partition
              does  not  have  enough free space to hold a copy of the largest
              file in the transfer.  In this case (i.e. when the  scratch  di-
              rectory  is  on  a  different disk partition), rsync will not be
              able to rename each received temporary file over the top of  the
              associated  destination  file,  but  instead  must  copy it into
              place.  Rsync does this by copying the file over the top of  the
              destination  file,  which  means  that the destination file will
              contain truncated data during this copy.  If this were not  done
              this  way  (even if the destination file were first removed, the
              data locally copied to a temporary file in the  destination  di-
              rectory,  and  then renamed into place) it would be possible for
              the old file to continue taking up disk space (if someone had it
              open),  and  thus  there might not be enough room to fit the new
              version on the disk at the same time.

              If you are using this option for reasons other than  a  shortage
              of  disk  space, you may wish to combine it with the --delay-up-
              dates option, which will ensure that all copied  files  get  put
              into  subdirectories  in the destination hierarchy, awaiting the
              end of the transfer.  If you don't have enough room to duplicate
              all the arriving files on the destination partition, another way
              to tell rsync that you aren't overly concerned about disk  space
              is to use the --partial-dir option with a relative path; because
              this tells rsync that it is OK to stash off a copy of  a  single
              file  in  a  subdir in the destination hierarchy, rsync will use
              the partial-dir as a staging area to bring over the copied file,
              and  then  rename it into place from there. (Specifying a --par-
              tial-dir with an absolute path does not have this side-effect.)

       --fuzzy, -y
              This option tells rsync that it should look for a basis file for
              any  destination  file  that  is missing.  The current algorithm
              looks in the same directory as the destination file for either a
              file  that  has  an identical size and modified-time, or a simi-
              larly-named file.  If found, rsync uses the fuzzy basis file  to
              try to speed up the transfer.

              If  the  option is repeated, the fuzzy scan will also be done in
              any matching alternate destination directories that  are  speci-
              fied via --compare-dest, --copy-dest, or --link-dest.

              Note  that  the  use of the --delete option might get rid of any
              potential fuzzy-match files, so  either  use  --delete-after  or
              specify some filename exclusions if you need to prevent this.

       --compare-dest=DIR
              This  option  instructs  rsync to use DIR on the destination ma-
              chine as an additional hierarchy to  compare  destination  files
              against  doing transfers (if the files are missing in the desti-
              nation directory).  If a file is found in DIR that is  identical
              to  the  sender's  file, the file will NOT be transferred to the
              destination directory.  This is useful  for  creating  a  sparse
              backup  of  just files that have changed from an earlier backup.
              This option is typically used to copy into an  empty  (or  newly
              created) directory.

              Beginning  in version 2.6.4, multiple --compare-dest directories
              may be provided, which will cause rsync to search  the  list  in
              the  order  specified  for  an exact match.  If a match is found
              that differs only in attributes, a local copy is  made  and  the
              attributes  updated.  If a match is not found, a basis file from
              one of the DIRs will be selected to try to speed up  the  trans-
              fer.

              If DIR is a relative path, it is relative to the destination di-
              rectory.  See also --copy-dest and --link-dest.

              NOTE: beginning with version 3.1.0, rsync  will  remove  a  file
              from  a  non-empty  destination  hierarchy  if an exact match is
              found in one of the compare-dest hierarchies (making the end re-
              sult more closely match a fresh copy).

       --copy-dest=DIR
              This  option  behaves  like  --compare-dest, but rsync will also
              copy unchanged files found in DIR to the  destination  directory
              using a local copy.  This is useful for doing transfers to a new
              destination while leaving existing files intact, and then  doing
              a  flash-cutover  when  all  files have been successfully trans-
              ferred.

              Multiple --copy-dest directories may  be  provided,  which  will
              cause rsync to search the list in the order specified for an un-
              changed file.  If a match is not found, a basis file from one of
              the DIRs will be selected to try to speed up the transfer.

              If DIR is a relative path, it is relative to the destination di-
              rectory.  See also --compare-dest and --link-dest.

       --link-dest=DIR
              This option behaves like --copy-dest, but  unchanged  files  are
              hard  linked  from  DIR to the destination directory.  The files
              must be identical in all preserved attributes (e.g. permissions,
              possibly  ownership)  in  order  for  the files to be linked to-
              gether.  An example:

                  rsync -av --link-dest=$PWD/prior_dir host:src_dir/ new_dir/

              If files aren't linking, double-check  their  attributes.   Also
              check  if  some attributes are getting forced outside of rsync's
              control, such a mount option that  squishes  root  to  a  single
              user,  or  mounts a removable drive with generic ownership (such
              as OS X's "Ignore ownership on this volume" option).

              Beginning in version 2.6.4, multiple --link-dest directories may
              be  provided,  which  will cause rsync to search the list in the
              order specified for an exact match (there is a limit of 20  such
              directories).   If  a  match  is  found that differs only in at-
              tributes, a local copy is made and the attributes updated.  If a
              match  is  not  found, a basis file from one of the DIRs will be
              selected to try to speed up the transfer.

              This option works best when copying into  an  empty  destination
              hierarchy,  as  existing files may get their attributes tweaked,
              and that can affect alternate destination files via  hard-links.
              Also,  itemizing  of  changes  can get a bit muddled.  Note that
              prior to version 3.1.0, an alternate-directory exact match would
              never be found (nor linked into the destination) when a destina-
              tion file already exists.

              Note that if you combine this option with --ignore-times,  rsync
              will not link any files together because it only links identical
              files together as a substitute for transferring the file,  never
              as an additional check after the file is updated.

              If DIR is a relative path, it is relative to the destination di-
              rectory.  See also --compare-dest and --copy-dest.

              Note that rsync versions prior to 2.6.1 had  a  bug  that  could
              prevent  --link-dest  from working properly for a non-super-user
              when --owner (-o) was specified (or  implied).   You  can  work-
              around this bug by avoiding the -o option (or using --no-o) when
              sending to an old rsync.

       --compress, -z
              With this option, rsync compresses the file data as it  is  sent
              to the destination machine, which reduces the amount of data be-
              ing transmitted -- something that is useful over a slow  connec-
              tion.

              Rsync  supports multiple compression methods and will choose one
              for you unless you force the choice using the  --compress-choice
              (--zc) option.

              Run  rsync --version  to  see the default compress list compiled
              into your version.

              When both sides of  the  transfer  are  at  least  3.2.0,  rsync
              chooses the first algorithm in the client's list of choices that
              is also in the server's list of choices.  If no common  compress
              choice is found, rsync exits with an error.  If the remote rsync
              is too old to support checksum negotiation, its list is  assumed
              to be "zlib".

              The  default  order can be customized by setting the environment
              variable RSYNC_COMPRESS_LIST to a space-separated  list  of  ac-
              ceptable  compression names.  If the string contains a "&" char-
              acter, it is separated into the "client string & server string",
              otherwise  the  same  string applies to both.  If the string (or
              string portion) contains no non-whitespace characters,  the  de-
              fault  compress list is used.  Any unknown compression names are
              discarded from the list, but a list with only invalid names  re-
              sults in a failed negotiation.

              There  are some older rsync versions that were configured to re-
              ject a -z option and require the use of -zz because  their  com-
              pression  library  was not compatible with the default zlib com-
              pression method.  You can usually ignore this  weirdness  unless
              the rsync server complains and tells you to specify -zz.

       --compress-choice=STR, --zc=STR
              This option can be used to override the automatic negotiation of
              the compression algorithm that occurs when --compress  is  used.
              The option implies --compress unless "none" was specified, which
              instead implies --no-compress.

              The compression options that you may be able to use are:

              o      zstd

              o      lz4

              o      zlibx

              o      zlib

              o      none

              Run rsync --version to see the default  compress  list  compiled
              into your version (which may differ from the list above).

              Note  that  if you see an error about an option named --old-com-
              press or --new-compress, this is rsync trying to send the --com-
              press-choice=zlib  or  --compress-choice=zlibx option in a back-
              ward-compatible manner  that  more  rsync  versions  understand.
              This  error indicates that the older rsync version on the server
              will not allow you to force the compression type.

              Note that the "zlibx" compression algorithm is just  the  "zlib"
              algorithm with matched data excluded from the compression stream
              (to try to make it more compatible with an external zlib  imple-
              mentation).

       --compress-level=NUM, --zl=NUM
              Explicitly set the compression level to use (see --compress, -z)
              instead of letting it default.  The --compress option is implied
              as  long as the level chosen is not a "don't compress" level for
              the compression algorithm that is in effect (e.g. zlib  compres-
              sion treats level 0 as "off").

              The  level values vary depending on the checksum in effect.  Be-
              cause rsync will negotiate a checksum choice  by  default  (when
              the  remote rsync is new enough), it can be good to combine this
              option with a --compress-choice (--zc) option unless you're sure
              of the choice in effect.  For example:

                  rsync -aiv --zc=zstd --zl=22 host:src/ dest/

              For  zlib  &  zlibx compression the valid values are from 1 to 9
              with 6 being the default.  Specifying --zl=0  turns  compression
              off, and specifying --zl=-1 chooses the default level of 6.

              For  zstd  compression  the  valid values are from -131072 to 22
              with 3 being the default. Specifying 0 chooses the default of 3.

              For lz4 compression there are no levels, so the value is  always
              0.

              If  you  specify  a  too-large or too-small value, the number is
              silently limited to a valid value.  This allows you  to  specify
              something  like --zl=999999999 and be assured that you'll end up
              with the maximum compression level no matter what algorithm  was
              chosen.

              If  you  want  to  know the compression level that is in effect,
              specify --debug=nstr to see  the  "negotiated  string"  results.
              This     will     report     something     like     "Client com-
              press: zstd (level 3)" (along with the checksum  choice  in  ef-
              fect).

       --skip-compress=LIST
              NOTE: no compression method currently supports per-file compres-
              sion changes, so this option has no effect.

              Override the list of file suffixes that will  be  compressed  as
              little  as possible.  Rsync sets the compression level on a per-
              file basis based on the file's suffix.  If the compression algo-
              rithm  has  an "off" level, then no compression occurs for those
              files.  Other algorithms that  support  changing  the  streaming
              level  on-the-fly  will  have the level minimized to reduces the
              CPU usage as much as possible for a matching file.

              The LIST should be one or more file suffixes (without  the  dot)
              separated  by  slashes  (/).  You may specify an empty string to
              indicate that no files should be skipped.

              Simple character-class matching is supported: each must  consist
              of a list of letters inside the square brackets (e.g. no special
              classes, such as "[:alpha:]", are supported, and '-' has no spe-
              cial meaning).

              The  characters  asterisk (*) and question-mark (?) have no spe-
              cial meaning.

              Here's an example that specifies 6 suffixes to skip (since 1  of
              the 5 rules matches 2 suffixes):

                  --skip-compress=gz/jpg/mp[34]/7z/bz2

              The default file suffixes in the skip-compress list in this ver-
              sion of rsync are:

                  3g2 3gp 7z aac ace apk avi bz2 deb dmg ear f4v flac flv  gpg
                  gz iso jar jpeg jpg lrz lz lz4 lzma lzo m1a m1v m2a m2ts m2v
                  m4a m4b m4p m4r m4v mka mkv mov mp1 mp2 mp3 mp4 mpa mpeg mpg
                  mpv  mts odb odf odg odi odm odp ods odt oga ogg ogm ogv ogx
                  opus otg oth otp ots ott oxt png qt  rar  rpm  rz  rzip  spx
                  squashfs  sxc sxd sxg sxm sxw sz tbz tbz2 tgz tlz ts txz tzo
                  vob war webm webp xz z zip zst

              This list will be replaced by your --skip-compress list  in  all
              but  one  situation:  a  copy  from a daemon rsync will add your
              skipped suffixes to its list of non-compressing files  (and  its
              list may be configured to a different default).

       --numeric-ids
              With  this option rsync will transfer numeric group and user IDs
              rather than using user and group names and mapping them at  both
              ends.

              By  default  rsync will use the username and groupname to deter-
              mine what ownership to give files.  The special uid  0  and  the
              special  group  0  are never mapped via user/group names even if
              the --numeric-ids option is not specified.

              If a user or group has no name on the source system or it has no
              match  on  the  destination system, then the numeric ID from the
              source system is used instead.  See also the use chroot  setting
              in  the  rsyncd.conf manpage for some comments on how the chroot
              setting affects rsync's ability to look  up  the  names  of  the
              users and groups and what you can do about it.

       --usermap=STRING, --groupmap=STRING
              These  options allow you to specify users and groups that should
              be mapped to other values by the receiving side.  The STRING  is
              one  or  more  FROM:TO pairs of values separated by commas.  Any
              matching FROM value from the sender is replaced with a TO  value
              from  the  receiver.   You may specify usernames or user IDs for
              the FROM and TO values, and the FROM value may also be  a  wild-
              card  string,  which  will be matched against the sender's names
              (wild-cards do NOT match against ID numbers,  though  see  below
              for  why  a  '*' matches everything).  You may instead specify a
              range of ID numbers via an inclusive range: LOW-HIGH.  For exam-
              ple:

                  --usermap=0-99:nobody,wayne:admin,*:normal --groupmap=usr:1,1:usr

              The first match in the list is the one that is used.  You should
              specify all your user mappings using a single --usermap  option,
              and/or all your group mappings using a single --groupmap option.

              Note  that  the  sender's  name for the 0 user and group are not
              transmitted to the receiver, so you should  either  match  these
              values  using  a  0, or use the names in effect on the receiving
              side (typically "root").  All other FROM names  match  those  in
              use on the sending side.  All TO names match those in use on the
              receiving side.

              Any IDs that do not have a name on the sending side are  treated
              as  having  an empty name for the purpose of matching.  This al-
              lows them to be matched via a "*" or using an empty  name.   For
              instance:

                  --usermap=:nobody --groupmap=*:nobody

              When  the --numeric-ids option is used, the sender does not send
              any names, so all the IDs are treated as having an  empty  name.
              This  means that you will need to specify numeric FROM values if
              you want to map these nameless IDs to different values.

              For the --usermap option to work, the receiver will need  to  be
              running  as  a super-user (see also the --super and --fake-super
              options).  For the --groupmap option to work, the receiver  will
              need to have permissions to set that group.

              Starting  with  rsync  3.2.4,  the  --usermap option implies the
              --owner (-o) option while  the  --groupmap  option  implies  the
              --group (-g) option (since rsync needs to have those options en-
              abled for the mapping options to work).

              An older rsync client may need to use -s to  avoid  a  complaint
              about wildcard characters, but a modern rsync handles this auto-
              matically.

       --chown=USER:GROUP
              This option forces all files to be  owned  by  USER  with  group
              GROUP.   This  is  a  simpler  interface  than using --usermap &
              --groupmap directly, but it is implemented using  those  options
              internally so they cannot be mixed.  If either the USER or GROUP
              is empty, no mapping for the omitted user/group will occur.   If
              GROUP  is  empty, the trailing colon may be omitted, but if USER
              is empty, a leading colon must be supplied.

              If you specify "--chown=foo:bar", this is exactly  the  same  as
              specifying  "--usermap=*:foo --groupmap=*:bar", only easier (and
              with the same implied --owner and/or --group options).

              An older rsync client may need to use -s to  avoid  a  complaint
              about wildcard characters, but a modern rsync handles this auto-
              matically.

       --timeout=SECONDS
              This option allows you to set a maximum I/O timeout in  seconds.
              If no data is transferred for the specified time then rsync will
              exit.  The default is 0, which means no timeout.

       --contimeout=SECONDS
              This option allows you to set the amount of time that rsync will
              wait  for  its connection to an rsync daemon to succeed.  If the
              timeout is reached, rsync exits with an error.

       --address=ADDRESS
              By default rsync will bind to the wildcard address when connect-
              ing  to  an  rsync  daemon.   The --address option allows you to
              specify a specific IP address (or hostname) to bind to.

              See also the daemon version of the --address option.

       --port=PORT
              This specifies an alternate TCP port number to use  rather  than
              the  default  of  873.  This is only needed if you are using the
              double-colon (::) syntax to connect with an rsync daemon  (since
              the  URL  syntax  has a way to specify the port as a part of the
              URL).

              See also the daemon version of the --port option.

       --sockopts=OPTIONS
              This option can provide endless fun for people who like to  tune
              their  systems  to  the utmost degree.  You can set all sorts of
              socket options which may make  transfers  faster  (or  slower!).
              Read the manpage for the setsockopt() system call for details on
              some of the options you may be able to set.  By default no  spe-
              cial  socket  options  are set.  This only affects direct socket
              connections to a remote rsync daemon.

              See also the daemon version of the --sockopts option.

       --blocking-io
              This tells rsync to use blocking I/O  when  launching  a  remote
              shell  transport.   If  the remote shell is either rsh or remsh,
              rsync defaults to using blocking I/O, otherwise it  defaults  to
              using  non-blocking  I/O.  (Note  that  ssh prefers non-blocking
              I/O.)

       --outbuf=MODE
              This sets the output buffering mode.  The mode can be None  (aka
              Unbuffered), Line, or Block (aka Full).  You may specify as lit-
              tle as a single letter for the mode,  and  use  upper  or  lower
              case.

              The  main use of this option is to change Full buffering to Line
              buffering when rsync's output is going to a file or pipe.

       --itemize-changes, -i
              Requests a simple itemized list of the changes  that  are  being
              made to each file, including attribute changes.  This is exactly
              the same as specifying --out-format='%i %n%L'.   If  you  repeat
              the option, unchanged files will also be output, but only if the
              receiving rsync is at least version 2.6.7 (you can use -vv  with
              older  versions  of  rsync, but that also turns on the output of
              other verbose messages).

              The "%i" escape has a cryptic output that is  11  letters  long.
              The  general  format  is like the string YXcstpoguax, where Y is
              replaced by the type of update being done, X is replaced by  the
              file-type,  and  the other letters represent attributes that may
              be output if they are being modified.

              The update types that replace the Y are as follows:

              o      A < means that a file is being transferred to the  remote
                     host (sent).

              o      A  >  means that a file is being transferred to the local
                     host (received).

              o      A c means that a local change/creation is  occurring  for
                     the  item  (such  as  the  creation of a directory or the
                     changing of a symlink, etc.).

              o      A h means that the item is a hard link  to  another  item
                     (requires --hard-links).

              o      A  .  means that the item is not being updated (though it
                     might have attributes that are being modified).

              o      A * means that the rest of the itemized-output area  con-
                     tains a message (e.g. "deleting").

              The  file-types  that replace the X are: f for a file, a d for a
              directory, an L for a symlink, a D for a device, and a S  for  a
              special file (e.g. named sockets and fifos).

              The  other  letters in the string indicate if some attributes of
              the file have changed, as follows:

              o      "." - the attribute is unchanged.

              o      "+" - the file is newly created.

              o      " " - all the attributes are unchanged (all dots turn  to
                     spaces).

              o      "?"  -  the  change  is unknown (when the remote rsync is
                     old).

              o      A letter indicates an attribute is being updated.

              The attribute that is associated with each letter is as follows:

              o      A c means either that a  regular  file  has  a  different
                     checksum (requires --checksum) or that a symlink, device,
                     or special file has a changed value.  Note  that  if  you
                     are sending files to an rsync prior to 3.0.1, this change
                     flag will be present only for checksum-differing  regular
                     files.

              o      A  s  means  the  size of a regular file is different and
                     will be updated by the file transfer.

              o      A t means the modification time is different and is being
                     updated to the sender's value (requires --times).  An al-
                     ternate value of T means that the modification time  will
                     be  set  to  the  transfer  time,  which  happens  when a
                     file/symlink/device is updated without --times and when a
                     symlink  is  changed and the receiver can't set its time.
                     (Note: when using an rsync 3.0.0 client,  you  might  see
                     the  s  flag combined with t instead of the proper T flag
                     for this time-setting failure.)

              o      A p means the permissions are different and are being up-
                     dated to the sender's value (requires --perms).

              o      An o means the owner is different and is being updated to
                     the sender's value (requires --owner and super-user priv-
                     ileges).

              o      A  g means the group is different and is being updated to
                     the sender's value (requires --group and the authority to
                     set the group).

              o

                     o      A u|n|b indicates the following information:

                            u  means the access (use) time is different and is
                            being updated  to  the  sender's  value  (requires
                            --atimes)

                     o      n means the create time (newness) is different and
                            is being updated to the sender's  value  (requires
                            --crtimes)

                     o      b  means that both the access and create times are
                            being updated

              o      The a means that the ACL information is being changed.

              o      The x means that the extended  attribute  information  is
                     being changed.

              One other output is possible: when deleting files, the "%i" will
              output the string "*deleting" for each item that  is  being  re-
              moved  (assuming  that  you are talking to a recent enough rsync
              that it logs deletions instead of outputting them as  a  verbose
              message).

       --out-format=FORMAT
              This allows you to specify exactly what the rsync client outputs
              to the user on a per-update basis.  The format is a text  string
              containing  embedded  single-character escape sequences prefixed
              with a percent (%) character.  A default format of "%n%L" is as-
              sumed  if  either --info=name or -v is specified (this tells you
              just the name of the file and, if the item is a link,  where  it
              points).  For a full list of the possible escape characters, see
              the log format setting in the rsyncd.conf manpage.

              Specifying the --out-format option implies the  --info=name  op-
              tion,  which will mention each file, dir, etc. that gets updated
              in a significant way  (a  transferred  file,  a  recreated  sym-
              link/device, or a touched directory).  In addition, if the item-
              ize-changes escape (%i) is included in the string (e.g.  if  the
              --itemize-changes  option  was  used),  the logging of names in-
              creases to mention any item that is changed in any way (as  long
              as  the  receiving  side is at least 2.6.4).  See the --itemize-
              changes option for a description of the output of "%i".

              Rsync will output the out-format string prior to a file's trans-
              fer  unless  one of the transfer-statistic escapes is requested,
              in which case the logging is done  at  the  end  of  the  file's
              transfer.  When this late logging is in effect and --progress is
              also specified, rsync will also output the name of the file  be-
              ing  transferred prior to its progress information (followed, of
              course, by the out-format output).

       --log-file=FILE
              This option causes rsync to log what it  is  doing  to  a  file.
              This  is  similar  to the logging that a daemon does, but can be
              requested for the client side and/or the server side of  a  non-
              daemon transfer.  If specified as a client option, transfer log-
              ging will be enabled with a default format of  "%i  %n%L".   See
              the --log-file-format option if you wish to override this.

              Here's  an  example command that requests the remote side to log
              what is happening:

                  rsync -av --remote-option=--log-file=/tmp/rlog src/ dest/

              This is very useful if you need to debug  why  a  connection  is
              closing unexpectedly.

              See also the daemon version of the --log-file option.

       --log-file-format=FORMAT
              This  allows  you  to specify exactly what per-update logging is
              put into the file specified by the --log-file option (which must
              also  be  specified for this option to have any effect).  If you
              specify an empty string, updated files will not be mentioned  in
              the log file.  For a list of the possible escape characters, see
              the log format setting in the rsyncd.conf manpage.

              The default FORMAT used if --log-file is specified and this  op-
              tion is not is '%i %n%L'.

              See also the daemon version of the --log-file-format option.

       --stats
              This  tells  rsync  to  print a verbose set of statistics on the
              file transfer, allowing you to tell how effective rsync's delta-
              transfer  algorithm is for your data.  This option is equivalent
              to --info=stats2  if  combined  with  0  or  1  -v  options,  or
              --info=stats3 if combined with 2 or more -v options.

              The current statistics are as follows:

              o      Number of files  is  the  count  of  all  "files" (in the
                     generic sense),  which  includes  directories,  symlinks,
                     etc.   The  total  count  will  be  followed by a list of
                     counts by filetype (if the total is non-zero).  For exam-
                     ple:  "(reg:  5,  dir:  3,  link: 2, dev: 1, special: 1)"
                     lists the totals for  regular  files,  directories,  sym-
                     links, devices, and special files.  If any of value is 0,
                     it is completely omitted from the list.

              o      Number of created files is the count of how many  "files"
                     (generic  sense)  were  created  (as opposed to updated).
                     The total count will be followed by a list of  counts  by
                     filetype (if the total is non-zero).

              o      Number of deleted files  is the count of how many "files"
                     (generic sense) were deleted.  The total  count  will  be
                     followed by a list of counts by filetype (if the total is
                     non-zero).  Note that this line is only output  if  dele-
                     tions  are  in  effect,  and only if protocol 31 is being
                     used (the default for rsync 3.1.x).

              o      Number of regular files transferred is the count of  nor-
                     mal  files  that  were updated via rsync's delta-transfer
                     algorithm, which does not include  dirs,  symlinks,  etc.
                     Note  that rsync 3.1.0 added the word "regular" into this
                     heading.

              o      Total file size is the total sum of all file sizes in the
                     transfer.   This  does not count any size for directories
                     or special files, but does include the size of symlinks.

              o      Total transferred file size is the total sum of all files
                     sizes for just the transferred files.

              o      Literal data  is  how  much unmatched file-update data we
                     had to send to the receiver for it to  recreate  the  up-
                     dated files.

              o      Matched data  is  how  much data the receiver got locally
                     when recreating the updated files.

              o      File list size is how big the file-list data was when the
                     sender sent it to the receiver.  This is smaller than the
                     in-memory size for the file list due to some  compressing
                     of duplicated data when rsync sends the list.

              o      File list generation time  is  the number of seconds that
                     the sender spent creating the file list.  This requires a
                     modern rsync on the sending side for this to be present.

              o      File list transfer time is the number of seconds that the
                     sender spent sending the file list to the receiver.

              o      Total bytes sent is the count of all the bytes that rsync
                     sent from the client side to the server side.

              o      Total bytes received  is  the  count  of  all non-message
                     bytes that rsync received by the  client  side  from  the
                     server  side.  "Non-message"  bytes  means  that we don't
                     count the bytes for a verbose  message  that  the  server
                     sent to us, which makes the stats more consistent.

       --8-bit-output, -8
              This  tells  rsync to leave all high-bit characters unescaped in
              the output instead of trying to test  them  to  see  if  they're
              valid  in the current locale and escaping the invalid ones.  All
              control characters (but never tabs) are always escaped,  regard-
              less of this option's setting.

              The  escape  idiom  that started in 2.6.7 is to output a literal
              backslash (\) and a hash (#), followed by exactly 3  octal  dig-
              its.  For example, a newline would output as "\#012".  A literal
              backslash that is in a filename is not escaped unless it is fol-
              lowed by a hash and 3 digits (0-9).

       --human-readable, -h
              Output  numbers  in  a  more human-readable format.  There are 3
              possible levels:

              1.     output numbers with a separator between  each  set  of  3
                     digits  (either  a comma or a period, depending on if the
                     decimal point is represented by a period or a comma).

              2.     output numbers in units of 1000 (with a character  suffix
                     for larger units -- see below).

              3.     output numbers in units of 1024.

              The default is human-readable level 1.  Each -h option increases
              the level by one.  You can take the level down to 0  (to  output
              numbers  as  pure  digits) by specifying the --no-human-readable
              (--no-h) option.

              The unit letters that are appended in levels  2  and  3  are:  K
              (kilo), M (mega), G (giga), T (tera), or P (peta).  For example,
              a 1234567-byte file would output as 1.23M in  level-2  (assuming
              that a period is your local decimal point).

              Backward compatibility note: versions of rsync prior to 3.1.0 do
              not support human-readable level 1, and they default to level 0.
              Thus, specifying one or two -h options will behave in a compara-
              ble manner in old and new versions as long as you didn't specify
              a  --no-h  option  prior  to  one  or  more -h options.  See the
              --list-only option for one difference.

       --partial
              By default, rsync will delete any partially transferred file  if
              the  transfer  is interrupted.  In some circumstances it is more
              desirable to keep partially transferred files.  Using the --par-
              tial  option  tells  rsync to keep the partial file which should
              make a subsequent transfer of the rest of the file much faster.

       --partial-dir=DIR
              This option modifies the behavior of the --partial option  while
              also  implying  that  it be enabled.  This enhanced partial-file
              method puts any partially transferred files into  the  specified
              DIR  instead  of writing the partial file out to the destination
              file.  On the next transfer, rsync will use a file found in this
              dir  as data to speed up the resumption of the transfer and then
              delete it after it has served its purpose.

              Note that if --whole-file is specified (or  implied),  any  par-
              tial-dir  files  that are found for a file that is being updated
              will simply be removed (since rsync is sending files without us-
              ing rsync's delta-transfer algorithm).

              Rsync  will  create  the DIR if it is missing, but just the last
              dir -- not the whole path.  This makes it easy to use a relative
              path (such as "--partial-dir=.rsync-partial") to have rsync cre-
              ate the partial-directory in the  destination  file's  directory
              when  it  is  needed,  and then remove it again when the partial
              file is deleted.  Note that this directory removal is only  done
              for a relative pathname, as it is expected that an absolute path
              is to a directory that is reserved for partial-dir work.

              If the partial-dir value is not an absolute path, rsync will add
              an  exclude rule at the end of all your existing excludes.  This
              will prevent the sending of any partial-dir files that may exist
              on the sending side, and will also prevent the untimely deletion
              of partial-dir items on the receiving  side.   An  example:  the
              above  --partial-dir  option  would  add  the equivalent of this
              "perishable" exclude at the  end  of  any  other  filter  rules:
              -f '-p .rsync-partial/'

              If you are supplying your own exclude rules, you may need to add
              your own exclude/hide/protect rule for the partial-dir because:

              1.     the auto-added rule may be ineffective at the end of your
                     other rules, or

              2.     you may wish to override rsync's exclude choice.

              For  instance,  if you want to make rsync clean-up any left-over
              partial-dirs that  may  be  lying  around,  you  should  specify
              --delete-after and add a "risk" filter rule, e.g.  -f 'R .rsync-
              partial/'. Avoid using --delete-before or --delete-during unless
              you  don't  need  rsync  to use any of the left-over partial-dir
              data during the current run.

              IMPORTANT: the --partial-dir should not  be  writable  by  other
              users or it is a security risk!  E.g. AVOID "/tmp"!

              You can also set the partial-dir value the RSYNC_PARTIAL_DIR en-
              vironment variable.  Setting this in the  environment  does  not
              force  --partial to be enabled, but rather it affects where par-
              tial files go when --partial is specified.   For  instance,  in-
              stead  of  using --partial-dir=.rsync-tmp along with --progress,
              you could set RSYNC_PARTIAL_DIR=.rsync-tmp in  your  environment
              and  then use the -P option to turn on the use of the .rsync-tmp
              dir for partial transfers.  The only times  that  the  --partial
              option does not look for this environment value are:

              1.     when  --inplace  was specified (since --inplace conflicts
                     with --partial-dir), and

              2.     when --delay-updates was specified (see below).

              When a modern rsync resumes the transfer of a file in  the  par-
              tial-dir,  that  partial file is now updated in-place instead of
              creating yet another tmp-file copy (so it maxes out  at  dest  +
              tmp  instead  of dest + partial + tmp).  This requires both ends
              of the transfer to be at least version 3.2.0.

              For the purposes of the  daemon-config's  "refuse options"  set-
              ting, --partial-dir does not imply --partial.  This is so that a
              refusal of the --partial option can  be  used  to  disallow  the
              overwriting  of destination files with a partial transfer, while
              still allowing the safer idiom provided by --partial-dir.

       --delay-updates
              This option puts the temporary file from each updated file  into
              a holding directory until the end of the transfer, at which time
              all the files are renamed into place in rapid succession.   This
              attempts to make the updating of the files a little more atomic.
              By default the files are placed into a directory named .~tmp~ in
              each  file's  destination directory, but if you've specified the
              --partial-dir option, that directory will be used instead.   See
              the  comments  in  the --partial-dir section for a discussion of
              how this .~tmp~ dir will be excluded from the transfer, and what
              you  can  do  if  you want rsync to cleanup old .~tmp~ dirs that
              might be lying around.  Conflicts with --inplace and --append.

              This option implies --no-inc-recursive since it needs  the  full
              file  list  in  memory in order to be able to iterate over it at
              the end.

              This option uses more memory on the receiving side (one bit  per
              file  transferred)  and  also requires enough free disk space on
              the receiving side to hold an additional copy of all the updated
              files.   Note  also  that you should not use an absolute path to
              --partial-dir unless:

              1.     there is no chance of any of the files  in  the  transfer
                     having the same name (since all the updated files will be
                     put into a single directory if the path is absolute), and

              2.     there are no mount points in the hierarchy (since the de-
                     layed  updates  will  fail  if they can't be renamed into
                     place).

              See also the "atomic-rsync" python script in the "support"  sub-
              dir  for  an  update algorithm that is even more atomic (it uses
              --link-dest and a parallel hierarchy of files).

       --prune-empty-dirs, -m
              This option tells the receiving rsync to get rid of empty direc-
              tories  from  the  file-list,  including nested directories that
              have no non-directory children.  This is useful for avoiding the
              creation  of  a  bunch  of  useless directories when the sending
              rsync is recursively scanning a hierarchy  of  files  using  in-
              clude/exclude/filter rules.

              This  option  can still leave empty directories on the receiving
              side if you make use of TRANSFER_RULES.

              Because the file-list is actually being pruned, this option also
              affects  what  directories  get deleted when a delete is active.
              However, keep in mind that excluded files  and  directories  can
              prevent existing items from being deleted due to an exclude both
              hiding source files and protecting destination files.   See  the
              perishable filter-rule option for how to avoid this.

              You  can  prevent  the pruning of certain empty directories from
              the file-list by using a global "protect" filter.  For instance,
              this  option would ensure that the directory "emptydir" was kept
              in the file-list:

                  --filter 'protect emptydir/'

              Here's an example that copies all .pdf  files  in  a  hierarchy,
              only  creating the necessary destination directories to hold the
              .pdf files, and ensures that any superfluous files and  directo-
              ries  in  the  destination  are removed (note the hide filter of
              non-directories being used instead of an exclude):

                  rsync -avm --del --include='*.pdf' -f 'hide,! */' src/ dest

              If you didn't want to remove superfluous destination files,  the
              more  time-honored options of --include='*/' --exclude='*' would
              work fine in place of the hide-filter (if that is  more  natural
              to you).

       --progress
              This  option  tells  rsync  to  print  information  showing  the
              progress of the transfer.  This gives a bored user something  to
              watch.   With  a  modern  rsync  this  is the same as specifying
              --info=flist2,name,progress, but any user-supplied settings  for
              those      info      flags      takes      precedence      (e.g.
              --info=flist0 --progress).

              While rsync  is  transferring  a  regular  file,  it  updates  a
              progress line that looks like this:

                  782448  63%  110.64kB/s    0:00:04

              In  this example, the receiver has reconstructed 782448 bytes or
              63% of the sender's file, which is being reconstructed at a rate
              of  110.64 kilobytes per second, and the transfer will finish in
              4 seconds if the current rate is maintained until the end.

              These statistics can be misleading if rsync's delta-transfer al-
              gorithm  is  in use.  For example, if the sender's file consists
              of the basis file followed by additional data, the reported rate
              will  probably  drop  dramatically when the receiver gets to the
              literal data, and the transfer will probably take much longer to
              finish  than  the  receiver  estimated  as  it was finishing the
              matched part of the file.

              When the file transfer finishes,  rsync  replaces  the  progress
              line with a summary line that looks like this:

                  1,238,099 100%  146.38kB/s    0:00:08  (xfr#5, to-chk=169/396)

              In this example, the file was 1,238,099 bytes long in total, the
              average rate of transfer for the whole file was 146.38 kilobytes
              per  second  over the 8 seconds that it took to complete, it was
              the 5th transfer of a regular file during the current rsync ses-
              sion, and there are 169 more files for the receiver to check (to
              see if they are up-to-date or not) remaining out of the 396  to-
              tal files in the file-list.

              In  an  incremental  recursion  scan, rsync won't know the total
              number of files in the file-list until it reaches  the  ends  of
              the scan, but since it starts to transfer files during the scan,
              it will display a line with the text "ir-chk"  (for  incremental
              recursion  check)  instead  of  "to-chk" until the point that it
              knows the full size of the list, at which point it  will  switch
              to using "to-chk".  Thus, seeing "ir-chk" lets you know that the
              total count of files in the file list is still going to increase
              (and  each  time  it does, the count of files left to check will
              increase by the number of the files added to the list).

       -P     The -P option is equivalent to "--partial --progress".  Its pur-
              pose  is to make it much easier to specify these two options for
              a long transfer that may be interrupted.

              There is also a --info=progress2 option that outputs  statistics
              based  on the whole transfer, rather than individual files.  Use
              this flag without outputting a filename (e.g. avoid -v or  spec-
              ify  --info=name0)  if you want to see how the transfer is doing
              without scrolling the screen with a lot  of  names.  (You  don't
              need   to   specify  the  --progress  option  in  order  to  use
              --info=progress2.)

              Finally, you can get an instant progress report by sending rsync
              a signal of either SIGINFO or SIGVTALRM.  On BSD systems, a SIG-
              INFO is generated by typing a Ctrl+T  (Linux  doesn't  currently
              support  a  SIGINFO  signal).   When the client-side process re-
              ceives one of those signals, it sets a flag to output  a  single
              progress  report  which is output when the current file transfer
              finishes (so it may take a little time if a big  file  is  being
              handled  when  the  signal  arrives).   A filename is output (if
              needed) followed by  the  --info=progress2  format  of  progress
              info.   If  you don't know which of the 3 rsync processes is the
              client process, it's OK to signal all of them  (since  the  non-
              client processes ignore the signal).

              CAUTION:  sending  SIGVTALRM  to an older rsync (pre-3.2.0) will
              kill it.

       --password-file=FILE
              This option allows you to provide a password  for  accessing  an
              rsync daemon via a file or via standard input if FILE is -.  The
              file should contain just the password on  the  first  line  (all
              other lines are ignored).  Rsync will exit with an error if FILE
              is world readable or if a root-run rsync command  finds  a  non-
              root-owned file.

              This  option does not supply a password to a remote shell trans-
              port such as ssh; to learn how to do that,  consult  the  remote
              shell's  documentation.   When accessing an rsync daemon using a
              remote shell as the transport, this option only comes  into  ef-
              fect after the remote shell finishes its authentication (i.e. if
              you have also specified a password in the daemon's config file).

       --early-input=FILE
              This option allows rsync to send up to 5K of data to the  "early
              exec"  script on its stdin.  One possible use of this data is to
              give the script a secret that can be used to mount an  encrypted
              filesystem (which you should unmount in the the "post-xfer exec"
              script).

              The daemon must be at least version 3.2.1.

       --list-only
              This option will cause the source files to be listed instead  of
              transferred.   This  option  is  inferred  if  there is a single
              source arg and no destination specified, so its main uses are:

              1.     to turn a copy command that includes  a  destination  arg
                     into a file-listing command, or

              2.     to be able to specify more than one source arg.  Note: be
                     sure to include the destination.

              CAUTION: keep in mind that a source arg with a wild-card is  ex-
              panded  by  the shell into multiple args, so it is never safe to
              try to specify a single wild-card arg to try to infer  this  op-
              tion. A safe example is:

                  rsync -av --list-only foo* dest/

              This  option  always uses an output format that looks similar to
              this:

                  drwxrwxr-x          4,096 2022/09/30 12:53:11 support
                  -rw-rw-r--             80 2005/01/11 10:37:37 support/Makefile

              The only option that affects this output style is (as of  3.1.0)
              the  --human-readable  (-h)  option.   The  default is to output
              sizes as byte counts with digit separators (in  a  14-character-
              width  column).   Specifying  at  least  one -h option makes the
              sizes output with unit suffixes.  If you  want  old-style  byte-
              count  sizes without digit separators (and an 11-character-width
              column) use --no-h.

              Compatibility note: when requesting a remote  listing  of  files
              from  an rsync that is version 2.6.3 or older, you may encounter
              an error if you ask for a non-recursive listing.   This  is  be-
              cause  a file listing implies the --dirs option w/o --recursive,
              and older rsyncs don't have that option.  To avoid this problem,
              either specify the --no-dirs option (if you don't need to expand
              a directory's content), or turn on  recursion  and  exclude  the
              content of subdirectories: -r --exclude='/*/*'.

       --bwlimit=RATE
              This  option allows you to specify the maximum transfer rate for
              the data sent over the socket, specified in  units  per  second.
              The  RATE value can be suffixed with a string to indicate a size
              multiplier, and may be a fractional value (e.g. --bwlimit=1.5m).
              If  no  suffix  is specified, the value will be assumed to be in
              units of 1024 bytes (as if "K" or "KiB" had been appended).  See
              the  --max-size  option  for  a description of all the available
              suffixes.  A value of 0 specifies no limit.

              For backward-compatibility  reasons,  the  rate  limit  will  be
              rounded  to  the  nearest KiB unit, so no rate smaller than 1024
              bytes per second is possible.

              Rsync writes data over the socket in  blocks,  and  this  option
              both  limits the size of the blocks that rsync writes, and tries
              to keep the average transfer rate at the requested limit.   Some
              burstiness  may  be  seen where rsync writes out a block of data
              and then sleeps to bring the average rate into compliance.

              Due to the internal buffering of data, the --progress option may
              not  be  an  accurate  reflection  on how fast the data is being
              sent.  This is because some files can show up as  being  rapidly
              sent  when the data is quickly buffered, while other can show up
              as very slow when the flushing  of  the  output  buffer  occurs.
              This may be fixed in a future version.

              See also the daemon version of the --bwlimit option.

       --stop-after=MINS, (--time-limit=MINS)
              This  option tells rsync to stop copying when the specified num-
              ber of minutes has elapsed.

              For maximal flexibility, rsync does not communicate this  option
              to  the remote rsync since it is usually enough that one side of
              the connection quits as specified.  This allows the option's use
              even  when only one side of the connection supports it.  You can
              tell the remote side about the time limit using  --remote-option
              (-M), should the need arise.

              The --time-limit version of this option is deprecated.

       --stop-at=y-m-dTh:m
              This option tells rsync to stop copying when the specified point
              in time has been reached. The date & time can be fully specified
              in   a   numeric   format  of  year-month-dayThour:minute  (e.g.
              2000-12-31T23:59) in the local timezone.  You may choose to sep-
              arate the date numbers using slashes instead of dashes.

              The  value can also be abbreviated in a variety of ways, such as
              specifying a 2-digit year and/or leaving off various values.  In
              all cases, the value will be taken to be the next possible point
              in time where the supplied information matches.   If  the  value
              specifies  the  current time or a past time, rsync exits with an
              error.

              For example, "1-30" specifies the next January 30th (at midnight
              local  time),  "14:00"  specifies the next 2 P.M., "1" specifies
              the next 1st of the month at midnight, "31" specifies  the  next
              month where we can stop on its 31st day, and ":59" specifies the
              next 59th minute after the hour.

              For maximal flexibility, rsync does not communicate this  option
              to  the remote rsync since it is usually enough that one side of
              the connection quits as specified.  This allows the option's use
              even  when only one side of the connection supports it.  You can
              tell the remote side about the time limit using  --remote-option
              (-M),  should  the  need arise.  Do keep in mind that the remote
              host may have a different default timezone than your local host.

       --fsync
              Cause the receiving side to fsync each finished file.  This  may
              slow  down  the  transfer, but can help to provide peace of mind
              when updating critical files.

       --write-batch=FILE
              Record a file that can later be  applied  to  another  identical
              destination with --read-batch.  See the "BATCH MODE" section for
              details, and also the --only-write-batch option.

              This option overrides the negotiated checksum &  compress  lists
              and  always negotiates a choice based on old-school md5/md4/zlib
              choices.  If you want a more modern choice, use the  --checksum-
              choice (--cc) and/or --compress-choice (--zc) options.

       --only-write-batch=FILE
              Works like --write-batch, except that no updates are made on the
              destination system when  creating  the  batch.   This  lets  you
              transport  the  changes to the destination system via some other
              means and then apply the changes via --read-batch.

              Note that you can feel free to write the batch directly to  some
              portable  media:  if this media fills to capacity before the end
              of the transfer, you can just apply that partial transfer to the
              destination  and repeat the whole process to get the rest of the
              changes (as long as you don't mind a partially updated  destina-
              tion system while the multi-update cycle is happening).

              Also note that you only save bandwidth when pushing changes to a
              remote system because this allows the batched  data  to  be  di-
              verted  from  the  sender  into the batch file without having to
              flow over the wire to the receiver (when pulling, the sender  is
              remote, and thus can't write the batch).

       --read-batch=FILE
              Apply  all of the changes stored in FILE, a file previously gen-
              erated by --write-batch.  If FILE is -, the batch data  will  be
              read  from  standard input. See the "BATCH MODE" section for de-
              tails.

       --protocol=NUM
              Force an older protocol version to be used.  This is useful  for
              creating  a  batch file that is compatible with an older version
              of rsync.  For instance, if rsync 2.6.4 is being used  with  the
              --write-batch  option,  but  rsync 2.6.3 is what will be used to
              run the --read-batch option, you should use "--protocol=28" when
              creating  the  batch file to force the older protocol version to
              be used in the batch file (assuming you can't upgrade the  rsync
              on the reading system).

       --iconv=CONVERT_SPEC
              Rsync  can  convert  filenames between character sets using this
              option.  Using a CONVERT_SPEC of "." tells rsync to look up  the
              default  character-set via the locale setting.  Alternately, you
              can fully specify what conversion to do by giving a local and  a
              remote  charset  separated  by  a comma in the order --iconv=LO-
              CAL,REMOTE, e.g. --iconv=utf8,iso88591.  This order ensures that
              the  option will stay the same whether you're pushing or pulling
              files.  Finally, you can specify either  --no-iconv  or  a  CON-
              VERT_SPEC  of  "-" to turn off any conversion.  The default set-
              ting of this option is site-specific, and can also  be  affected
              via the RSYNC_ICONV environment variable.

              For  a  list of what charset names your local iconv library sup-
              ports, you can run "iconv --list".

              If you specify  the  --secluded-args  (-s)  option,  rsync  will
              translate the filenames you specify on the command-line that are
              being sent to the remote host.  See also  the  --files-from  op-
              tion.

              Note  that  rsync  does not do any conversion of names in filter
              files (including include/exclude files).  It is up to you to en-
              sure  that  you're  specifying  matching rules that can match on
              both sides of the transfer.  For instance, you can specify extra
              include/exclude  rules  if there are filename differences on the
              two sides that need to be accounted for.

              When you pass an --iconv option to an rsync daemon  that  allows
              it,  the daemon uses the charset specified in its "charset" con-
              figuration parameter regardless of the remote charset you  actu-
              ally  pass.   Thus,  you may feel free to specify just the local
              charset for a daemon transfer (e.g.  --iconv=utf8).

       --ipv4, -4 or --ipv6, -6
              Tells rsync to prefer IPv4/IPv6 when creating sockets or running
              ssh.   This  affects sockets that rsync has direct control over,
              such as the outgoing socket when directly  contacting  an  rsync
              daemon,  as well as the forwarding of the -4 or -6 option to ssh
              when rsync can deduce that ssh  is  being  used  as  the  remote
              shell.   For  other  remote  shells  you'll  need to specify the
              "--rsh SHELL -4" option directly (or whatever IPv4/IPv6 hint op-
              tions it uses).

              See also the daemon version of these options.

              If  rsync  was compiled without support for IPv6, the --ipv6 op-
              tion will have no effect.  The rsync --version output will  con-
              tain "no IPv6" if is the case.

       --checksum-seed=NUM
              Set  the checksum seed to the integer NUM.  This 4 byte checksum
              seed is included in each block and MD4 file checksum calculation
              (the  more  modern MD5 file checksums don't use a seed).  By de-
              fault the checksum seed is generated by the server and  defaults
              to  the  current  time().  This option is used to set a specific
              checksum seed, which is useful for applications  that  want  re-
              peatable  block checksums, or in the case where the user wants a
              more random checksum seed.  Setting NUM to 0 causes rsync to use
              the default of time() for checksum seed.

EXECUTION EXAMPLE:
COMMAND INPUT:
rsync --version

COMMAND OUTPUT:
rsync  version 3.2.7  protocol version 32
Copyright (C) 1996-2022 by Andrew Tridgell, Wayne Davison, and others.
Web site: https://rsync.samba.org/
Capabilities:
    64-bit files, 64-bit inums, 64-bit timestamps, 64-bit long ints,
    socketpairs, symlinks, symtimes, hardlinks, hardlink-specials,
    hardlink-symlinks, IPv6, atimes, batchfiles, inplace, append, ACLs,
    xattrs, optional secluded-args, iconv, prealloc, stop-at, no crtimes
Optimizations:
    SIMD-roll, no asm-roll, openssl-crypto, no asm-MD5
Checksum list:
    xxh128 xxh3 xxh64 (xxhash) md5 md4 sha1 none
Compress list:
    zstd lz4 zlibx zlib none
Daemon auth list:
    sha512 sha256 sha1 md5 md4

rsync comes with ABSOLUTELY NO WARRANTY.  This is free software, and you
are welcome to redistribute it under certain conditions.  See the GNU
General Public Licence for details.

===

COMMAND: awk

DESCRIPTION: mawk - pattern scanning and text processing language

USAGE: mawk  [-W  option]  [-F value] [-v var=value] [--] 'program text' [file
       ...]
       mawk [-W option] [-F value] [-v var=value] [-f program-file] [--] [file
       ...]

OPTIONS:
-F value       sets the field separator, FS, to value.

       -f file        Program  text is read from file instead of from the com-
                      mand line.  Multiple -f options are allowed.

       -v var=value   assigns value to program variable var.

       --             indicates the unambiguous end of options.

       The above options will be available with any POSIX compatible implemen-
       tation  of  AWK.  Implementation specific options are prefaced with -W.
       mawk provides these:

       -W dump        writes an assembler like listing of the internal  repre-
                      sentation  of the program to stdout and exits 0 (on suc-
                      cessful compilation).

       -W exec file   Program text is read from file and this is the last  op-
                      tion.

                      This  is a useful alternative to -f on systems that sup-
                      port the #!  "magic number"  convention  for  executable
                      scripts.   Those  implicitly  pass  the  pathname of the
                      script itself as the final parameter, and expect no more
                      than  one  "-"  option on the #! line.  Because mawk can
                      combine multiple -W options separated by commas, you can
                      use this option when an additional -W option is needed.

       -W help        prints  a  usage  message  to  stderr and exits (same as
                      "-W usage").

       -W interactive sets unbuffered writes to stdout and line buffered reads
                      from  stdin.  Records from stdin are lines regardless of
                      the value of RS.

       -W posix_space forces mawk not to consider '\n' to be space.

       -W random=num  calls srand with the given parameter (and overrides  the
                      auto-seeding behavior).

       -W sprintf=num adjusts  the  size  of mawk's internal sprintf buffer to
                      num bytes.  More than rare use of this option  indicates
                      mawk should be recompiled.

       -W usage       prints  a  usage  message  to  stderr and exits (same as
                      "-W help").

       -W version     mawk writes its version and copyright to stdout and com-
                      piled limits to stderr and exits 0.

       mawk  accepts  abbreviations for any of these options, e.g., "-W v" and
       "-Wv" both tell mawk to show its version.

       mawk allows multiple -W options to be combined by  separating  the  op-
       tions  with commas, e.g., -Wsprint=2000,posix.  This is useful for exe-
       cutable #!  "magic number" invocations in which only  one  argument  is
       supported, e.g., -Winteractive,exec.

EXECUTION EXAMPLE:
COMMAND INPUT:
awk --version

COMMAND OUTPUT:
awk: not an option: --version

===

COMMAND: sed

DESCRIPTION: sed - stream editor for filtering and transforming text

USAGE: sed [-V] [--version] [--help] [-n] [--quiet] [--silent]
           [-l N] [--line-length=N] [-u] [--unbuffered]
           [-E] [-r] [--regexp-extended]
           [-e script] [--expression=script]
           [-f script-file] [--file=script-file]
           [script-if-no-other-script]
           [file...]

EXECUTION EXAMPLE:
COMMAND INPUT:
sed --version

COMMAND OUTPUT:
sed (GNU sed) 4.9
Packaged by Debian
Copyright (C) 2022 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <https://gnu.org/licenses/gpl.html>.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Written by Jay Fenlason, Tom Lord, Ken Pizzini,
Paolo Bonzini, Jim Meyering, and Assaf Gordon.

This sed program was built with SELinux support.
SELinux is disabled on this system.

GNU sed home page: <https://www.gnu.org/software/sed/>.
General help using GNU software: <https://www.gnu.org/gethelp/>.
E-mail bug reports to: <bug-sed@gnu.org>.

===

COMMAND: cut

DESCRIPTION: cut - remove sections from each line of files

USAGE: cut OPTION... [FILE]...

EXECUTION EXAMPLE:
COMMAND INPUT:
cut --version

COMMAND OUTPUT:
cut (GNU coreutils) 9.1
Copyright (C) 2022 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <https://gnu.org/licenses/gpl.html>.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Written by David M. Ihnat, David MacKenzie, and Jim Meyering.

===

COMMAND: tr

DESCRIPTION: tr - translate or delete characters

USAGE: tr [OPTION]... STRING1 [STRING2]

EXECUTION EXAMPLE:
COMMAND INPUT:
tr --help | head -5

COMMAND OUTPUT:
Usage: tr [OPTION]... STRING1 [STRING2]
Translate, squeeze, and/or delete characters from standard input,
writing to standard output.  STRING1 and STRING2 specify arrays of
characters ARRAY1 and ARRAY2 that control the action.

===

COMMAND: diff

DESCRIPTION: diff - compare files line by line

USAGE: diff [OPTION]... FILES

EXECUTION EXAMPLE:
COMMAND INPUT:
diff --version

COMMAND OUTPUT:
diff (GNU diffutils) 3.8
Copyright (C) 2021 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <https://gnu.org/licenses/gpl.html>.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Written by Paul Eggert, Mike Haertel, David Hayes,
Richard Stallman, and Len Tower.

===

COMMAND: vi

DESCRIPTION: vim - Vi IMproved, a programmer's text editor

USAGE: vim [options] [file ..]
       vim [options] -
       vim [options] -t tag
       vim [options] -q [errorfile]

       ex
       view
       gvim gview evim eview
       rvim rview rgvim rgview

OPTIONS:
The  options may be given in any order, before or after filenames.  Op-
       tions without an argument can be combined after a single dash.

       +[num]      For the first file the cursor will be  positioned  on  line
                   "num".   If "num" is missing, the cursor will be positioned
                   on the last line.

       +/{pat}     For the first file the cursor will  be  positioned  in  the
                   line  with  the  first  occurrence  of  {pat}.   See ":help
                   search-pattern" for the available search patterns.

       +{command}

       -c {command}
                   {command} will be executed after the first  file  has  been
                   read.   {command}  is interpreted as an Ex command.  If the
                   {command} contains spaces it must  be  enclosed  in  double
                   quotes  (this depends on the shell that is used).  Example:
                   vim "+set si" main.c
                   Note: You can use up to 10 "+" or "-c" commands.

       -S {file}   {file} will be sourced after the first file has been  read.
                   This  is  equivalent  to -c "source {file}".  {file} cannot
                   start with '-'.  If {file} is omitted "Session.vim" is used
                   (only works when -S is the last argument).

       --cmd {command}
                   Like  using  "-c",  but the command is executed just before
                   processing any vimrc file.  You can use up to 10  of  these
                   commands, independently from "-c" commands.

       -A          If  Vim  has  been compiled with ARABIC support for editing
                   right-to-left oriented files and Arabic  keyboard  mapping,
                   this  option  starts  Vim  in Arabic mode, i.e. 'arabic' is
                   set.  Otherwise an error message is given and Vim aborts.

       -b          Binary mode.  A few options will be set that makes it  pos-
                   sible to edit a binary or executable file.

       -C          Compatible.   Set  the 'compatible' option.  This will make
                   Vim behave mostly like Vi, even though a  .vimrc  file  ex-
                   ists.

       -d          Start in diff mode.  There should between two to eight file
                   name arguments.  Vim will open all the files and show  dif-
                   ferences between them.  Works like vimdiff(1).

       -d {device} Open  {device}  for  use as a terminal.  Only on the Amiga.
                   Example: "-d con:20/30/600/150".

       -D          Debugging.  Go to debugging mode when executing  the  first
                   command from a script.

       -e          Start  Vim  in Ex mode, just like the executable was called
                   "ex".

       -E          Start Vim in improved Ex mode, just like the executable was
                   called "exim".

       -f          Foreground.  For the GUI version, Vim will not fork and de-
                   tach from the shell it was started in.  On the  Amiga,  Vim
                   is  not restarted to open a new window.  This option should
                   be used when Vim is executed by a program  that  will  wait
                   for  the  edit session to finish (e.g. mail).  On the Amiga
                   the ":sh" and ":!" commands will not work.

       --nofork    Foreground.  For the GUI version, Vim will not fork and de-
                   tach from the shell it was started in.

       -F          If  Vim  has  been  compiled with FKMAP support for editing
                   right-to-left oriented files and  Farsi  keyboard  mapping,
                   this  option  starts  Vim  in  Farsi mode, i.e. 'fkmap' and
                   'rightleft' are set.  Otherwise an error message  is  given
                   and Vim aborts.

       -g          If  Vim has been compiled with GUI support, this option en-
                   ables the GUI.  If no GUI support was compiled in, an error
                   message is given and Vim aborts.

       -h          Give a bit of help about the command line arguments and op-
                   tions.  After this Vim exits.

       -H          If Vim has been compiled with RIGHTLEFT support for editing
                   right-to-left  oriented  files and Hebrew keyboard mapping,
                   this option starts Vim in Hebrew  mode,  i.e.  'hkmap'  and
                   'rightleft'  are  set.  Otherwise an error message is given
                   and Vim aborts.

       -i {viminfo}
                   Specifies the filename to use when reading or  writing  the
                   viminfo  file,  instead  of the default "~/.viminfo".  This
                   can also be used to skip the use of the .viminfo  file,  by
                   giving the name "NONE".

       -L          Same as -r.

       -l          Lisp mode.  Sets the 'lisp' and 'showmatch' options on.

       -m          Modifying  files  is  disabled.  Resets the 'write' option.
                   You can still modify the buffer, but writing a file is  not
                   possible.

       -M          Modifications  not  allowed.   The 'modifiable' and 'write'
                   options will be unset, so that changes are not allowed  and
                   files  can  not be written.  Note that these options can be
                   set to enable making modifications.

       -N          No-compatible mode.  Resets the 'compatible' option.   This
                   will  make Vim behave a bit better, but less Vi compatible,
                   even though a .vimrc file does not exist.

       -n          No swap file will be used.  Recovery after a crash will  be
                   impossible.   Handy  if  you  want to edit a file on a very
                   slow medium (e.g. floppy).  Can also  be  done  with  ":set
                   uc=0".  Can be undone with ":set uc=200".

       -nb         Become an editor server for NetBeans.  See the docs for de-
                   tails.

       -o[N]       Open N windows stacked.  When N is omitted, open one window
                   for each file.

       -O[N]       Open  N  windows side by side.  When N is omitted, open one
                   window for each file.

       -p[N]       Open N tab pages.  When N is omitted, open one tab page for
                   each file.

       -R          Read-only  mode.   The  'readonly' option will be set.  You
                   can still edit the buffer, but will be prevented from acci-
                   dentally overwriting a file.  If you do want to overwrite a
                   file, add an exclamation mark to  the  Ex  command,  as  in
                   ":w!".   The  -R  option  also  implies  the -n option (see
                   above).  The 'readonly' option  can  be  reset  with  ":set
                   noro".  See ":help 'readonly'".

       -r          List  swap files, with information about using them for re-
                   covery.

       -r {file}   Recovery mode.  The swap file is used to recover a  crashed
                   editing  session.   The  swap  file is a file with the same
                   filename as the text file with ".swp" appended.  See ":help
                   recovery".

       -s          Silent  mode.   Only  when started as "Ex" or when the "-e"
                   option was given before the "-s" option.

       -s {scriptin}
                   The script file {scriptin} is read.  The characters in  the
                   file  are  interpreted  as if you had typed them.  The same
                   can be done with the command ":source! {scriptin}".  If the
                   end of the file is reached before the editor exits, further
                   characters are read from the keyboard.

       -T {terminal}
                   Tells Vim the name of the terminal you are using.  Only re-
                   quired  when  the  automatic way doesn't work.  Should be a
                   terminal known to Vim (builtin) or defined in  the  termcap
                   or terminfo file.

       -u {vimrc}  Use  the  commands in the file {vimrc} for initializations.
                   All the other initializations are  skipped.   Use  this  to
                   edit  a special kind of files.  It can also be used to skip
                   all initializations by giving the name "NONE".  See  ":help
                   initialization" within vim for more details.

       -U {gvimrc} Use  the  commands in the file {gvimrc} for GUI initializa-
                   tions.  All the other GUI initializations are skipped.   It
                   can  also be used to skip all GUI initializations by giving
                   the name "NONE".  See ":help gui-init" within vim for  more
                   details.

       -V[N]       Verbose.   Give  messages about which files are sourced and
                   for reading and writing a viminfo file.  The optional  num-
                   ber N is the value for 'verbose'.  Default is 10.

       -v          Start  Vim  in Vi mode, just like the executable was called
                   "vi".  This only has effect when the executable  is  called
                   "ex".

       -w {scriptout}
                   All  the  characters that you type are recorded in the file
                   {scriptout}, until you exit Vim.  This  is  useful  if  you
                   want  to  create  a script file to be used with "vim -s" or
                   ":source!".  If the {scriptout} file exists, characters are
                   appended.

       -W {scriptout}
                   Like -w, but an existing file is overwritten.

       -x          Use encryption when writing files.  Will prompt for a crypt
                   key.

       -X          Don't connect to the X server.  Shortens startup time in  a
                   terminal,  but  the  window title and clipboard will not be
                   used.

       -y          Start Vim in easy mode, just like the executable was called
                   "evim"  or "eview".  Makes Vim behave like a click-and-type
                   editor.

       -Z          Restricted mode.  Works like  the  executable  starts  with
                   "r".

       --          Denotes  the end of the options.  Arguments after this will
                   be handled as a file name.  This can  be  used  to  edit  a
                   filename that starts with a '-'.

       --clean     Do  not  use  any  personal  configuration (vimrc, plugins,
                   etc.).  Useful to see if a problem reproduces with a  clean
                   Vim setup.

       --echo-wid  GTK GUI only: Echo the Window ID on stdout.

       --help      Give a help message and exit, just like "-h".

       --literal   Take  file  name  arguments  literally, do not expand wild-
                   cards.  This has no effect on Unix where the shell  expands
                   wildcards.

       --noplugin  Skip loading plugins.  Implied by -u NONE.

       --remote    Connect to a Vim server and make it edit the files given in
                   the rest of the arguments.  If no server is found a warning
                   is given and the files are edited in the current Vim.

       --remote-expr {expr}
                   Connect  to  a  Vim server, evaluate {expr} in it and print
                   the result on stdout.

       --remote-send {keys}
                   Connect to a Vim server and send {keys} to it.

       --remote-silent
                   As --remote, but without the  warning  when  no  server  is
                   found.

       --remote-wait
                   As  --remote,  but  Vim  does not exit until the files have
                   been edited.

       --remote-wait-silent
                   As --remote-wait, but without the warning when no server is
                   found.

       --serverlist
                   List the names of all Vim servers that can be found.

       --servername {name}
                   Use  {name}  as the server name.  Used for the current Vim,
                   unless used with a --remote argument, then it's the name of
                   the server to connect to.

       --socketid {id}
                   GTK  GUI only: Use the GtkPlug mechanism to run gvim in an-
                   other window.

       --startuptime {file}
                   During startup write timing messages to the file {fname}.

       --version   Print version information and exit.

EXECUTION EXAMPLE:
COMMAND INPUT:
vi --version | head -3

COMMAND OUTPUT:
VIM - Vi IMproved 9.0 (2022 Jun 28, compiled May 04 2023 10:24:44)
Included patches: 1-1378, 1499
Modified by team+vim@tracker.debian.org

===

COMMAND: nano

DESCRIPTION: nano - Nano's ANOther editor, inspired by Pico

USAGE: nano [options] [[+line[,column]] file]...

       nano [options] [[+[crCR](/|?)string] file]...

OPTIONS:
-A, --smarthome
              Make the Home key smarter.  When Home is pressed anywhere but at
              the  very  beginning of non-whitespace characters on a line, the
              cursor will jump to that beginning  (either  forwards  or  back-
              wards).  If the cursor is already at that position, it will jump
              to the true beginning of the line.

       -B, --backup
              When saving a file, back up the previous version  of  it,  using
              the current filename suffixed with a tilde (~).

       -C directory, --backupdir=directory
              Make  and  keep  not  just  one backup file, but make and keep a
              uniquely numbered one every time a file is saved -- when backups
              are enabled (-B).  The uniquely numbered files are stored in the
              specified directory.

       -D, --boldtext
              For the interface, use bold instead of reverse video.  This will
              be  overridden  by  setting the options titlecolor, statuscolor,
              keycolor, functioncolor, numbercolor,  and/or  selectedcolor  in
              your nanorc file.  See nanorc(5).

       -E, --tabstospaces
              Convert each typed tab to spaces -- to the number of spaces that
              a tab at that position would take up.

       -F, --multibuffer
              Read a file into a new buffer by default.

       -G, --locking
              Use vim-style file locking when editing files.

       -H, --historylog
              Save the last hundred search strings and replacement strings and
              executed  commands,  so  they can be easily reused in later ses-
              sions.

       -I, --ignorercfiles
              Don't look at the system's nanorc nor at the user's nanorc.

       -J number, --guidestripe=number
              Draw a vertical stripe at the given column, to  help  judge  the
              width of the text.  (The color of the stripe can be changed with
              set stripecolor in your nanorc file.)

       -K, --rawsequences
              Interpret escape sequences directly, instead of  asking  ncurses
              to translate them.  (If you need this option to get some keys to
              work properly, it means that the terminfo  terminal  description
              that  is  used  does not fully match the actual behavior of your
              terminal.  This can happen when you ssh into a BSD machine,  for
              example.)  Using this option disables nano's mouse support.

       -L, --nonewlines
              Don't  automatically add a newline when a text does not end with
              one.  (This can cause you to save non-POSIX text files.)

       -M, --trimblanks
              Snip trailing whitespace from the wrapped  line  when  automatic
              hard-wrapping occurs or when text is justified.

       -N, --noconvert
              Disable automatic conversion of files from DOS/Mac format.

       -O, --bookstyle
              When  justifying,  treat any line that starts with whitespace as
              the beginning of a paragraph (unless auto-indenting is on).

       -P, --positionlog
              For the 200 most recent files, log the last position of the cur-
              sor,  and  place it at that position again upon reopening such a
              file.

       -Q "regex", --quotestr="regex"
              Set the regular expression for matching the quoting  part  of  a
              line.   The default value is "^([ \t]*([!#%:;>|}]|//))+".  (Note
              that \t stands for an actual Tab.)  This makes  it  possible  to
              rejustify blocks of quoted text when composing email, and to re-
              wrap blocks of line comments when writing source code.

       -R, --restricted
              Restricted mode: don't read or write to any file  not  specified
              on  the  command  line.  This means: don't read or write history
              files; don't allow suspending; don't allow spell checking; don't
              allow  a  file to be appended to, prepended to, or saved under a
              different name if it already has  one;  and  don't  make  backup
              files.   Restricted  mode can also be activated by invoking nano
              with any name beginning with 'r' (e.g. "rnano").

       -S, --softwrap
              Display over multiple screen rows lines that exceed the screen's
              width.  (You can make this soft-wrapping occur at whitespace in-
              stead of rudely at the screen's edge, by using also --atblanks.)
              (The old short option, -$, is deprecated.)

       -T number, --tabsize=number
              Set  the  size (width) of a tab to number columns.  The value of
              number must be greater than 0.  The default value is 8.

       -U, --quickblank
              Make status-bar messages disappear after 1 keystroke instead  of
              after  20.  Note that option -c (--constantshow) overrides this.
              When option --minibar or --zero is in effect, --quickblank makes
              a  message  disappear after 0.8 seconds instead of after the de-
              fault 1.5 seconds.

       -V, --version
              Show the current version number and exit.

       -W, --wordbounds
              Detect word boundaries differently by treating punctuation char-
              acters as part of a word.

       -X "characters", --wordchars="characters"
              Specify  which other characters (besides the normal alphanumeric
              ones) should be considered as part of a word.  When  using  this
              option, you probably want to omit -W (--wordbounds).

       -Y name, --syntax=name
              Specify  the  name  of the syntax highlighting to use from among
              the ones defined in the nanorc files.

       -Z, --zap
              Let an unmodified Backspace or Delete erase  the  marked  region
              (instead  of  a single character, and without affecting the cut-
              buffer).

       -a, --atblanks
              When doing soft line wrapping, wrap lines at whitespace  instead
              of always at the edge of the screen.

       -b, --breaklonglines
              Automatically  hard-wrap  the current line when it becomes over-
              long.  (This option is the opposite of -w (--nowrap) -- the last
              one given takes effect.)

       -c, --constantshow
              Constantly  show  the  cursor  position on the status bar.  Note
              that this overrides option -U (--quickblank).

       -d, --rebinddelete
              Interpret the Delete and Backspace keys differently so that both
              Backspace  and  Delete  work properly.  You should only use this
              option when on your system either Backspace acts like Delete  or
              Delete acts like Backspace.

       -e, --emptyline
              Do  not  use  the  line below the title bar, leaving it entirely
              blank.

       -f file, --rcfile=file
              Read only this file for setting nano's options, instead of read-
              ing both the system-wide and the user's nanorc files.

       -g, --showcursor
              Make  the  cursor visible in the file browser (putting it on the
              highlighted item) and in the help viewer.   Useful  for  braille
              users and people with poor vision.

       -h, --help
              Show a summary of the available command-line options and exit.

       -i, --autoindent
              Automatically  indent a newly created line to the same number of
              tabs and/or spaces as the previous line (or as the next line  if
              the previous line is the beginning of a paragraph).

       -j, --jumpyscrolling
              Scroll the buffer contents per half-screen instead of per line.

       -k, --cutfromcursor
              Make  the  'Cut Text' command (normally ^K) cut from the current
              cursor position to the end of the line, instead of  cutting  the
              entire line.

       -l, --linenumbers
              Display  line  numbers  to the left of the text area.  (Any line
              with an anchor additionally gets a mark in the margin.)

       -m, --mouse
              Enable mouse support, if available for your  system.   When  en-
              abled,  mouse  clicks  can  be used to place the cursor, set the
              mark (with a double click), and execute  shortcuts.   The  mouse
              will work in the X Window System, and on the console when gpm is
              running.  Text can still be selected through dragging by holding
              down the Shift key.

       -n, --noread
              Treat  any  name  given on the command line as a new file.  This
              allows nano to write to named pipes: it will start with a  blank
              buffer,  and  will  write  to  the  pipe when the user saves the
              "file".  This way nano can be used as an editor  in  combination
              with  for instance gpg without having to write sensitive data to
              disk first.

       -o directory, --operatingdir=directory
              Set the operating directory.  This makes nano set  up  something
              similar to a chroot.

       -p, --preserve
              Preserve  the XON and XOFF sequences (^Q and ^S) so they will be
              caught by the terminal.

       -q, --indicator
              Display a "scrollbar" on the righthand side of the edit  window.
              It shows the position of the viewport in the buffer and how much
              of the buffer is covered by the viewport.

       -r number, --fill=number
              Set the target width for justifying and automatic  hard-wrapping
              at  this number of columns.  If the value is 0 or less, wrapping
              will occur at the width of the screen minus number columns,  al-
              lowing the wrap point to vary along with the width of the screen
              if the screen is resized.  The default value is -8.

       -s "program [argument ...]", --speller="program [argument ...]"
              Use this command to perform spell checking and  correcting,  in-
              stead  of using the built-in corrector that calls hunspell(1) or
              spell(1).

       -t, --saveonexit
              Save a changed buffer without prompting (when exiting with ^X).

       -u, --unix
              Save a file by default in Unix format.   This  overrides  nano's
              default  behavior  of  saving  a file in the format that it had.
              (This option has no effect when you also use --noconvert.)

       -v, --view
              Just view the file and disallow editing: read-only  mode.   This
              mode  allows  the user to open also other files for viewing, un-
              less --restricted is given too.

       -w, --nowrap
              Do not automatically hard-wrap the current line when it  becomes
              overlong.  This is the default.  (This option is the opposite of
              -b (--breaklonglines) -- the last one given takes effect.)

       -x, --nohelp
              Don't show the two help lines at the bottom of the screen.

       -y, --afterends
              Make Ctrl+Right and Ctrl+Delete stop at word ends instead of be-
              ginnings.

       -!, --magic
              When neither the file's name nor its first line give a clue, try
              using libmagic to determine the applicable syntax.

       -%, --stateflags
              Use the top-right corner of the screen for  showing  some  state
              flags:  I  when  auto-indenting,  M  when the mark is on, L when
              hard-wrapping (breaking long lines), R when recording  a  macro,
              and  S  when soft-wrapping.  When the buffer is modified, a star
              (*) is shown after the filename in the center of the title bar.

       -_, --minibar
              Suppress the title bar and instead show  information  about  the
              current buffer at the bottom of the screen, in the space for the
              status bar.  In this "minibar" the  filename  is  shown  on  the
              left,  followed  by an asterisk if the buffer has been modified.
              On the right are displayed the current line and  column  number,
              the  code  of the character under the cursor (in Unicode format:
              U+xxxx), the same flags as are shown by --stateflags, and a per-
              centage  that  expresses  how  far  the  cursor is into the file
              (linewise).  When a file is  loaded  or  saved,  and  also  when
              switching  between buffers, the number of lines in the buffer is
              displayed after the filename.  This number is cleared  upon  the
              next  keystroke, or replaced with an [i/n] counter when multiple
              buffers are open.  The line plus column numbers and the  charac-
              ter code are displayed only when --constantshow is used, and can
              be toggled on and off with M-C.  The state flags  are  displayed
              only when --stateflags is used.

       -0, --zero
              Hide  all  elements of the interface (title bar, status bar, and
              help lines) and use all rows of the  terminal  for  showing  the
              contents  of the buffer.  The status bar appears only when there
              is a significant message, and disappears after  1.5  seconds  or
              upon the next keystroke.  With M-Z the title bar plus status bar
              can be toggled.  With M-X the help lines.

EXECUTION EXAMPLE:
COMMAND INPUT:
nano --version

COMMAND OUTPUT:
GNU nano, version 7.2
 (C) 2023 the Free Software Foundation and various contributors
 Compiled options: --disable-libmagic --enable-utf8

===

COMMAND: less

DESCRIPTION: less - opposite of more

USAGE: less -?
       less --help
       less -V
       less --version
       less [-[+]aABcCdeEfFgGiIJKLmMnNqQrRsSuUVwWX~]
            [-b space] [-h lines] [-j line] [-k keyfile]
            [-{oO} logfile] [-p pattern] [-P prompt] [-t tag]
            [-T tagsfile] [-x tab,...] [-y lines] [-[z] lines]
            [-# shift] [+[+]cmd] [--] [filename]...
       (See  the  OPTIONS section for alternate option syntax with long option
       names.)

OPTIONS:
below),  this will change the setting of that option and print a
              message describing the new setting.  If a ^P (CONTROL-P) is  en-
              tered  immediately  after the dash, the setting of the option is
              changed but no message is printed.  If the option letter  has  a
              numeric  value (such as -b or -h), or a string value (such as -P
              or -t), a new value may be entered after the option letter.   If
              no  new  value is entered, a message describing the current set-
              ting is printed and nothing is changed.

       --     Like the - command, but takes a long option  name  (see  OPTIONS
              below) rather than a single option letter.  You must press ENTER
              or RETURN after typing the option name.  A ^P immediately  after
              the  second dash suppresses printing of a message describing the
              new setting, as in the - command.

       -+     Followed by one of the command line option letters this will re-
              set  the  option  to its default setting and print a message de-
              scribing the new setting.  (The  "-+X"  command  does  the  same
              thing  as  "-+X"  on  the command line.)  This does not work for
              string-valued options.

       --+    Like the -+ command, but takes a long option name rather than  a
              single option letter.

       -!     Followed  by  one  of the command line option letters, this will
              reset the option to the "opposite" of its  default  setting  and
              print  a message describing the new setting.  This does not work
              for numeric or string-valued options.

       --!    Like the -! command, but takes a long option name rather than  a
              single option letter.

       _      (Underscore.)   Followed  by one of the command line option let-
              ters, this will print a message describing the  current  setting
              of that option.  The setting of the option is not changed.

       __     (Double underscore.)  Like the _ (underscore) command, but takes
              a long option name rather than a single option letter.  You must
              press ENTER or RETURN after typing the option name.

       +cmd   Causes  the specified cmd to be executed each time a new file is
              examined.  For example, +G causes less to initially display each
              file starting at the end rather than the beginning.

       V      Prints the version number of less being run.

       q or Q or :q or :Q or ZZ
              Exits less.

       The  following four commands may or may not be valid, depending on your
       particular installation.

       v      Invokes an editor to edit the current file  being  viewed.   The
              editor is taken from the environment variable VISUAL if defined,
              or EDITOR if VISUAL is not defined, or defaults to "vi" if  nei-
              ther  VISUAL  nor EDITOR is defined.  See also the discussion of
              LESSEDIT under the section on PROMPTS below.

       ! shell-command
              Invokes a shell to run the shell-command given.  A percent  sign
              (%)  in the command is replaced by the name of the current file.
              A pound sign (#) is replaced by the name of the previously exam-
              ined  file.   "!!"  repeats the last shell command.  "!" with no
              shell command simply invokes a  shell.   On  Unix  systems,  the
              shell  is taken from the environment variable SHELL, or defaults
              to "sh".  On MS-DOS and OS/2 systems, the shell  is  the  normal
              command processor.

       | <m> shell-command
              <m>  represents  any  mark letter.  Pipes a section of the input
              file to the given shell command.  The section of the file to  be
              piped  is between the position marked by the letter and the cur-
              rent screen.  The entire current screen is included,  regardless
              of  whether  the  marked position is before or after the current
              screen.  <m> may also be ^ or $ to indicate beginning or end  of
              file  respectively.   If <m> is . or newline, the current screen
              is piped.

       s filename
              Save the input to a file.  This only works if  the  input  is  a
              pipe, not an ordinary file.

EXECUTION EXAMPLE:
COMMAND INPUT:
less --version

COMMAND OUTPUT:
less 590 (GNU regular expressions)
Copyright (C) 1984-2021  Mark Nudelman

less comes with NO WARRANTY, to the extent permitted by law.
For information about the terms of redistribution,
see the file named README in the less distribution.
Home page: https://greenwoodsoftware.com/less

===

COMMAND: strings

DESCRIPTION: strings - print the sequences of printable characters in files

USAGE: strings [-afovV] [-min-len]
               [-n min-len] [--bytes=min-len]
               [-t radix] [--radix=radix]
               [-e encoding] [--encoding=encoding]
               [-U method] [--unicode=method]
               [-] [--all] [--print-file-name]
               [-T bfdname] [--target=bfdname]
               [-w] [--include-all-whitespace]
               [-s] [--output-separator sep_string]
               [--help] [--version] file...

OPTIONS:
-a
       --all
       -   Scan the whole file, regardless of what sections it contains or
           whether those sections are loaded or initialized.  Normally this is
           the default behaviour, but strings can be configured so that the -d
           is the default instead.

           The - option is position dependent and forces strings to perform
           full scans of any file that is mentioned after the - on the command
           line, even if the -d option has been specified.

       -d
       --data
           Only print strings from initialized, loaded data sections in the
           file.  This may reduce the amount of garbage in the output, but it
           also exposes the strings program to any security flaws that may be
           present in the BFD library used to scan and load sections.  Strings
           can be configured so that this option is the default behaviour.  In
           such cases the -a option can be used to avoid using the BFD library
           and instead just print all of the strings found in the file.

       -f
       --print-file-name
           Print the name of the file before each string.

       --help
           Print a summary of the program usage on the standard output and
           exit.

       -min-len
       -n min-len
       --bytes=min-len
           Print sequences of displayable characters that are at least min-len
           characters long.  If not specified a default minimum length of 4 is
           used.  The distinction between displayable and non-displayable
           characters depends upon the setting of the -e and -U options.
           Sequences are always terminated at control characters such as new-
           line and carriage-return, but not the tab character.

       -o  Like -t o.  Some other versions of strings have -o act like -t d
           instead.  Since we can not be compatible with both ways, we simply
           chose one.

       -t radix
       --radix=radix
           Print the offset within the file before each string.  The single
           character argument specifies the radix of the offset---o for octal,
           x for hexadecimal, or d for decimal.

       -e encoding
       --encoding=encoding
           Select the character encoding of the strings that are to be found.
           Possible values for encoding are: s = single-7-bit-byte characters
           (default), S = single-8-bit-byte characters, b = 16-bit bigendian,
           l = 16-bit littleendian, B = 32-bit bigendian, L = 32-bit
           littleendian.  Useful for finding wide character strings. (l and b
           apply to, for example, Unicode UTF-16/UCS-2 encodings).

       -U [d|i|l|e|x|h]
       --unicode=[default|invalid|locale|escape|hex|highlight]
           Controls the display of UTF-8 encoded multibyte characters in
           strings.  The default (--unicode=default) is to give them no
           special treatment, and instead rely upon the setting of the
           --encoding option.  The other values for this option automatically
           enable --encoding=S.

           The --unicode=invalid option treats them as non-graphic characters
           and hence not part of a valid string.  All the remaining options
           treat them as valid string characters.

           The --unicode=locale option displays them in the current locale,
           which may or may not support UTF-8 encoding.  The --unicode=hex
           option displays them as hex byte sequences enclosed between <>
           characters.  The --unicode=escape option displays them as escape
           sequences (\uxxxx) and the --unicode=highlight option displays them
           as escape sequences highlighted in red (if supported by the output
           device).  The colouring is intended to draw attention to the
           presence of unicode sequences where they might not be expected.

       -T bfdname
       --target=bfdname
           Specify an object code format other than your system's default
           format.

       -v
       -V
       --version
           Print the program version number on the standard output and exit.

       -w
       --include-all-whitespace
           By default tab and space characters are included in the strings
           that are displayed, but other whitespace characters, such a
           newlines and carriage returns, are not.  The -w option changes this
           so that all whitespace characters are considered to be part of a
           string.

       -s
       --output-separator
           By default, output strings are delimited by a new-line. This option
           allows you to supply any string to be used as the output record
           separator.  Useful with --include-all-whitespace where strings may
           contain new-lines internally.

       @file
           Read command-line options from file.  The options read are inserted
           in place of the original @file option.  If file does not exist, or
           cannot be read, then the option will be treated literally, and not
           removed.

           Options in file are separated by whitespace.  A whitespace
           character may be included in an option by surrounding the entire
           option in either single or double quotes.  Any character (including
           a backslash) may be included by prefixing the character to be
           included with a backslash.  The file may itself contain additional
           @file options; any such options will be processed recursively.

EXECUTION EXAMPLE:
COMMAND INPUT:
strings /bin/ls | head -5

COMMAND OUTPUT:
/lib64/ld-linux-x86-64.so.2
k.;n@	
_ITM_deregisterTMCloneTable
__gmon_start__
_ITM_registerTMCloneTable

===

COMMAND: sudo

DESCRIPTION: sudo, sudoedit -- execute a command as another user

USAGE: sudo -h | -K | -k | -V
     sudo -v [-ABkNnS] [-g group] [-h host] [-p prompt] [-u user]
     sudo -l [-ABkNnS] [-g group] [-h host] [-p prompt] [-U user] [-u user]
          [command [arg ...]]
     sudo [-ABbEHnPS] [-C num] [-D directory] [-g group] [-h host] [-p prompt]
          [-R directory] [-r role] [-t type] [-T timeout] [-u user]
          [VAR=value] [-i | -s] [command [arg ...]]
     sudoedit [-ABkNnS] [-C num] [-D directory] [-g group] [-h host]
          [-p prompt] [-R directory] [-r role] [-t type] [-T timeout]
          [-u user] file ...

EXECUTION EXAMPLE:
COMMAND INPUT:
sudo -V

COMMAND OUTPUT:
Sudo version 1.9.13p3
Sudoers policy plugin version 1.9.13p3
Sudoers file grammar version 50
Sudoers I/O plugin version 1.9.13p3
Sudoers audit plugin version 1.9.13p3

===

COMMAND: bash

DESCRIPTION: bash - GNU Bourne-Again SHell

USAGE: bash [options] [command_string | file]

OPTIONS:
All of the single-character shell options documented in the description
       of the set builtin command, including -o, can be used as  options  when
       the  shell  is invoked.  In addition, bash interprets the following op-
       tions when it is invoked:

       -c        If the -c option is present, then commands are read from  the
                 first non-option argument command_string.  If there are argu-
                 ments after the command_string, the  first  argument  is  as-
                 signed  to $0 and any remaining arguments are assigned to the
                 positional parameters.  The assignment to $0 sets the name of
                 the shell, which is used in warning and error messages.
       -i        If the -i option is present, the shell is interactive.
       -l        Make bash act as if it had been invoked as a login shell (see
                 INVOCATION below).
       -r        If the -r option is present,  the  shell  becomes  restricted
                 (see RESTRICTED SHELL below).
       -s        If  the -s option is present, or if no arguments remain after
                 option processing, then commands are read from  the  standard
                 input.   This  option  allows the positional parameters to be
                 set when invoking an interactive shell or when reading  input
                 through a pipe.
       -v        Print shell input lines as they are read.
       -x        Print commands and their arguments as they are executed.
       -D        A  list of all double-quoted strings preceded by $ is printed
                 on the standard output.  These are the strings that are  sub-
                 ject to language translation when the current locale is not C
                 or POSIX.  This implies the -n option; no  commands  will  be
                 executed.
       [-+]O [shopt_option]
                 shopt_option  is  one  of  the  shell options accepted by the
                 shopt  builtin  (see  SHELL  BUILTIN  COMMANDS  below).    If
                 shopt_option is present, -O sets the value of that option; +O
                 unsets it.  If shopt_option is not supplied,  the  names  and
                 values  of the shell options accepted by shopt are printed on
                 the standard output.  If the invocation  option  is  +O,  the
                 output is displayed in a format that may be reused as input.
       --        A  --  signals the end of options and disables further option
                 processing.  Any arguments after the -- are treated as  file-
                 names and arguments.  An argument of - is equivalent to --.

       Bash  also  interprets  a number of multi-character options.  These op-
       tions must appear on the command line before the  single-character  op-
       tions to be recognized.

       --debugger
              Arrange for the debugger profile to be executed before the shell
              starts.  Turns on extended debugging mode (see  the  description
              of the extdebug option to the shopt builtin below).
       --dump-po-strings
              Equivalent  to -D, but the output is in the GNU gettext po (por-
              table object) file format.
       --dump-strings
              Equivalent to -D.
       --help Display a usage message on standard  output  and  exit  success-
              fully.
       --init-file file
       --rcfile file
              Execute  commands  from file instead of the system wide initial-
              ization file /etc/bash.bashrc and the standard personal initial-
              ization  file ~/.bashrc if the shell is interactive (see INVOCA-
              TION below).

       --login
              Equivalent to -l.

       --noediting
              Do not use the GNU readline library to read command  lines  when
              the shell is interactive.

       --noprofile
              Do  not read either the system-wide startup file /etc/profile or
              any  of  the  personal  initialization  files   ~/.bash_profile,
              ~/.bash_login,  or  ~/.profile.   By  default,  bash reads these
              files when it is invoked as a login shell  (see  INVOCATION  be-
              low).

       --norc Do  not  read  and  execute  the system wide initialization file
              /etc/bash.bashrc and the personal initialization file  ~/.bashrc
              if  the  shell  is interactive.  This option is on by default if
              the shell is invoked as sh.

       --posix
              Change the behavior of bash where the default operation  differs
              from the POSIX standard to match the standard (posix mode).  See
              SEE ALSO below for a reference to a document  that  details  how
              posix mode affects bash's behavior.

       --restricted
              The shell becomes restricted (see RESTRICTED SHELL below).

       --verbose
              Equivalent to -v.

       --version
              Show  version information for this instance of bash on the stan-
              dard output and exit successfully.

EXECUTION EXAMPLE:
COMMAND INPUT:
bash --version

COMMAND OUTPUT:
GNU bash, version 5.2.15(1)-release (x86_64-pc-linux-gnu)
Copyright (C) 2022 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>

This is free software; you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

===

COMMAND: env

DESCRIPTION: env - run a program in a modified environment

USAGE: env [OPTION]... [-] [NAME=VALUE]... [COMMAND [ARG]...]

OPTIONS:
-S/--split-string usage in scripts
       The  -S option allows specifying multiple parameters in a script.  Run-
       ning a script named 1.pl containing the following first line:

              #!/usr/bin/env -S perl -w -T
              ...

       Will execute perl -w -T 1.pl .

       Without the '-S' parameter the script will likely fail with:

              /usr/bin/env: 'perl -w -T': No such file or directory

       See the full documentation for more details.

   --default-signal[=SIG] usage
       This option allows setting a signal  handler  to  its  default  action,
       which  is  not  possible using the traditional shell trap command.  The
       following example ensures that seq will be  terminated  by  SIGPIPE  no
       matter  how  this  signal  is being handled in the process invoking the
       command.

              sh -c 'env --default-signal=PIPE seq inf | head -n1'

EXECUTION EXAMPLE:
COMMAND INPUT:
env | head -5

COMMAND OUTPUT:
USER=vega
SSH_CLIENT=130.208.133.151 64316 22
XDG_SESSION_TYPE=tty
SHLVL=1
MOTD_SHOWN=pam

===

COMMAND: printenv

DESCRIPTION: printenv - print all or part of environment

USAGE: printenv [OPTION]... [VARIABLE]...

EXECUTION EXAMPLE:
COMMAND INPUT:
printenv | head -5

COMMAND OUTPUT:
USER=vega
SSH_CLIENT=130.208.133.151 64316 22
XDG_SESSION_TYPE=tty
SHLVL=1
MOTD_SHOWN=pam

===

COMMAND: docker

DESCRIPTION: docker - Docker image and container command line interface

USAGE: docker [OPTIONS] COMMAND [ARG...]

       docker [--help|-v|--version]

OPTIONS:
--help
         Print usage statement

       --config=""
         Specifies  the location of the Docker client configuration files. The
       default is '~/.docker'.

       -D, --debug=true|false
         Enable debug mode. Default is false.

       -H, --host=[unix:///var/run/docker.sock]: tcp://[host]:[port][path]  to
       bind or unix://[/path/to/socket] to use.
         The socket(s) to bind to in daemon mode specified using one or more
         tcp://host:port/path,  unix:///path/to/socket,  fd://*  or fd://sock-
       etfd.
         If the tcp port is not specified, then it will default to either 2375
       when
         --tls is off, or 2376 when --tls is on, or --tlsverify is specified.

       -l, --log-level="debug|info|warn|error|fatal"
         Set the logging level. Default is info.

       --tls=true|false
         Use TLS; implied by --tlsverify. Default is false.

       --tlscacert=~/.docker/ca.pem
         Trust certs signed only by this CA.

       --tlscert=~/.docker/cert.pem
         Path to TLS certificate file.

       --tlskey=~/.docker/key.pem
         Path to TLS key file.

       --tlsverify=true|false
         Use  TLS and verify the remote (daemon: verify client, client: verify
       daemon).
         Default is false.

       -v, --version=true|false
         Print version information and quit. Default is false.

EXECUTION EXAMPLE:
COMMAND INPUT:
docker --version

COMMAND OUTPUT:
Docker version 20.10.24+dfsg1, build 297e128

===

COMMAND: python3

DESCRIPTION: python  - an interpreted, interactive, object-oriented programming lan-
       guage

USAGE: python [ -B ] [ -b ] [ -d ] [ -E ] [ -h ] [ -i ] [ -I ]
              [ -m module-name ] [ -q ] [ -O ] [ -OO ] [ -P ] [ -s ] [ -S ]  [
       -u ]
              [ -v ] [ -V ] [ -W argument ] [ -x ] [ -X option ] [ -?  ]
              [ --check-hash-based-pycs default | always | never ]
              [ --help ] [ --help-env ] [ --help-xoptions ] [ --help-all ]
              [ -c command | script | - ] [ arguments ]

OPTIONS:
-B     Don't write .pyc files on import. See also  PYTHONDONTWRITEBYTE-
              CODE.

       -b     Issue   warnings  about  str(bytes_instance),  str(bytearray_in-
              stance) and comparing bytes/bytearray with str. (-bb: issue  er-
              rors)

       -c command
              Specify  the command to execute (see next section).  This termi-
              nates the option list (following options are passed as arguments
              to the command).

       --check-hash-based-pycs mode
              Configure  how Python evaluates the up-to-dateness of hash-based
              .pyc files.

       -d     Turn on parser debugging output (for expert only,  depending  on
              compilation options).

       -E     Ignore environment variables like PYTHONPATH and PYTHONHOME that
              modify the behavior of the interpreter.

       -h ,  -? ,  --help
              Prints the usage for the interpreter executable and exits.

       --help-env
              Prints help about Python-specific environment variables and  ex-
              its.

       --help-xoptions
              Prints help about implementation-specific -X options and exits.

       --help-all
              Prints complete usage information and exits.

       -i     When  a  script  is passed as first argument or the -c option is
              used, enter interactive mode after executing the script  or  the
              command.  It does not read the $PYTHONSTARTUP file.  This can be
              useful to inspect global variables  or  a  stack  trace  when  a
              script raises an exception.

       -I     Run Python in isolated mode. This also implies -E, -P and -s. In
              isolated mode sys.path contains neither the  script's  directory
              nor  the user's site-packages directory. All PYTHON* environment
              variables are ignored, too.  Further restrictions may be imposed
              to prevent the user from injecting malicious code.

       -m module-name
              Searches  sys.path for the named module and runs the correspond-
              ing .py file as a script. This terminates the option list  (fol-
              lowing options are passed as arguments to the module).

       -O     Remove  assert  statements and any code conditional on the value
              of __debug__; augment the filename for compiled (bytecode) files
              by adding .opt-1 before the .pyc extension.

       -OO    Do  -O and also discard docstrings; change the filename for com-
              piled (bytecode) files by adding .opt-2 before the  .pyc  exten-
              sion.

       -P     Don't   automatically  prepend  a  potentially  unsafe  path  to
              sys.path such as the current directory, the  script's  directory
              or  an  empty  string.  See  also the PYTHONSAFEPATH environment
              variable.

       -q     Do not print the version and copyright messages. These  messages
              are also suppressed in non-interactive mode.

       -s     Don't add user site directory to sys.path.

       -S     Disable the import of the module site and the site-dependent ma-
              nipulations of sys.path that it entails.  Also disable these ma-
              nipulations if site is explicitly imported later.

       -u     Force  the stdout and stderr streams to be unbuffered.  This op-
              tion has no effect on the stdin stream.

       -v     Print a message each time a module is initialized,  showing  the
              place  (filename  or  built-in  module) from which it is loaded.
              When given twice, print a message for each file that is  checked
              for  when  searching for a module.  Also provides information on
              module cleanup at exit.

       -V ,  --version
              Prints the Python version number of the  executable  and  exits.
              When given twice, print more information about the build.

       -W argument
              Warning  control.  Python's  warning machinery by default prints
              warning messages to sys.stderr.

              The simplest settings apply a particular action  unconditionally
              to all warnings emitted by a process (even those that are other-
              wise ignored by default):

                -Wdefault  # Warn once per call location
                -Werror    # Convert to exceptions
                -Walways   # Warn every time
                -Wmodule   # Warn once per calling module
                -Wonce     # Warn once per Python process
                -Wignore   # Never warn

              The action names can be abbreviated as desired  and  the  inter-
              preter will resolve them to the appropriate action name. For ex-
              ample, -Wi is the same as -Wignore .

              The  full  form  of  argument  is:  action:message:category:mod-
              ule:lineno

              Empty  fields  match  all  values;  trailing empty fields may be
              omitted. For example -W ignore::DeprecationWarning  ignores  all
              DeprecationWarning warnings.

              The action field is as explained above but only applies to warn-
              ings that match the remaining fields.

              The message field must match the whole printed warning  message;
              this match is case-insensitive.

              The  category  field matches the warning category (ex: "Depreca-
              tionWarning"). This must be a class name; the match test whether
              the  actual warning category of the message is a subclass of the
              specified warning category.

              The module field matches the (fully-qualified) module name; this
              match is case-sensitive.

              The lineno field matches the line number, where zero matches all
              line numbers and is thus equivalent to an omitted line number.

              Multiple -W options can be given; when a  warning  matches  more
              than one option, the action for the last matching option is per-
              formed. Invalid -W options are ignored (though, a  warning  mes-
              sage  is printed about invalid options when the first warning is
              issued).

              Warnings can also be controlled using the  PYTHONWARNINGS  envi-
              ronment  variable  and  from  within  a Python program using the
              warnings module.   For  example,  the  warnings.filterwarnings()
              function  can be used to use a regular expression on the warning
              message.

       -X option
              Set implementation-specific option. The  following  options  are
              available:

                  -X faulthandler: enable faulthandler

                  -X showrefcount: output the total reference count and number
              of used
                      memory blocks when the program finishes  or  after  each
              statement in the
                      interactive interpreter. This only works on debug builds

                  -X  tracemalloc: start tracing Python memory allocations us-
              ing the
                      tracemalloc module. By default,  only  the  most  recent
              frame is stored in a
                      traceback of a trace. Use -X tracemalloc=NFRAME to start
              tracing with a
                      traceback limit of NFRAME frames

                  -X importtime: show how long each  import  takes.  It  shows
              module name,
                      cumulative time (including nested imports) and self time
              (excluding
                      nested imports). Note that its output may be  broken  in
              multi-threaded
                      application.  Typical  usage is python3 -X importtime -c
              'import asyncio'

                  -X dev: enable CPython's "development mode", introducing ad-
              ditional runtime
                      checks which are too expensive to be enabled by default.
              It will not be
                      more verbose than the default if the  code  is  correct:
              new warnings are
                      only  emitted  when  an issue is detected. Effect of the
              developer mode:
                         * Add default warning filter, as -W default
                         * Install debug hooks on memory allocators:  see  the
              PyMem_SetupDebugHooks()
                           C function
                         *  Enable  the faulthandler module to dump the Python
              traceback on a crash
                         * Enable asyncio debug mode
                         * Set the dev_mode attribute of sys.flags to True
                         * io.IOBase destructor logs close() exceptions

                  -X utf8: enable UTF-8 mode for operating system  interfaces,
              overriding the default
                      locale-aware  mode.  -X utf8=0 explicitly disables UTF-8
              mode (even when it would
                      otherwise activate automatically).  See  PYTHONUTF8  for
              more details

                  -X  pycache_prefix=PATH: enable writing .pyc files to a par-
              allel tree rooted at the
                      given directory instead of to the code tree.

                  -X warn_default_encoding: enable opt-in EncodingWarning  for
              'encoding=None'

                  -X no_debug_ranges: disable the inclusion of the tables map-
              ping extra location
                     information (end line, start column offset and end column
              offset) to every
                     instruction  in code objects. This is useful when smaller
              code objects and pyc
                     files are desired as well as suppressing the extra visual
              location indicators
                     when the interpreter displays tracebacks.

                  -X  frozen_modules=[on|off]:  whether  or not frozen modules
              should be used.
                     The default is "on" (or "off" if you are running a  local
              build).

                  -X  int_max_str_digits=number:  limit  the size of int<->str
              conversions.
                     This helps avoid denial of service attacks  when  parsing
              untrusted data.
                     The  default  is  sys.int_info.default_max_str_digits.  0
              disables.

       -x     Skip the first line of the source.  This is intended for  a  DOS
              specific hack only.  Warning: the line numbers in error messages
              will be off by one!

EXECUTION EXAMPLE:
COMMAND INPUT:
python3 --version

COMMAND OUTPUT:
Python 3.11.2

===

COMMAND: gcc

DESCRIPTION: Usage: gcc [options] file...

USAGE: gcc [options] file...

OPTIONS:
-pass-exit-codes         Exit with highest error code from a phase.
--help                   Display this information.
--target-help            Display target specific command line options (including assembler and linker options).
--help={common|optimizers|params|target|warnings|[^]{joined|separate|undocumented}}[,...].
--version                Display compiler version information.
-dumpspecs               Display all of the built in spec strings.
-dumpversion             Display the version of the compiler.
-dumpmachine             Display the compiler's target processor.
-foffload=<targets>      Specify offloading targets.
-print-search-dirs       Display the directories in the compiler's search path.
-print-libgcc-file-name  Display the name of the compiler's companion library.
-print-file-name=<lib>   Display the full path to library <lib>.
-print-prog-name=<prog>  Display the full path to compiler component <prog>.
-print-multiarch         Display the target's normalized GNU triplet, used as
-print-multi-directory   Display the root directory for versions of libgcc.
-print-multi-lib         Display the mapping between command line options and
-print-multi-os-directory Display the relative path to OS libraries.
-print-sysroot           Display the target libraries directory.
-print-sysroot-headers-suffix Display the sysroot suffix used to find headers.
-Wa,<options>            Pass comma-separated <options> on to the assembler.
-Wp,<options>            Pass comma-separated <options> on to the preprocessor.
-Wl,<options>            Pass comma-separated <options> on to the linker.
-Xassembler <arg>        Pass <arg> on to the assembler.
-Xpreprocessor <arg>     Pass <arg> on to the preprocessor.
-Xlinker <arg>           Pass <arg> on to the linker.
-save-temps              Do not delete intermediate files.
-save-temps=<arg>        Do not delete intermediate files.
-no-canonical-prefixes   Do not canonicalize paths when building relative
-pipe                    Use pipes rather than intermediate files.
-time                    Time the execution of each subprocess.
-specs=<file>            Override built-in specs with the contents of <file>.
-std=<standard>          Assume that the input sources are for <standard>.
--sysroot=<directory>    Use <directory> as the root directory for headers
-B <directory>           Add <directory> to the compiler's search paths.
-v                       Display the programs invoked by the compiler.
-###                     Like -v but options quoted and commands not executed.
-E                       Preprocess only; do not compile, assemble or link.
-S                       Compile only; do not assemble or link.
-c                       Compile and assemble, but do not link.
-o <file>                Place the output into <file>.
-pie                     Create a dynamically linked position independent
-shared                  Create a shared library.
-x <language>            Specify the language of the following input files.

EXECUTION EXAMPLE:
COMMAND INPUT:
gcc --version

COMMAND OUTPUT:
gcc (Debian 12.2.0-14) 12.2.0
Copyright (C) 2022 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

===

COMMAND: logger

DESCRIPTION: logger - enter messages into the system log

USAGE: logger [options] message

OPTIONS:
-d, --udp
           Use datagrams (UDP) only. By default the connection is tried to the
           syslog port defined in /etc/services, which is often 514.

           See also --server and --socket to specify where to connect.

       -e, --skip-empty
           Ignore empty lines when processing files. An empty line is defined
           to be a line without any characters. Thus a line consisting only of
           whitespace is NOT considered empty. Note that when the
           --prio-prefix option is specified, the priority is not part of the
           line. Thus an empty line in this mode is a line that does not have
           any characters after the priority prefix (e.g., <13>).

       -f, --file file
           Log the contents of the specified file. This option cannot be
           combined with a command-line message.

       -i
           Log the PID of the logger process with each line.

       --id[=id]
           Log the PID of the logger process with each line. When the optional
           argument id is specified, then it is used instead of the logger
           command's PID. The use of --id=$$ (PPID) is recommended in scripts
           that send several messages.

           Note that the system logging infrastructure (for example systemd
           when listening on /dev/log) may follow local socket credentials to
           overwrite the PID specified in the message. logger(1) is able to
           set those socket credentials to the given id, but only if you have
           root permissions and a process with the specified PID exists,
           otherwise the socket credentials are not modified and the problem
           is silently ignored.

       --journald[=file]
           Write a systemd journal entry. The entry is read from the given
           file, when specified, otherwise from standard input. Each line must
           begin with a field that is accepted by journald; see
           systemd.journal-fields(7) for details. The use of a MESSAGE_ID
           field is generally a good idea, as it makes finding entries easy.
           Examples:

              logger --journald <<end
              MESSAGE_ID=67feb6ffbaf24c5cbec13c008dd72309
              MESSAGE=The dogs bark, but the caravan goes on.
              DOGS=bark
              CARAVAN=goes on
              end

              logger --journald=entry.txt

       Notice that --journald will ignore values of other options, such as
       priority. If priority is needed it must be within input, and use
       PRIORITY field. The simple execution of journalctl(1) will display
       MESSAGE field. Use journalctl --output json-pretty to see rest of the
       fields.

       + To include newlines in MESSAGE, specify MESSAGE several times. This
       is handled as a special case, other fields will be stored as an array
       in the journal if they appear multiple times.

       --msgid msgid
           Sets the RFC 5424 <https://tools.ietf.org/html/rfc5424> MSGID
           field. Note that the space character is not permitted inside of
           msgid. This option is only used if --rfc5424 is specified as well;
           otherwise, it is silently ignored.

       -n, --server server
           Write to the specified remote syslog server instead of to the
           system log socket. Unless --udp or --tcp is specified, logger will
           first try to use UDP, but if this fails a TCP connection is
           attempted.

       --no-act
           Causes everything to be done except for writing the log message to
           the system log, and removing the connection to the journal. This
           option can be used together with --stderr for testing purposes.

       --octet-count
           Use the RFC 6587 <https://tools.ietf.org/html/rfc6587> octet
           counting framing method for sending messages. When this option is
           not used, the default is no framing on UDP, and RFC6587
           non-transparent framing (also known as octet stuffing) on TCP.

       -P, --port port
           Use the specified port. When this option is not specified, the port
           defaults to syslog for udp and to syslog-conn for tcp connections.

       -p, --priority priority
           Enter the message into the log with the specified priority. The
           priority may be specified numerically or as a facility.level pair.
           For example, -p local3.info logs the message as informational in
           the local3 facility. The default is user.notice.

       --prio-prefix
           Look for a syslog prefix on every line read from standard input.
           This prefix is a decimal number within angle brackets that encodes
           both the facility and the level. The number is constructed by
           multiplying the facility by 8 and then adding the level. For
           example, local0.info, meaning facility=16 and level=6, becomes
           <134>.

           If the prefix contains no facility, the facility defaults to what
           is specified by the -p option. Similarly, if no prefix is provided,
           the line is logged using the priority given with -p.

           This option doesn't affect a command-line message.

       --rfc3164
           Use the RFC 3164 <https://tools.ietf.org/html/rfc3164> BSD syslog
           protocol to submit messages to a remote server.

       --rfc5424[=without]
           Use the RFC 5424 <https://tools.ietf.org/html/rfc5424> syslog
           protocol to submit messages to a remote server. The optional
           without argument can be a comma-separated list of the following
           values: notq, notime, nohost.

           The notq value suppresses the time-quality structured data from the
           submitted message. The time-quality information shows whether the
           local clock was synchronized plus the maximum number of
           microseconds the timestamp might be off. The time quality is also
           automatically suppressed when --sd-id timeQuality is specified.

           The notime value (which implies notq) suppresses the complete
           sender timestamp that is in ISO-8601 format, including microseconds
           and timezone.

           The nohost value suppresses gethostname(2) information from the
           message header.

           The RFC 5424 protocol has been the default for logger since version
           2.26.

       -s, --stderr
           Output the message to standard error as well as to the system log.

       --sd-id name[@digits]
           Specifies a structured data element ID for an RFC 5424 message
           header. The option has to be used before --sd-param to introduce a
           new element. The number of structured data elements is unlimited.
           The ID (name plus possibly @digits) is case-sensitive and uniquely
           identifies the type and purpose of the element. The same ID must
           not exist more than once in a message. The @digits part is required
           for user-defined non-standardized IDs.

           logger currently generates the timeQuality standardized element
           only. RFC 5424 also describes the elements origin (with parameters
           ip, enterpriseId, software and swVersion) and meta (with parameters
           sequenceId, sysUpTime and language). These element IDs may be
           specified without the @digits suffix.

       --sd-param name=value
           Specifies a structured data element parameter, a name and value
           pair. The option has to be used after --sd-id and may be specified
           more than once for the same element. Note that the quotation marks
           around value are required and must be escaped on the command line.

                   logger --rfc5424 --sd-id zoo@123             \
                                    --sd-param tiger="hungry"   \
                                    --sd-param zebra="running"  \
                                    --sd-id manager@123         \
                                    --sd-param onMeeting="yes"  \
                                    "this is message"

           produces:

           <13>1 2015-10-01T14:07:59.168662+02:00 ws kzak - - [timeQuality
           tzKnown="1" isSynced="1" syncAccuracy="218616"][zoo@123
           tiger="hungry" zebra="running"][manager@123 onMeeting="yes"] this
           is message

       -S, --size size
           Sets the maximum permitted message size to size. The default is
           1KiB characters, which is the limit traditionally used and
           specified in RFC 3164. With RFC 5424, this limit has become
           flexible. A good assumption is that RFC 5424 receivers can at least
           process 4KiB messages.

           Most receivers accept messages larger than 1KiB over any type of
           syslog protocol. As such, the --size option affects logger in all
           cases (not only when --rfc5424 was used).

           Note: the message-size limit limits the overall message size,
           including the syslog header. Header sizes vary depending on the
           selected options and the hostname length. As a rule of thumb,
           headers are usually not longer than 50 to 80 characters. When
           selecting a maximum message size, it is important to ensure that
           the receiver supports the max size as well, otherwise messages may
           become truncated. Again, as a rule of thumb two to four KiB message
           size should generally be OK, whereas anything larger should be
           verified to work.

       --socket-errors[=mode]
           Print errors about Unix socket connections. The mode can be a value
           of off, on, or auto. When the mode is auto, then logger will detect
           if the init process is systemd(1), and if so assumption is made
           /dev/log can be used early at boot. Other init systems lack of
           /dev/log will not cause errors that is identical with messaging
           using openlog(3) system call. The logger(1) before version 2.26
           used openlog(3), and hence was unable to detected loss of messages
           sent to Unix sockets.

           The default mode is auto. When errors are not enabled lost messages
           are not communicated and will result to successful exit status of
           logger(1) invocation.

       -T, --tcp
           Use stream (TCP) only. By default the connection is tried to the
           syslog-conn port defined in /etc/services, which is often 601.

           See also --server and --socket to specify where to connect.

       -t, --tag tag
           Mark every line to be logged with the specified tag. The default
           tag is the name of the user logged in on the terminal (or a user
           name based on effective user ID).

       -u, --socket socket
           Write to the specified socket instead of to the system log socket.

       --
           End the argument list. This allows the message to start with a
           hyphen (-).

       -h, --help
           Display help text and exit.

       -V, --version
           Print version and exit.

EXECUTION EXAMPLE:
COMMAND INPUT:
logger "Test message" && grep "Test message" /var/log/syslog | tail -1

COMMAND OUTPUT:
2025-03-03T23:02:41.210314+00:00 cybo1 vega: Test message

===

COMMAND: last

DESCRIPTION: last, lastb - show a listing of last logged in users

USAGE: last [options] [username...] [tty...]

       lastb [options] [username...] [tty...]

OPTIONS:
-a, --hostlast
           Display the hostname in the last column. Useful in combination with
           the --dns option.

       -d, --dns
           For non-local logins, Linux stores not only the host name of the
           remote host, but its IP number as well. This option translates the
           IP number back into a hostname.

       -f, --file file
           Tell last to use a specific file instead of /var/log/wtmp. The
           --file option can be given multiple times, and all of the specified
           files will be processed.

       -F, --fulltimes
           Print full login and logout times and dates.

       -i, --ip
           Like --dns , but displays the host's IP number instead of the name.

       -number; -n, --limit number
           Tell last how many lines to show.

       -p, --present time
           Display the users who were present at the specified time. This is
           like using the options --since and --until together with the same
           time.

       -R, --nohostname
           Suppresses the display of the hostname field.

       -s, --since time
           Display the state of logins since the specified time. This is
           useful, e.g., to easily determine who was logged in at a particular
           time. The option is often combined with --until.

       -t, --until time
           Display the state of logins until the specified time.

       --time-format format
           Define the output timestamp format to be one of notime, short,
           full, or iso. The notime variant will not print any timestamps at
           all, short is the default, and full is the same as the --fulltimes
           option. The iso variant will display the timestamp in ISO-8601
           format. The ISO format contains timezone information, making it
           preferable when printouts are investigated outside of the system.

       -w, --fullnames
           Display full user names and domain names in the output.

       -x, --system
           Display the system shutdown entries and run level changes.

       -h, --help
           Display help text and exit.

       -V, --version
           Print version and exit.

EXECUTION EXAMPLE:
COMMAND INPUT:
last | head -5

COMMAND OUTPUT:
vega     pts/0        130.208.133.151  Mon Mar  3 22:44   still logged in
reboot   system boot  6.1.0-31-cloud-a Mon Mar  3 22:29   still running

wtmp begins Mon Mar  3 22:29:30 2025

===

COMMAND: lastlog

DESCRIPTION: lastlog - reports the most recent login of all users or of a given user

USAGE: lastlog [options]

OPTIONS:
The options which apply to the lastlog command are:

       -b, --before DAYS
           Print only lastlog records older than DAYS.

       -C, --clear
           Clear lastlog record of a user. This option can be used only
           together with -u (--user)).

       -h, --help
           Display help message and exit.

       -R, --root CHROOT_DIR
           Apply changes in the CHROOT_DIR directory and use the configuration
           files from the CHROOT_DIR directory. Only absolute paths are
           supported.

       -S, --set
           Set lastlog record of a user to the current time. This option can
           be used only together with -u (--user)).

       -t, --time DAYS
           Print the lastlog records more recent than DAYS.

       -u, --user LOGIN|RANGE
           Print the lastlog record of the specified user(s).

           The users can be specified by a login name, a numerical user ID, or
           a RANGE of users. This RANGE of users can be specified with a min
           and max values (UID_MIN-UID_MAX), a max value (-UID_MAX), or a min
           value (UID_MIN-).

       If the user has never logged in the message ** Never logged in** will
       be displayed instead of the port and time.

       Only the entries for the current users of the system will be displayed.
       Other entries may exist for users that were deleted previously.

EXECUTION EXAMPLE:
COMMAND INPUT:
lastlog | head -5

COMMAND OUTPUT:
Username         Port     From                                       Latest
root                                                                **Never logged in**
daemon                                                              **Never logged in**
bin                                                                 **Never logged in**
sys                                                                 **Never logged in**

===

COMMAND: watch

DESCRIPTION: watch - execute a program periodically, showing output fullscreen

USAGE: watch [options] command

OPTIONS:
-d, --differences[=permanent]
              Highlight the differences between successive updates. If the op-
              tional  permanent argument is specified then watch will show all
              changes since the first iteration.

       -n, --interval seconds
              Specify update interval.  The command  will  not  allow  quicker
              than  0.1  second interval, in which the smaller values are con-
              verted. Both '.' and ',' work for any locales. The  WATCH_INTER-
              VAL  environment  can  be used to persistently set a non-default
              interval (following the same rules and formatting).

       -p, --precise
              Make watch attempt to run command every --interval seconds.  Try
              it  with ntptime (if present) and notice how the fractional sec-
              onds stays (nearly) the same, as opposed to  normal  mode  where
              they continuously increase.

       -t, --no-title
              Turn  off  the header showing the interval, command, and current
              time at the top of the display, as well as the  following  blank
              line.

       -b, --beep
              Beep if command has a non-zero exit.

       -e, --errexit
              Freeze updates on command error, and exit after a key press.

       -g, --chgexit
              Exit when the output of command changes.

       -q, --equexit <cycles>
              Exit when output of command does not change for the given number
              of cycles.

       -c, --color
              Interpret ANSI color and style sequences.

       -x, --exec
              Pass command to exec(2) instead of sh -c which reduces the  need
              to use extra quoting to get the desired effect.

       -w, --no-wrap
              Turn  off line wrapping. Long lines will be truncated instead of
              wrapped to the next line.

       -h, --help
              Display help text and exit.

       -v, --version
              Display version information and exit.

EXECUTION EXAMPLE:
COMMAND INPUT:
watch --version

COMMAND OUTPUT:
watch from procps-ng 4.0.2

===

COMMAND: ldd

DESCRIPTION: ldd - print shared object dependencies

USAGE: ldd [option]... file...

OPTIONS:
--version
              Print the version number of ldd.

       -v, --verbose
              Print all information, including, for example, symbol versioning
              information.

       -u, --unused
              Print unused direct dependencies.  (Since glibc 2.3.4.)

       -d, --data-relocs
              Perform relocations and report any missing objects (ELF only).

       -r, --function-relocs
              Perform relocations for both data objects and functions, and re-
              port any missing objects or functions (ELF only).

       --help Usage information.

EXECUTION EXAMPLE:
COMMAND INPUT:
ldd /bin/ls | head -5

COMMAND OUTPUT:
linux-vdso.so.1 (0x00007ffe84d8a000)
	libselinux.so.1 => /lib/x86_64-linux-gnu/libselinux.so.1 (0x00007f1723ee1000)
	libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f1723d00000)
	libpcre2-8.so.0 => /lib/x86_64-linux-gnu/libpcre2-8.so.0 (0x00007f1723c66000)
	/lib64/ld-linux-x86-64.so.2 (0x00007f1723f3d000)

===

